# 저장소와 검색

## 데이터베이스를 강력하게 만드는 데이터 구조

데이터를 추가하는 것은 비용이 저렴하다. 반면 찾는 것은 그렇지 않다. 데이터베이스에 많은 레코드가 있으면 더욱 그렇다. 데이터베이스의 레코드 수가 2배가 되면 찾는데 걸리는 시간도 2배가 된다.

데이터베이스에서 특정 키의 값을 효율적으로 찾기 위해서는 다른 데이터 구조가 필요하다. 바로 **색인**이다.

- 색인은 기본 데이터에서 파생된 **추가적인** 구조다.
- 색인은 쓰기 과정에서 오버헤드가 발생한다. 단순히 파일을 쓸 때보다 색인을 갱신하기 위한 작업이 추가되기 때문이다.

따라서 질의 패턴에 대한 지식을 활용해 수동으로 색인을 선택해야 필요이상으로 오버헤드를 발생시키지 않으면서 가장 큰 이익을 안겨주는 색인을 선택할 수 있다.

### 해시 색인

해시 테이블은 키-값 쌍을 저장하는 자료구조다. 해시 테이블은 키를 해시 함수에 넣어서 해시값을 얻고, 이 해시값을 배열의 인덱스로 사용한다. 배열의 각 슬롯에는 키-값 쌍이 저장된다.

각 키의 값이 자주 갱신되는 상황에 매우 적합하다.

파일에 항상 추가만 한다면 결국 디스크 공간이 부족해진다. 특정 크기의 세그먼트(segment)로 로그를 나누는 방식이 좋은 해결책이다.

### SS 테이블과 LSM 트리

세그먼트 파일의 형식에 키-값 쌍을 키로 정렬해보자. 이를 정렬된 문자열 테이블(Sorted String Table) 또는 짧게 SS테이블이라고 부른다. SS테이블은 해시 색인을 가진 로그 세그먼트보다 몇 가지 큰 장점이 있다.

1. 세그먼트 병합은 파일이 사용 가능한 메모리보다 크더라도 간단하고 효율적이다. 병합정렬과 유사한 알고리즘을 사용한다.
2. 파일에서 특정 키를 찾기 위해 더는 메모리에 모든 키의 색인을 유지할 필요가 없다. 1, 5 라는 데이터가 색인되어있다면, 2는 그 사이에 있을 것이라고 추측할 수 있으므로(정렬되어 있기 때문에), 1로 이동한 뒤 스캔하면 된다.
3. 읽기 요청은 요청 범위 내에서 여러 키-값 쌍을 스캔해야 하기 때문에 해당 레코드들을 블록으로 그룹화하고 디스크에 쓰기 전에 압축한다. 디스크 공간을 절약한다는 점 외에도 압축은 I/O 대역폭 사용도 줄인다.

#### SS 테이블 생성과 유지

유입되는 쓰기는 임의 순서로 발생하는데 데이터를 키로 정렬하려면 어떻게 해야할까? 레드 블랙 트리나 AVL 트리와 같은 자료구조를 사용하면 임의 순서로 키를 삽입하고 정렬된 순서로 해당 키를 다시 읽을 수 있다.

이제 저장소 엔진을 다음과 같이 만들 수 있다.

- 쓰기가 들어오면 인메모리 균형 트리 데이터 구조에 추가한다. 이 인메모리 트리는 **멤테이블(memtable)**이라고도 한다.
- 멤테이블이 꽉 차면 디스크에 SS 테이블을 쓴다. 디스크에 기록하는 동안 쓰기는 새로운 멤테이블 인스턴스에 기록한다.
- 읽기 요청을 제공하려면 먼저 멤테이블에서 키를 찾아야 한다. 그다음 디스크 상의 가장 최신 세그먼트에서 찾는다.
- 가끔 세그먼트 파일을 합치고 덮어 쓰여지거나 삭제된 값을 버리는 병합과 컴팩션 과정을 수행한다. 이 과정은 백그라운드에서 수행된다.

#### SS 테이블에서 LSM 트리 만들기

정렬된 파일 병합과 컴팩션 원리를 기반으로 하는 저장소 엔진을 LSM 저장소 엔진이라 부른다.

루씬(Lucene)은 엘라스틱서치나 솔라에서 사용하는 전문 검색 색인 엔진이다. 루씬은 용어 사전(term dictionary)을 저장하기 위해 유사한 방법을 사용한다. 검색 질의로 단어가 들어오면 단어가 언급된 모든 문서(웹 페이지, 제품 설명 등)를 찾는다. 이 접근법은 키를 단어(용어)로, 값은 단어를 포함한 모든 문서의 ID 목록(포스팅 목록)으로 하는 키-값 구조로 구현한다. 루씬에서 용어와 포스팅 목록의 매핑은 SS테이블 같은 정렬 파일에 유지하고 필요에 따라 백그라운드에서 병합한다.

#### 성능 최적화

- 블룸 필터: 키가 존재하지 않는다는 사실을 확인하기 위해 가장 오래된 세그먼트까지 거슬러올라가는 가능성을 줄이기 위해 사용한다.
- 크기 계층과 레벨 컴팩션 전략

### B 트리

가장 일반적으로 사용되는 색인 구조

로그 구조화 색인은 데이터베이스를 일반적으로 수 메가바이트 이상의 가변 크기를 가진 세그먼트로 나누고 항상 순차적으로 세그먼트를 기록한다.

반면 B 트리는 전통적으로 4KB 크기(때로는 더 큰)의 고정 크기 블록이나 페이지로 나누고 한 번에 하나의 페이지에 읽기 또는 쓰기를 한다.

- 루트 페이지
- 리프 페이지
- 분기 계수

#### 신뢰할 수 있는 B 트리 만들기

디스크의 페이지를 덮어쓰는 것은 실제 하드웨어 동작이다. 일부 페이지만 기록하고 데이터베이스가 고장 난다면 결국 색인이 훼손되기 때문에 이것은 매우 위험한 동작이다. 고장 상황에서 스스로 복구할 수 있게 만들려면 일반적으로 디스크 상에 쓰기 전 로그(write-ahead log, WAL) 재실행 로그라고도 하는 데이터 구조를 추가해 B 트리를 구현한다. 이 로그는 데이터베이스가 고장 이후 복구될 때 일관성 있는 상태로 B 트리를 복원하는 데 사용한다.

다중 스레드가 동시에 B 트리에 접근한다면 주의 깊게 동시성 제어를 해야 한다.

#### B 트리 최적화

- copy on write scheme
- 축약된 키 저장
- 리프 페이지가 디스크 상의 연속된 순서로 나타나게끔 트리 배치
- 트리에 포인터를 추가
- 프랙탈 트리

### B 트리와 LSM 트리 비교

#### LSM 트리의 장점

B 트리 색인은 모든 데이터 조각을 최소한 두 번 기록해야 한다. 쓰기 전 로그 한 번과 트리 페이지에 한 번이다. 해당 페이지 내 몇 바이트만 바뀌어도 한 번에 전체 페이지를 기록해야 하는 오버헤드도 있다.

데이터베이스에 쓰기 한 번이 데이터베이스 수명 동안 여러 번의 쓰기를 야기하는 이런 효과를 **쓰기 증폭**이라고 한다. 쓰기가 많은 애플리케이션에서 성능 병목은 데이터베이스가 디스크에 쓰는 속도일 수 있다. 이 경우 쓰기 증폭은 바로 성능 비용이다.

- LSM 트리는 상대적으로 쓰기 증폭이 더 낮다. 
- 압축률이 더 좋다.

#### LSM 트리의 단점

- 컴팩션 과정이 때로는 진행 중인 읽기와 쓰기의 성능에 영향을 준다
- 컴팩션 설정을 주의 깊게 하지 않으면 컴팩션이 유입 쓰기 속도를 따라갈 수 없다

## 트랜잭션 처리나 분석?

사용자 입력을 기반으로 삽입되거나 갱신되는 대화식 처리를 온라인 트랜잭션 처리(online transaction processing, OLTP)라고 한다.

그러나 데이터 분석은 트랜잭션과 접근 패턴이 매우 다르다. 보통 분석 질의는 많은 수의 레코드를 스캔해 일부 칼럼만 읽어 집계 통계를 계산해야 한다. 이런 데이터베이스 사용 패턴을 트랜잭션 처리와 구분하기 위해 온라인 분석 처리(online analytical processing, OLAP)라고 한다.

### 데이터 웨어하우징

- 데이터 웨어하우스 : OLTP 작업에 영향을 주지 않고 마음껏 질의할 수 있는 개별 데이터베이스
- ETL(Extract-Transform-Load): 데이터베이스에서 데이터를 추출하고 분석 친화적인 스키마로 변환, 정제 및 적재하는 과정

### 분석용 스키마: 별 모양 스키마와 눈꽃송이 모양 스키마

## 칼럼 지향 저장소

모든 값을 하나의 로우에 함께 저장하지 않는 대신 각 칼럼 별로 모든 값을 함께 저장한다. 각 칼럼을 개별 파일에 저장하면 질의에 사용되는 칼럼만 읽고 구분 분석하면 된다.

- 칼럼 지향 저장소 배치는 각 칼럼 파일에 포함된 로우가 모두 같은 순서인 점에 의존한다

### 칼럼 압축

- 비트맵 부호화(bitmap encoding)

#### 메모리 대역폭과 벡터화 처리

### 칼럼 저장소의 순서 정렬

칼럼 별로 독립적으로 정렬할 수는 없다. 그렇게 하면 각 칼럼의 어떤 항목이 동일한 로우에 속하는지 알 수 없기 때문이다. 한 칼럼의 k번째 항목이 다른 칼럼의 k번째 항목과 같은 로우에 속한다는 것을 알고 있으니 재구성할 수 있다.

따라서, 칼럼별로 저장됐을지라도 데이터는 한번에 전체 로우를 정렬해야 한다.

정렬된 순서는 칼럼 압축에 도움이 된다. 기본 정렬 칼럼에 고유 값을 많이 포함하지 않는다면 정렬된 칼럼은 같은 값이 연속해서 길게 반복된다. 간단한 런 렝스 부호화는 **수십억 개의 로우를 가진 테이블이라도 수 킬로바이트로 칼럼을 압축**할 수 있다. 이런 압축 효과는 첫 번째 정렬 키에서 가장 강력하다. 두 번째나 세 번째 정렬키는 그보다 뒤섞여 있어서 반복된 값이 길지 않기 때문이다.

### 칼럼 지향 저장소에 쓰기

### 집계: 데이터 큐브와 구체화 뷰

## 정리
