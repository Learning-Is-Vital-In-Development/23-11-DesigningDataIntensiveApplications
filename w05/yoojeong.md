## 저장소와 검색

### 트랜잭션 처리나 분석?

보통 애플리케이션은 색인을 사용해 일부 키에 대한 적은 수의 레코드를 찾는다. 레코드는 사용자 입력 기반으로 추가 및 갱신된다. <br>
이런 애플리케이션은 대화식이기에 이런 접근 패턴을 온라인 트랜잭션 처리(online trrasaction processing, OLTP)이라 한다.


하지만 데이터베이스를 데이터 분석(data analytic)에도 점점 더 많이 사용하기 시작했고, 데이터 분석은 기존 트랜잭션과 접근 패턴이 매우 다르다. <br>
사용자에게 소수의 원시 데이터를 반환하는게 아닌 많은 수의 레코드를 스캔한 뒤 일부 칼럼만 읽어서 집계 통계(카운트, 합, 평균 등)를 계산해야 한다. <br>
이런 접근 패턴을 온라인 분석 처리(online analytic processing, OLAP)라고 부른다.



| 특성 | 트랜잭션 처리 시스템(OLTP)|분석 시스템(OLAP)|
|:--:|  :--:|:--:|
|주요 읽기 패턴|질의당 적은 수의 레코드, 키 기준으로 가져옴|많은 레코드에 대한 집계|
|주요 쓰기 패턴|임의 접근, 사용자 입력을 낮은 지연 시간으로 기록|대규모 불러오기(bulk import, ETL) 또는 이벤트 스트림|
|주요 사용처|웹 애플리케이션을 통한 최종 사용자/소비자|의사결정 지원을 위한 내부 분석가|
|데이터 표현|데이터의 최신 상태(현재 시점)|시간이 지나며 일어난 이벤트 이력|
|데이터셋 크기|기가바이트에서 테라바이트|테라바이트에서 페타바이트|

처음에는 둘 다 동일한 데이터베이스를 사용했으나, 최근에 들어서는 OLTP 시스템을 분석 목적으로 사용하지 않고 개별 데이터베이스에서 분석을 수행하는 경향을 보였으며, 이러한 개별 데이터베이스를 데이터 웨어하우스(data warehouse)라고 불렀다.


#### 데이터 웨어하우징

- OLTP 데이터베이스에 즉석 분석 질의(ad hoc analytic query)를 함부로 실행시켰다간 서비스의 전체 서비스 퀄리티 하락으로 이어질 수 있다.
- 데이터 웨어하우스는 분석가들이 OLTP 작업에 영향을 주지 않고 마음껏 질의할 수 있게 데이터의 읽기 전용 복사본을 저장하는 개별 데이터베이스이다.
- 데이터는 OLTP 데이터베이스에서 (주기적인 데이터 덤프나 지속적인 갱신 스트림을 사용해) 추출(extract)하고 분석 친화적인 스키마로 변환(transform)하여 데이터 웨어하우스에 적재(load)한다.(ETL)

![image](https://github.com/rachel5004/23-11-DesigningDataIntensiveApplications/assets/75432228/429bce98-c470-4c12-9578-847556c0cabc)


#### OLTP 데이터베이스와 데이터 웨어하우스의 차이점
SQL은 일반적으로 분석 질의에 적합하기에 데이터웨어 하우스는 일반적인 관계형 모델을 사용한다.

- SQL 질의를 생성하고 결과를 시각화
- 분석가가 드릴 다운(drill-down), 슬라이싱(slicing), 다이싱(dicing)같은 작업을 통해 데이터를 탐색할 수 있게 해주는 여러 그래픽 데이터 분석 도구 존재
  
OLTP나 데이터 웨어하우스 둘 다 SQL 질의 인터페이스를 지원한다는 공통점이 있지만, 둘은 서로 매우 다른 질의 패턴에 맞게 최적화되었기 때문에 내부는 완전히 다르다.<br>
그렇기에 다수의 데이터베이스 벤더 역시 트랜잭션 처리와 분석 작업부하를 둘 다 지원하기보단 하나에 특화되도록 지원하는데 중점을 둔다. 

> 참고: 드릴 다운(drill-down), 슬라이싱(slicing), 다이싱(dicing)
드릴 다운은 요약된 정보에서 상세 정보까지 계층을 나눠 구체적으로 분석하는 작업.
> 슬라이싱과 다이싱은 상세한 분석을 위해 주어진 큰 규모의 데이터를 작은 단위로 나누고 원하는 세부 분석 결과를 얻을 때까지 반복한다는 의미.

#### 분석용 스키마: 별 모양 스키마와 눈꽃송이 모양 스키마

많은 데이터 웨어하우스는 별 모양 스키마(star schema, 혹은 차원 모델링)로 상당히 정형화된 방식을 사용한다. 

![image](https://github.com/rachel5004/23-11-DesigningDataIntensiveApplications/assets/75432228/c51d7fe2-6efb-462c-af48-6875a11c8bea)


- `사실 테이블(fact table)`: 각 로우는 특정 시각에 발생한 이벤트에 해당한다.(e.g. 고객의 제품 구매) 사실 테이블의 일부 컬럼은 제품이 판매된 가격과 공급자로부터 구매한 비용과 같은 속성이다. 나머지 다른 컬럼들은 차원 테이블을 가리키는 외래키 참조다.
- `차원테이블(dimension table)`: 이벤트의 속성인 누가, 언제, 어디서, 무엇을, 어떻게, 왜를 나타낸다. (e.g. 판매된 제품(dim_product))
  
이러한 템플릿의 변형을 눈꽃송이 모양 스키마(snowflake schema)라고 하며 차원이 하위 차원으로 더 세분화된다. <br>
쉽게 말해 하위 차원테이블이 모두 실제 값만을 저장하는게아닌 또다른 차원테이블의 외래키를 저장하여 세분화하는 것이다. <br>
이는 별 모양 스키마보다 더 정규화됐지만, 작업 난이도가 더 올라가기 때문에 분석가들은 별 모양 스키마를 더 선호한다.

### 칼럼 지향 저장소


```sql
SELECT
  dim_date.weekday, dim_product.category,
  SUM(fact_sales.quantity) AS quantity_sold
FROM fact_sales
  JOIN dim_date ON fact_sales.date_key = dim_date.date_key
  JOIN dim_product ON fact_sales.product_sk = dim_product.product_sk
WHERE
  dim_date.year = 2013 AND
  dim_product.category IN ('Fresh fruit', 'Candy')
GROUP BY
  dim_date.weekday, dim_product.category;
```

사실 테이블에는 엄청난 개수의 로우와 페타바이트 데이터가 있기 떄문에 모든 값을 하나의 로우에 함께 저장하지 않는 대신 각 컬럼 별로 모든 값을 함께 저장한다.<br>
각 컬럼을 개별 파일에 저장하면 질의에 사용되는 컬럼만 읽고 분석하면 된다.


![image](https://github.com/rachel5004/23-11-DesigningDataIntensiveApplications/assets/75432228/e223d259-0ddf-4a03-a575-0af208818fdf)


### 칼럼 압축
압축을 통해 데이터를 압축하면 디스크 처리량을 줄일 수 있는데, 칼럼 지향 저장소는 대게 압축에 적합하다.<br>
product_sk 처럼 많은 값이 반복될 경우 데이터 웨어하우스에서 특히 효과적인 비트맵 부호화(bitmap encoding) 압축을 사용할 수 있다.

![image](https://github.com/rachel5004/23-11-DesigningDataIntensiveApplications/assets/75432228/c2c642be-91d9-4e9e-a760-f57fd5363b5e)


칼럼에서 고유 값의 수는 로우 수에 비해 적다. (product_sk : 18개의 데이터, 고유한 값은 6가지(29, 30, 31, 68, 69, 74) 뿐) 

그렇기에 n개의 고유 값을 가진 칼럼을 가져와 n개의 개별 비트맵으로 변환할 수 있다.  위 그림과 같이 고유 값 하나가 하나의 비트맵이고 각 로우는 한 비트를 가지기에 로우가 해당 값을 가질 경우 비트는 1이고 아니면 0이다. 
여기서 고유 값(n)이 클수록 대부분의 비트맵은 0이 더 많아지는데 이를 희소(sparse)하다고 말하는데, 이 경우 위 그림의 하단처럼 런 렝스 부호화(run-length encoding)할 수 있다.
이러한 비트맵 색인은 데이터 웨어하우스에서 일반적으로 사용되는 질의종류에 매우 적합하다. 

1. `WHERE product_sk IN (30, 68, 69)`
: product_sk가 30, 68, 69 인 비트맵 세 개를 적재해 비트 OR 연산을 하면 해당 조건에 해당하는 값이 몇 번째 인덱스에 존재하는지 쉽게 확인할 수 있다. 

2. `WHERE product_sk = 31 AND store_sk = 3`
: product_sk = 31과 store_sk = 3인 비트맵을 적재해 비트 AND를 연산하면, 해당 계산은 각 칼럼에 동일한 순서로 로우가 포함되기 때문에 한 칼럼의 비트맵에 있는 k번째 비트는 다른 칼럼의 비트맵에서 k번째 비트와 같은 로우에 해당한다. 

> 참고: 칼럼 지향 저장소와 칼럼 패밀리
카산드라와 HBase는 빅테이블로부터 내려오는 칼럼 패밀리란 개념이 있다.
하지만, 이를 칼럼 지향적이라 부르기엔 오해의 소지가 많다. 각 칼럼 패밀리 안에는 로우 키에 따라 로우와 모든 칼럼을 함께 저장하며 칼럼 압축을 사용하지 않는다. 따라서 빅테이블 모델은 여전히 대부분 로우 지향이다.


### 메모리 대역폭과 벡터화 처리
수백만이 넘는 로우를 스캔해야 할 때 데이터 웨어하우스 질의는 디스크로부터 메모리로 데이터를 가져오는 대역폭이 큰 병목이다. 
그리고 분석용 데이터베이스 개발자는 메인 메모리에서 CPU 캐시로 가는 대역폭을 효율적으로 사용하고 CPU 명령 처리 파이프라인에서 분기 예측 실패(branch misprediction)와 버블(bubble)을 피하며 최신 CPU에서 단일 명령 다중 데이터(single-instruction-multi-data, SIMD)명령을 사용하게끔 신경써야 한다.
칼럼 저장소 배치는 CPU 주기를 효율적으로 사용하기에 적잡한데, 예를 들어 질의 엔진은 압축된 칼럼 데이터를 CPU의 L1캐시에 딱 맞게 덩어리로 나눠 가져오고 이 작업을(함수 호출이 없는) 타이트 루프(tight loop)에서 반복한다. CPU는 함수 호출이 많이 필요한 코드나 각 레코드 처리를 위해 분기가 필요한 코드보다 타이트 루프를 훨씬 빠르게 실행할 수 있다. 
칼럼 압축을 사용하면 같은 양의 L1 캐시에 칼럼의 더 많은 로우를 저장할 수 있다. 앞에서 설명한 비트 AND 와 OR같은 연산자는 압축된 칼럼 데이터 덩어리를 바로 연산할 수 있게 설계할 수 있다.
이런 기법을 벡터화 처리(vectorized processing)라고 한다.

> 분기 예측실패와 버블
분기 예측 실패를 알기위해선 분기 예측을 알 필요가 있다. 
분기 예측이란 CPU 처리성능 향상을 위해 명령(instruction)처리 과정을 여러 단계로 세분화 하는기법인 파이프라인을 통한 명령 실행 중 조건 분기 명령의 실행이 종료될 때까지 다음 명령을 대기하지 않고 분기를 예측 실행해 파이프라인 처리 성능 저하를 최소화하는 CPU 실행 기술이며, 이런 예측이 실패하는 것을 분기예측실패라 한다. 어떤 방식으로 분기를 예측하는지에 대해서는 주제와 벗어나기에 생략한다.  그리고 파이프라인에서 구조적 해저드를 해소하기 위해 버블을 넣는데, 이 때 명령의 처리를 진행하지 않는다. 

### 칼럼 저장소의 순서 정렬
칼럼 저장소에서 로우가 저장되는 순서가 반드시 중요한건 아니다. 
삽입된 순서로 저장하는 방식이 가장 쉽다. 하지만, 이전의 SS 테이블에서 했던 것처럼 순서를 도입해 이를 색인 메커니즘으로 사용할 수 있다. 
각 칼럼을 독립적으로 정렬할 수는 없다. 그렇게 되면 칼럼의 어떤 항목이 동일한 로우에 속한다는 것을 보장할 수 없게 되기 때문이다. 한 칼럼의 k번째 항목이 다른 칼럼의 k번째 항목과 같은 로우에 속한다는 것을 보장하기에 로우를 재구성할 수 있기 때문이다. 


![image](https://github.com/rachel5004/23-11-DesigningDataIntensiveApplications/assets/75432228/c76f1181-8385-477d-bc99-9ce8dc83eb40)

age칼럼만 단독 정렬하는 경우
위 그림과 같이 하나의 칼럼만 정렬할 경우, 김철수 라는 이름의 유저가 offset 1인 위치이기에 이 offset을 기반으로 데이터를 모았을 때 {김철수, 29, QA, IT2001}이라는 잘못된 정보가 모이게 된다.
그렇기에 칼럼별로 저장되었을지라도 데이터는 한번에 전체 로우를 정렬해야 한다.
데이터베이스 관리자는 공통 질의에 대한 지식을 사용해 테이블에서 정렬해야 하는 칼럼을 선택할 수 있으며, 첫 번째 칼럼에서 같은 값을 가진 로우들의 정렬 순서를 두 번째 칼럼에서 정할 수 있다. 이런 특징을 이용해 그룹화와 필터링 질의에 도움을 줄 수 있다. 
정렬된 순서의 또 다른 장점으로는 칼럼 압축이 있는데, 기본 정렬 칼럼에 고유 값을 많이 포함하지 않는다면 정렬한 후 기본 정렬 칼럼은 연속해서 같은 값이 연속해서 길게 반복된다. 
간단한 런 렝스 부호화는 수십억 개의 로우를 가진 테이블도 수 킬로바이트로 칼럼을 압축할 수 있다. 
물론 이런 압축은 첫 번째 정렬키가 가장 강력하고 두 번째, 세 번째로 내려갈수록 뒤섞여 있기에 압축률이 높지 않다. 하지만, 초반 정렬된 몇개의 칼럼을 압축하는 것은 전체적으로 여전히 이득이다. 


#### 다양한 순서 정렬
다양한 질의는 각각이 다른 정렬 순서의 도움을 받는다. 
그렇다면 같은 데이터를 다양한 방식으로 정렬해 저장한다면, 질의를 처리할 때 가장 적합한 버전을 사용하면 높은 성능을 기대할 수 있다.  하나의 장비가 고장나도 데이터를 잃지 않기 위해서는 동일한 데이터를 여러 장비에 복제할 필요가 있는데(Ex: raid 구성) 복제 데이터를 서로 다른 방식으로 정렬해서 저장하면 다양한 순서정렬 데이터셋을 가질 수 있다. 
칼럼 지향 저장에서 여러 정렬 순서를 갖는 것은 로우 지향 저장에서 여러 2차 색인을 갖는것과 약간 비슷하다. 
하지만, 로우 지향 저장은 한 곳(힙 파일이나 클러스터드 색인)에 모든 로우를 유지하고 2차 색인은 일치하는 로우를 가리키는 포인터만 포함한다는 차이가 있다. 칼럼 저장에서는 일반적으로 데이터를 가리키는 포인터가 없고, 단지 값을 포함한 칼럼만 존재한다. 
#### 칼럼 지향 저장소에 쓰기
데이터 웨어하우스에서 칼럼 지향 저장소 뿐만아니라 압축, 정렬 모두 읽기 질의를 빠르게 하는 방법이다. 하지만, 반대로 쓰기를 어렵게 하는 방법이기도 하다. 
B 트리와 같은 제자리 갱신(update-in-place)접근 방식은 압축된 칼럼에선 불가능하다. 
대신 LSM트리를 이용해 쓰기 문제를 해결한다. 모든 쓰기는 먼저 인메모리 저장소로 이동해 정렬된 구조에 추가하고 디스크에 쓸 준비를 한다. 그 다음 충분한 쓰기가 모이면 디스크의 칼럼 파일에 병합하고 대량으로 새로운 파일에 기록한다. 
질의는 디스크의 칼럼 데이터와 메모리의 최근쓰기를 모두 조사하여 결합해야 한다. 
다만, 질의 최적화기는 이런 구별을 사용자에게 드러내지 않는다. 

#### 집계: 데이터 큐브와 구체화 뷰
자주 사용되는 값에 대한 캐시를 하면 어떨까?
데이터 웨어하우스는 구체화 집계(materialized aggregate)라는 측면을 가지고 있기에, 보통 질의에 집계 함수(COUNT, SUM, AVG, MIN, MAX)가 포함되는 경우가 많다. 
그렇다면 이런 집계 일부(COUNT, SUM)을 캐시하는건 어떨까?
이런 캐시를 만드는 한 가지 방법이 구체화 뷰(materialized view)다. 관계형 데이터 모델에선 이런 (COUNT, SUM 같은)캐시를 대개 표준 (가상)뷰로 정의하는데,  표준 뷰는 테이블 같은 객체로 일부 질의의 결과가 내용이다. 
구체화 뷰는 디스크에 기록된 질의 결과의 실제 복사본이지만, 가상 뷰(virtual view)는 단지 질의를 작성하는 단축키라는 차이가 있다. 가상 뷰에서 읽을 때 SQL엔진은 뷰의 원래 질의를 즉석에서 확장하고 나서 질의를 처리한다. 

#### 원본 데이터가 변경되는 경우
위에서 구체화 뷰는 복사본이라는 말을 했는데, 원본 데이터가 변경되면 이 복사본과 일치하지 않기대문에 구체화 뷰를 갱신해야 하는데, 데이터베이스는 이 작업을 자동으로 수행할 수 있다. 
하지만 이런 과정에서 발생하는 쓰기는 비용이 비싸기에 OLTP 데이터베이스에서는 구체화 뷰를 자주 사용하지 않는다. 
하지만, 데이터 웨어하우스에서는 읽기 비중이 크기 때문에 구체화 뷰를 사용하는 전략은 합리적이다. 
데이터 큐브(data cube) 또는 OLAP 큐브라 알려진 구체화 뷰는 일반화된 구체화 뷰의 특별 사례다. 

![image](https://github.com/rachel5004/23-11-DesigningDataIntensiveApplications/assets/75432228/abbd7a6c-4893-4cd9-93fa-1c70560d9872)

위 그림은 사실 테이블이 2차원 테이블에만 외래 키를 가진다고 가정할 때 그릴 수 있는 2차원 테이블이다. 각각의 축은 날짜(date), 제품(product)이고 각 셀은 날짜와 제품을 결함한 모든 사실의 속성의 집계값(Ex: SUM)이다.  
이러한 데이터 큐브의 장점은 특정 질의를 효과적으로 미리 계산했기에 해당 질의를 수행할 때 매우 빠른 속도를 보여준다. 
하지만, 원시 데이터와 질의하는 것과 동일한 유연성을 제공하지 못한다는 단점도 가지고 있는데, 예를 들어 가격은 차원 중 하나가 아니기에 가격이 100달러 이상인 항목에서 발생한 판매량의 비율을 계산할 수는 없다.  그래서 데이터 웨어하우스 대부분은 가능한 많은 원시 데이터를 유지하려고 노력한다. 데이터 큐브의 집계 값은 특정 질의에 대한 성능 향상에만 사용한다. 
