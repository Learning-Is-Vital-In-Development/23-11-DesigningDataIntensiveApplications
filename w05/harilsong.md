# Ch3 저장소와 검색 (트랜잭션 처리나 분석?, 칼럼 지향 저장소)

## 트랜잭션 처리나 분석?

트랜잭션이라는 용어는 논리 단위 형태로서 읽기와 쓰기 그룹을 나타낸다.

> 트랜잭션이 반드시 ACID 속성을 가질 필요는 없다. 트랜잭션 처리는 일괄 처리 작업과 달리 클라이언트가 지연시간이 낮은 읽기와 쓰기를 가능하게 한다는 의미다.

- OLTP: Online Transaction Processing, 사용자 입력을 기반으로 데이터를 읽고 쓰는 작업을 수행하는 시스템
- OLAP: Online Analytical Processing, 데이터를 분석하는 시스템

데이터 분석은 트랜잭션과 접근 패턴이 매우 다르다. 보통 분석 질의는 사용자에게 원시 데이터를 반환하는 것이 아니라 많은 수의 레코드를 스캔해 레코드당 일부 칼럼만 읽어 집계 통계를 계산해야 한다.

| 특성       | OLTP                         | OLAP                                  |
|----------|------------------------------|---------------------------------------|
| 주요 읽기 패턴 | 질의당 적은 수의 레코드, 키 기준으로 가져옴    | 많은 레코드에 대한 집계                         |
| 주요 쓰기 패턴 | 임의 접근, 사용자 입력을 낮은 지연 시간으로 기록 | 대규모 불러오기(bulk import, ETL) 또는 이벤트 스트림 |
| 주요 사용처   | 웹 애플리케이션을 통한 최종 사용자/소비자      | 의사결정 지원을 위한 내부 분석가                    |
| 데이터 표현   | 데이터의 최신 상태(현재 시점)            | 시간이 지나며 일어난 이벤트 이력                    |
| 데이터셋 크기  | 기가바이트에서 테라바이트                | 테라바이트에서 페타바이트                         |

처음에는 두가지 모두 같은 데이터베이스에서 수행했지만 시간이 지나며 개별 데이터베이스에서 분석을 수행하는 경향을 보였다. 이 개별 데이터베이스를 **데이터 웨어하우스(data warehouse)** 라고 불렀다.

### 데이터 웨어하우징

OLTP 시스템은 대개 사업 운영에 대단히 중요하기 때문에 일반적으로 높은 가용성과 낮은 지연시간의 트랜잭션 처리를 기대한다. 그래서 데이터베이스 관리자는 OLTP 데이터베이스를 철저하게 보호하려 한다. 비즈니스
분석가가 OLTP 데이터베이스에 즉석 분석 질의(ad hoc analytic query)를 수행하면 데이터셋의 많은 부분을 스캔해 이와 동시에 실행되는 트랜잭션의 성능을 저하시킬 가능성이 있다.

반대로 데이터 웨어하우스는 분석가들이 OLTP 작업에 영향을 주지 않고 마음껏 질의할 수 있는 개별 데이터베이스다. 데이터 웨어하우스는 회사 내의 모든 다양한 OLTP 시스템에 있는 데이터의 읽기 전용 복사본이다.
데이터 웨어하우스로 데이터를 가져오는 이 과정을 **ETL(Extract-Transform-Load)** 이라 한다.

#### OLTP 데이터베이스와 데이터 웨어하우스의 차이점

각각 다른 질의패턴에 맞게 최적화됐기 때문에 시스템의 내부는 완전히 다르다.

### 분석용 스키마: 별 모양 스키마와 눈꽃 송이 모양 스키마

많은 데이터 웨어하우스는 별 모양 스키마로 알려진 상당히 정형화된 방식을 사용한다.

스키마의 중심에 소위 사실 테이블(fact table)이 있다.

## 칼럼 지향 저장소

사실 테이블은 칼럼이 보통 100개 이상이지만 일반적인 데이터 웨어하우스 질의는 한 번에 4개 또는 5개의 칼럼만 접근한다.

대부분의 OLTP 데이터베이스에서 저장소는 **로우 지향** 방식으로 데이터를 배치한다. 특정 칼럼을 가져오기 위해서는 모든 로우를 메모리로 적재한 다음 구문을 해석해 필요한 조건을 충족하지 않은 로우를 필터링해야 한다. 이 작업은 오랜 시간이 걸릴 수 있다.

**칼럼 지향 저장소**의 기본 개념은 간단하다. 모든 값을 하나의 로우에 함께 저장하지 않는 대신 각 칼럼별로 모든 값을 함께 저장한다. 각 칼럼을 개별 파일에 저장하면 질의에 사용되는 칼럼만 읽고 구분 분석하면 된다.

칼럼 지향 저장소 배치는 각 칼럼 파일에 포함된 로우가 모두 같은 순서인 점에 의존한다. 그러므로 로우의 전체 값을 다시 모으려면 개별 칼럼 파일의 23번째 항목을 가져온 다음 테이블의 23번째 로우 형태로 함께 모아 구성할 수 있다.

### 칼럼 압축

각 칼럼은 많은 값이 반복해서 나타나는 경향이 있다. 압축을 하기에 이런 경향성은 매우 좋은 징조다. 칼럼의 데이터에 따라 다양한 압축 기법을 사용할 수 있다. 그 중 한 가지 기법은 데이터 웨어하우스에서 특히 효과적인 **비트맵 부호화(bitmap encoding)** 이다.

#### 메모리 대역폭과 벡터화 처리

수백만 로우를 스캔해야 하는 데이터 웨어하우스 질의는 디스크로부터 메모리로 데이터를 가져오는 대역폭이 큰 병목이다.

칼럼 압축을 사용하면 같은 양의 L1 캐시에 칼럼의 더 많은 로우를 저장할 수 있다. AND 와 OR 같은 연산자는 압축된 칼럼 데이터 덩어리를 바로 연산할 수 있게 설계할 수 있다. 이런 기법을 **벡터화 처리(vectorized processing)** 라고 한다.

### 칼럼 저장소의 순서 정렬

각 칼럼을 독립적으로 정렬할 수는 없다. 칼럼 저장소는 칼럼이 어떤 항목이 동일한 로우에 속하는지를 순서로 판단하기 때문이다. 칼럼 별로 저장됐을지라도 데이터는 한번에 전체 로우를 정렬해야 한다.

첫 번째 칼럼에서 같은 값을 가진 로우들의 정렬 순서를 두 번째 칼럼에서 정할 수 있다. 이것은 특정 날짜 범위에 판매한 제품을 그룹화하거나 필터링하는 질의에 도움이 된다.

정렬된 순서의 또 다른 장점으로 칼럼 압축에 도움이 된다. 기본 정렬 칼럼에 고유 값을 많이 포함하지 않는다면 정렬한 후 기본 정렬 칼럼은 연속해서 같은 값이 길게 반복된다. 간단한 런 렝스 부호화는 수십억 개의 로우를 가진 테이블이라도 수 킬로바이트로 칼럼을 압축할 수 있다.

이런 압축 효과는 첫 번째 정렬 키에서 가장 강력하다.

#### 다양한 순서 정렬

다양한 질의는 서로 다른 정렬 순서의 도움을 받으므로 같은 데이터를 다양한 방식으로 정렬해 저장한다면 어떨까?

하나의 장비가 고장나도 데이터를 잃지 않으려면 데이터를 여러 장비에 복제해 두는 작업이 필요하다. 복제 데이터를 서로 다른 방식으로 정렬해서 저장하면 질의를 처리할 때 질의 패턴에 가장 적합한 버전을 사용할 수 있다.

이것은 로우 지향 저장에서 여러 2차 색인을 갖는 것과 약간 비슷하다. 하지만 로우 지향 저장은 한 곳(힙 파일이나 클러스터드 색인)에 모든 로우를 유지하고 2차 색인은 일치하는 로우를 가리키는 포인터만 포함한다는 점이 큰 차이점이다. 칼럼 저장에서는 일반적으로 데이터를 가리키는 포인터가 없고, 단지 값을 포함한 칼럼만 존재한다.

### 칼럼 지향 저장소에 쓰기

대부분의 데이터 분석가가 하는 작업은 읽기 전용이기 때문에 지금까지 살펴본 최적화는 합리적이다. 하지만 모두 쓰기를 어렵게 한다는 단점이 있다.

B 트리 사용과 같은 제자리 갱신 접근 방식은 압축된 칼럼에서는 불가능하다. 정렬된 테이블의 중간에 있는 로우에 삽입을 원하는 경우 모든 칼럼 파일을 재작성해야 한다.

다행히도 LSM 트리라는 좋은 해결책을 이미 설명했다. 모든 쓰기는 먼저 인메모리 저장소로 이동해 정렬된 구조에 추가하고 디스크에 쓸 준비를 한다. 인메모리 저장소가 로우 지향인지 칼럼 지향인지는 중요하지 않다. 충분한 쓰기를 모으면 디스크의 칼럼 파일에 병합하고 대량으로 새로운 파일에 기록한다.

질의는 디스크의 칼럼 데이터와 메모리의 최근 쓰기를 모두 조사해 두 가지를 결합해야 한다.

### 집계: 데이터 큐브와 구체화 뷰

- 구체화 집계(materialized aggregate)
- 구체화 뷰(materialized view)

데이터 웨어하우스 질의는 보통 SQL 에 count, max, sum, avg, min 같은 집계 함수를 포함한다. 동일한 집계를 많은 다양한 질의에서 사용한다면 매번 원시 데이터를 처리하는 일은 낭비다. 질의가 자주 사용하는 일부 카운트나 합을 캐시하는 건 어떨까?

이런 캐시를 만드는 한 가지 방법이 구체화 뷰(materialized view)다. 관계형 모델에서는 이런 캐시를 대개 표준 뷰로 정의한다.

구체화 뷰는 원본 데이터의 비정규화된 복사본이기 때문에, 원본 데이터를 변경하면 구체화 뷰를 갱신해야 한다. 하지만 이런 갱신으로 인한 쓰기는 비용이 비싸기 때문에 OLTP 데이터베이스에서는 구체화 뷰를 자주 사용하지 않는다. 데이터 웨어하우스에서는 읽기 비중이 크기 때문에 구체화 뷰를 사용하는 전략은 합리적이다.

데이터 큐브 또는 OLAP 큐브 라고 알려진 구체화 뷰는 일반화된 구체화 뷰의 특별 사례다.

구체화 데이터 큐브의 장점은 특정 질의를 효과적으로 미리 계산했기 때문에 해당 질의를 수행할 때 매우 빠르다. 예를 들어 어제 매장별 총 판매량을 알고 싶으면 백만 개 로우를 스캔할 필요 없이 적절한 차원을 따라 합계를 살펴보기만 하면 된다.

데이터 큐브의 단점은 원시 데이터에 질의하는 것과 동일한 유연성이 없다는 것이다. 데이터 큐브는 미리 계산된 집계만 제공할 뿐이다. 따라서 대부분의 데이터 웨어하우스는 가능한 한 많은 원시 데이터를 유지하려고 노력한다. 데이터 큐브와 같은 집계 값은 특정 질의에 대한 성능 향상에만 사용한다.

## 정리

- OLTP 시스템은 사용자 입력을 기반으로 데이터를 읽고 쓰는 작업을 수행하는 시스템이다. 대개 디스크 탐색이 병목이다.
- 데이터 웨어하우스와 유사한 분석 시스템은 주로 비즈니스 분석가가 사용한다. OLTP 시스템보다 훨씬 적은 수의 질의를 다루지만 각 질의는 대개 매우 다루기 어렵고 많은 데이터를 스캔해야 한다. 이 경우는 일반적으로 디스크 대역폭(탐색이 아닌)이 병목이다. 칼럼 지향 저장소는 이런 종류의 작업부하를 처리할 때 사용 가능한 솔루션이다.

OLTP 측면에서는

- 로그 구조화 관점(NoSQL)에서 파일에 추가와 오래된 파일의 삭제만 허용하고 한 번 쓰여진 파일은 절대 갱신하지 않는다.
- 제자리 갱신 관점(RDB)에서 덮어쓰기 할 수 있는 고정 크기 페이지의 셋으로 디스크를 다룬다. 이 관점에서는 B 트리가 가장 큰 예이다.
