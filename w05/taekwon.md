## 트랜잭션 처리나 분석

데이터베이스가 많은 여러 종류의 데이터(블로그, 게임 주소록)를 사용하기 시작했지만 기본적인 접근 패턴은 비즈니스 트랜잭션 처리와 유사하다. 보통 애플리케이션은 색인을 사용해 일부 키에 대한 적은 수의 레코드를 찾으며, 레코드는 사용자 입력을 기반으로 삽입 되거나 갱신된다. 이러한 대화식 애플리케이션을 `온라인 트랜잭션 처리(OLTP)`라고 한다.

그러나 데이터베이스를 데이터 분석에도 점점 더 많이 사용하기 사작하며, 원시 데이터를 반환하는 것이 아니라 많은 수의 레코드를 스캔해 레코드당 일부 칼럼만 읽어 집게, 통계를 계산해 내야한다.

이런 질의는 보통 비즈니스 분석가가 작성하며, 비즈니스 인텔리전스를 작성하는데 사용된다.

이런 데이터베이스 사용패턴을 트랜잭션 처리와 구별하기 위해 `온라인 분석처리(OLAP)`라고 부른다.

![image](https://github.com/akfls221/23-11-DesigningDataIntensiveApplications/assets/71249347/c097b527-2cbe-4f3e-9d44-564d59803bfe)

처음에는 두 시스템에 동일한 데이터베이스를 사용해 왔으며, 이와 관련해 SQL이 매우 유연한 모습을 보였다, 그럼에도 90년대 초반 회사들은 OLTP시스템을 분석 목적으로 사용하지 않고 개별 데이터베이스에서 분석을 수행하였으며, 이를 `데이터 웨어 하우스`라고 불렀다.

### 데이터 웨어하우징

데이터 웨어하우스는 분석가들이 OLTP작업에 영향을 주지 않고 마음껏 질의할 수 잇는 개별 데이터베이스다.  이는 회사 내의 모든 다양한 OLTP시스템에 있는 데이터의 읽기 전용 복사본이며, 주기적으로 데이터 덤프등을 통해 추출하고 분석 친화적인 스키마로 변환하여 정리한 후 적재한다.이 과정을 `ETL(Extract-Transform-Load)`라고 한다.

웨어하우스의 큰 장점은 분석 접근 패턴에 맞게 최적화 할 수 있다는 점이며, 앞의 색인 알고리즘은 OLAP에서는 별로 좋지 않은 편이다.

![image](https://github.com/akfls221/23-11-DesigningDataIntensiveApplications/assets/71249347/427296e0-ee60-41d0-81f6-47696eaf274b)

표면적으로는 OLTP 와 웨어하우스 모두 SQL 질의 인터페이스를 지원하기 때문에 비슷해 보이지만, 각각 매우 다른 질의 패턴에 최적화 되어있어 내부 시스템은 완전히 다르다.

### 분석용 스키마 : 별 모양 스키마, 눈꽃송이 스키마

![image](https://github.com/akfls221/23-11-DesigningDataIntensiveApplications/assets/71249347/92408a81-3690-4362-a689-60c1855d5795)

그림과 같이 스키마 중심에 사실 테이블이 있으며, 사실 테이블의 일부 칼럼은 제품이 판매된 가격과 공급자로 부터 구매한 비용등의 속성이다. 이러한 사실 테이블의 각 칼럼은 차원 테이블이라 부르는 다른 테이블을 가리키는 외래 키 참조다.

즉, 사실 테이블의 각 로우는 이벤트(고객의 제품 구매 등)를 나타내고 차원은 이벤트의 속성인 육하원칙을 나타낸다.

이처럼 테이블 관계가 시각화 될 때 사실 테이블이 가운데 있고 차원 테이블로 둘러싸고 있다는 사실에서 `별 모양 스키마란` 이름이 비롯되었으며, 이 템플릿의 변형을 `눈꽃송이 모양 스키마`라고 하며, 차원테이블이 하위차원으로 더 세분화 된다.

### 칼럼 지향 저장소

웨어 하우스의 사실 테이블은 보통 100개이상의 칼럼이지만, 일반적인 데이터 웨어하우스 질의는 한 번에 4개 또는 5개 칼럼만 접근한다. 이 질의는 많은 수의 로우에 접근하지만 몇개의 칼럼에만 접근할 필요가 있으며 다른 칼럼은 무시한다.

대부분의 OLTP 저장소는 `로우지향 방식`으로 데이터를 배치한다. 즉 테이블에서 한 로우의 모든 값은 서로 인접하게 저장된다. 이는 모든 로우를 메모리로 적재한 다음 구문을 해석해 필요한 조건을 충족하지 않는 로우를 필터링 해야 하며, 이는 오랜 시간이 걸릴 수 있다.

칼럼 지향 저장소의 기본 개념은 이와 반대로 각 `칼럼 별로 모든 값을 함께 저장`한다.

![image](https://github.com/akfls221/23-11-DesigningDataIntensiveApplications/assets/71249347/c45678a2-b910-4f07-870b-e709c5efe72a)

이러한 칼럼 지향 저장소 배치는 각 칼럼 파일에 포함된 로우가 모두 같은 순서인 점에 의존하며, 로우 전체 값을 다시 모으려면 개별 칼럼 파일의 23번째 항목을 가져온 다음 테이블의 23번째 로우 형태로 함께 모아 구성할 수 있다.

### 칼럼 압축

질의에 필요한 칼럼을 디스크에 읽어 적재하는 작업 외에도 데이터를 압축하면 디스크 처리량을 더 줄일 수 있다.

![image](https://github.com/akfls221/23-11-DesigningDataIntensiveApplications/assets/71249347/cbbcb9f3-40fa-4441-b9ce-e1d39221c192)

고유값(product_sk)하나가 하나의 비트맵이고 각 로우는 한 비트를 가지며, 만약 로우가 해당 값을 가지면 비트는 1이고 그렇지 않으면 0이다.

고유값이 매우 작으면 비트맵은 로우당 하나의 비트로 저장이 가능하지만, 고유값이 많을 경우 대부분의 비트맵은 0이 더많다.(이런 상황을 `희소(sparse)`하다고 한다.) 이런 경우 위 그림의 하단부에 있는 내용과 같이 `런 렝스 부호화`를 통해 칼럼의 부호화를 현저히 줄일 수 있다.

### 메모리 대역폭과 벡터화 처리

- 수백만 로우를 스캔해야 하는 데이터 웨어하우스 질의는 디스크로부터 메모리로 데이터를 가져오는 대역폭이 큰 병목이다.
- 디스크로부터 적재한 데이터 양 줄이기 외에도 칼럼 저장소 배치는 CPU 주기를 효율적으로 사용하기에 적합하다.
- 칼럼 압축을 통해 L1 캐시에 더 많은 로우를 저장하고, 비트 AND와 OR 같은 연산자를 통해 압축된 칼럼 데이터 덩어리를 많이 연산할 수 있습니다. 이를 `벡터화 처리`라고 한다.

### 칼럼 저장소의 순서정렬

칼럼 저장소에서는 로우가 저장되는 순서가 반드시 중요하지는 않다. 새로운 로우를 삽입하는 작업은 각 칼럼 파일에 덧붙여 추가하는 것을 의미하기 때문에 삽입된 순서로 저장하는 방식이 가장 쉽다. 하지만 이전 SS 테이블과 같이 순서를 도입해 이를 색인 메커니즘으로 사용이 가능하다.

다만 각 칼럼을 독립적으로 정렬할 경우 더 이상 칼럼의 어떤 항목이 동일한 로우에 속하는지 알 수 없기 때문에, 한 칼럼의 k번째 항목이 다른 칼럼의 k번째 항목과 같은 로우에 속한다는 것을 알고 있으니 로우를 재구성한다.

이러한 정렬은 특정 범위에 대한 제품을 그룹화 하거나 필터링하는 질의에 도움이 된다.

정렬된 순서의 또 다른 장점은 칼럼 압축에 도움이 되며, 기본 정렬 칼럼에 고유 값을 많이 포함하지 않는다면 정렬 후 기본 정렬 칼럼은 연속해서 같은 값이 연속해 반복된다. 간단한 런 렝스 부호화는 수십억 개의 로우를 가진 테이블이라도 수 킬로바이트로 압축이 가능하다.

이런 압축효과는 보통 첫 번째 정렬 키에서 가장 강력하며, 두 번째나 세 번째는 그보다 뒤섞여 있어 반복된 값이 그리 길지 않다.

### 다양한 순서 정렬

하나의 장비가 고장 나도 데이터를 잃지 않으려면 데이터를 여러 장비에 복재해 두는 작업이 필요하다. 이때 복제 데이터를 서로 다른 방식으로 정렬해서 저장하면 질의를 처리할 때 질의 패턴에 가장 적합한 버전을 사용할 수 있다.

칼럼 지향 저장에서 여러 정렬 순서를 갖는 것은 로우 지향 저장에서 2차 색인을 갖는 것과 비슷하나,

로우 지향은 한 곳(힙 파일, 클러스터드 색인)에 모든 로우를 유지하고, 2차 색인은 일치하는 로우를 가리키는 포인터만 포함한다는 점에서 다르다.  컬럼 포인터는 없고 단지 값을 포함한 칼럼만 존재한다.

### 칼럼 지향 저장소에 쓰기

칼럼 지향 저장소, 압축, 정렬은 모두 읽기 질의를 더 빠르게 하지만 쓰기를 어렵게 한다.

좋은 해결책으로 앞에서 봤던 LSM 트리 처럼 모든 쓰기는 먼저 인 메모리 저장소로 이동해 정렬된 구조에 추가하고 디스크에 쓸 준비를 한다. 이후 디스크의 칼럼 파일에 병합하고 대량으로 새로운 파일에 기록한다.

질의는 디스크의 칼럼 데이터와 메모리의 최근 쓰기를 모두 조사해 두 가지를 결합해야 한다.

### 집계: 데이터 큐브와 구체화 뷰

데이터 웨어하우스의 다른 측면으로 `구체화 집계` 가 있다. 동일한 집계를 많은 다양한 질의에서 사용한다면 매번 원시 데이터를 처리하는 일은 낭비다. 이에, 자주 사용하는 일부 카운트나, 합을 캐시하는 방식인 `구체화 뷰`가 있다.

관계형 데이터 모델에선 보통 이런 캐시를 `가상 뷰` 로 정의한다. 구체화 뷰는 디스크에 기록된 질의 결과의 실제 복사본이지만, 가상뷰는 단지 질의를 작성하는 단축키라는 차이가 있다.

참고)

![image](https://github.com/akfls221/23-11-DesigningDataIntensiveApplications/assets/71249347/3d909242-721d-4717-a9b4-7bec3eb866ce)

MSA 의 구체화 뷰 패턴으로 쿼리 테이블과 클라이언트 애플리케이션의 화면과 일대일 대응을 함으로써 복잡한 SQL join (여기에서는 여러 마이크로서비스의 조회) 을 처리하지 않고 데이터 조회를 할 수 있다

원본 데이터 변경시 구체화 뷰는 원본 데이터의 비정규화된 복사본으로 구체화 뷰를 갱신해야 하며, 이런 갱신으로 인한 쓰기 비용이 비싸 OLTP구조에선 자주 사용하지 않지만 데이터 웨어하우스의 경우 읽기의 비중이 높아 합리적인 선택이다.

일반화된 구체화 뷰의 특별한 사례로 `데이터 큐브` 또는 `OLAP` 큐브가 있다.

![image](https://github.com/akfls221/23-11-DesigningDataIntensiveApplications/assets/71249347/675f0eca-48ad-47ee-8c1b-ea0891199e36)

구체화 데이터 큐브의 장점은 특정 질의를 효과적으로 미리 계산했기 때문에 해당 질의를 수행할 때 매우 빠르다. 다만 원시 데이터에 질의하는 것과 동일한 유연성이  없다는 단점이 있어 데이터 큐브와 같은 집계 값은 특정 질의에 대한 성능 향상에만 사용한다.