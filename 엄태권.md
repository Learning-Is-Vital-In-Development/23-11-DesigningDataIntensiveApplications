# 03장. 저장소와 검색

## 서론

가장 기본적인 수준에서 데이터베이스는 두 가지 작업을 수행한다.

- 데이터를 받으면 데이터를 저장한다.
- 저장된 데이터를 요청하면 다시 데이터를 제공한다.

대게 개발자는 사용 가능한 여러 저장소 엔진 중에 구현하려는 애플리케이션에 적합한 엔진을 선택하는 작업이 필요하다.

좋은 성능을 내게끔 저장소 엔진을 조정하려면 저장소 엔진이 내부에서 수행되는 작업에 대한 대략적인 개념을 이해할 필요가 있다

## 색인

제일 간단한 set, get을 내포하고 있는 데이터베이스를 기준으로 생각해보자.

```sql
#여기선 동시성 제어, 오류처리, 디스크 공간 회수 등의 실제여러 문제는 배제하고 생각한다
db_set(){
	echo "$1,$2" >> database
}

db_get(){
	grep "^$1," database | sed -e "s/^$1,//" | tail -n 1
}
```

db_set() :  파일의 끝에 추가하므로 키를 여러번 갱신해도 값의 예전 버전을 덮어 쓰지 않는다.

db_get() : 매번 키를 찾을 때마다 데이터베이스의 파일을 처음부터 끝까지 스캔해야 한다. 또한 

레코드 수의 증가에 따라 검색 비용이 O(n)으로 증가한다.

set의 경우를 떠나 get메소드 호출시 매우 비효율적임을 알 수 있다.  특정 키의 값을 효율적으로 찾기 위해 다른 데이터 구조가 필요하며, 이를 색인 이라고 한다.

색인은 일반적으로 어떤 부가적인 메타데이터를 유지하며, 이 메타데이터는 이정표 역할로 원하는 데이터의 위치를 찾는 데 도움을 준다.

![image](https://github.com/akfls221/23-11-DesigningDataIntensiveApplications/assets/71249347/7e181f88-9c00-4602-b774-b0abbb5c1b06)

색인은 추가와 삭제를 허용하며, 이는 데이터베이스의 내용에 영향을 주진 않지만, 질의 성능에 영향을 준다. 무분별한 색인은 쓰기 속도를 떨어트린다.(데이터 쓰기시에 색인도 갱신해야 하기 때문)

색인을 잘 선택했다면, 읽기 질의 속도가 향상되지만, 무분별한 색인은 쓰기 속도를 떨어뜨리는 `trade-off 관계`이다.

## 로그 구조(log-structured)

### 해시 색인

키-값 데이터에 대한 색인으로 사전 타입(dictionary type)과 유사한 해시 맵으로 구현한 색인이다.

디스크 상의 데이터를 위한 인메모리 데이터 구조의 색인으로 생각하자.

단순히 파일에 추가하는 방식의 데이터 저장소를 구성한다는 가정하에 간단하게 아래와 같은 색인 전략을 쓸 수 있다.

![image](https://github.com/akfls221/23-11-DesigningDataIntensiveApplications/assets/71249347/d69b534b-0ad6-4583-9900-07b8295a4a98)

키를 디스크상의 데이터 파일의 바이트 오프셋에 매핑하여 해시 맵을 유지한다. 값을 조회하려면 해시 맵을 사용해 데이터 파일에서 오프셋을 찾아 위치를 구하고 값을 읽는다.

이 단순 방식은 해시 맵을 전부 메모리에 유지하는 것을 조건으로 고성능 읽기, 쓰기를 보장한다.

주로 고유 키 자체가 많지는 않지만 키당 쓰기 수가 많은 작업부하에 적합하다.

그러나 위 같은 log-structured의 형식으로 데이터를 저장하면 항상 파일에 추가만 하기때문에 결국 디스크 공간이 부족해지게 된다.

이를 해결하기 위해 데이터를 특정 크기의 `세그먼트`로 나누고, 주기적 `컴팩션`을통해 해결한다.

![image](https://github.com/akfls221/23-11-DesigningDataIntensiveApplications/assets/71249347/4839f619-7e2c-40aa-a79f-9049d574fbde)

중복된 키를 버리고 각 키의 최신 값만 유지하는 컴팩션과 세그먼트 병합을 동시에 수행해 해시 맵은 각 데이터의 오프셋과 키를 매핑하고, 각 오프셋이 가리키는 값은 최신 값임을 보장할 수 있다.

그러나 해시 색인도 간단한 만큼 단점 또한 확실히 존재한다.

- 해시 테이블은 메모리에 저장해야 하기 때문에 키가 너무 많으면 문제가 된다.
- 해시 맵은 범위 질의(range query)에 대해 효율적이지 않다.(모든 범위를 조회해야 한다.)

### SS테이블과 LSM트리

위의 해시 색인과 같은 제한이 없는 구조도 확인해 보자.

추가적으로 위에서 봤던 세그먼트 파일에서 간단한 변경 사항 한 가지를 적용해 보자.

- 모든 key-value 쌍을 키로 정렬한다.

이처럼 키로 정렬된 형식을 `정렬된 문자열 테이블(Sorted String Table)`이라고 한다.

SS 테이블은 해시 색인을 가진 로그 세그먼트보다 몇 가지 큰 장점이 있다.

- 세그먼트 병합이 보다 효율적이며, 세그먼트가 정렬된 상태에서 병합이 일어나기 때문에 merge-sort가 가능하다.
- 파일에서 특정 키를 찾기 위해 모든 키의 색인을 유지할 필요 없이 일부 키에 대한 색인만 있으면 충분하다.

![image](https://github.com/akfls221/23-11-DesigningDataIntensiveApplications/assets/71249347/519501a4-6525-4d07-9d5a-6f11872fb186)

### SS테이블 생성과 유지

그럼 유입되는 쓰기는 임의 순서대로 발생하는데 이를 키로 정렬하려면 어떻게 해야할까

디스크 상에 정렬된 구조를 유지하는 일은 가능하지만, 메모리에 유지하는 편이 훨씬 쉽다.

아래 와 같은 쓰기와 읽기 과정을 통해 해결이 가능하다.

- 쓰기가 들어오면 인메모리(멤테이블) 균형 트리 데이터 구조에 추가한다.
- 멤테이블이 임계값보다 커지면 SS테이블 파일로 디스크에 기록한다.(트리가 이미 정렬되어 있어 효율적으로 수행이 가능하다)
- 읽기 요청을 제공하기 위해 아래와 같은 순서를 거친다.
멤테이블 → 최신 세그먼트 → 두 번째 오래된 세그먼트 → 세 번째 오래된 세그먼트
- 백그라운드에서 세그먼트 파일을 합치고 덮어 쓰여지거나, 삭제된 값을 버리는 병홥과 컴팩션을 수행한다.

위와 같은 게획은 한 가지 문제가 있다. 만일 데이터베이스 고장으로 인해 디스크에 정상적으로 기록되지 않고 손실되는 데이터가 발행할 수 있다. 

이를 해결하기 위해 매번 쓰기를 즉시 추가할 수 있게 분리된 로그를 디스크 상에 유지하고, 멤테이블이 정상적으로 복원되면, 삭제 처리한다.

### LSM트리

위와 같이 SS 테이블의 형식으로 디스크에 key-value 데이터를 저장하는 색인 방식(정렬된 파일 병합과 컴팩션 원리를 기반으로 함.)을 `LSM 트리`라고 한다.

LSM 트리의 성능 최적화를 위해 아래와 같이 몇 가지의 방법이 있다.

- 블룸 필터(Bloom filter)
원소가 특정 집합에 속하는지 여부를 확률적으로 알아내는 자료구조로, 이를 활용해 키가 데이터베이스에 존재하지 않음을 확률적으로 알려줄 수 있으며, 없다고 판단되었을 경우는 실제로도 디스크에 없다는 것을 보장해 주기 때문에 디스크 읽기를 아낄 수 있다.
다만, 확률적으로 알려주는 점에서 데이터가 있다고 판단했지만 실제 없는 `False Positive`가 발생할 수 있다.
- 크기 계층(size-tiered) / 레벨 컴팩션(leveled compaction)
    
    
    |  | 사이즈 계층 컴팩션 | 레벨 컴팩션 |
    | --- | --- | --- |
    | 기준 | 데이터의 사이즈 (크기) | 레벨 (계층) |
    | 데이터 저장 방식 | 레벨별로 크기에 따라 분산 저장 | 레벨별로 데이터 개수나 크기를 유지하며 저장 |
    | 병합 대상 | 가장 낮은 레벨에서 상위 레벨로 병합 | 상위 레벨에서 하위 레벨로 순차적으로 병합 |
    | 컴팩션 목표 | 쓰기 작업에 효율적, 디스크 I/O 최소화, 쓰기 성능 개선 | 읽기 작업에 효율적, 읽기 성능 개선 |
    | 중복 데이터 제거 | 가장 낮은 레벨에서 중복 데이터 제거 | 상위 레벨에서 하위 레벨로 순차적으로 중복 데이터 제거 |
    | 주로 사용되는 곳 | LSM 트리의 기본 컴팩션 방식, 쓰기 성능에 초점 | LSM 트리의 읽기 성능 향상에 초점 |

## 페이지 지향(page-oriented)

### B트리

LSM트리도 보편화되고는 있지만 아직 가장 널리 사용되는 색인 구조는 B트리로 그 구조가 LSM 트리와는 상당히 다르다. 사실상 정렬된 key-value 구조를 유지하기 때문에 범위 질의에 효율적이라는 점 빼고는 모두 다르다.

B트리는 수 메가바이트 이상의 가변 크기의 세그먼트를 가진 LSM과 다르게 4KB 크기의 고정 크기 블록이나 페이지로 나누고 한 번에 하나의 페이지에 읽기 또는 쓰기를 한다.

각 페이지는 주소나 위치를 이용해 식별이 가능하며 이 방식으로 하나의 페이지가 다른 페이지를 참조할 수 있다

![image](https://github.com/akfls221/23-11-DesigningDataIntensiveApplications/assets/71249347/6f0ceb40-7754-42aa-8973-7b18276acdf7)

한 페이지는 B트리의 루트(root)로 지정되며, 하나의 페이지는 여러개의 키와 하위 페이지의 참조를 포함한다.(참고로 중간 노드를 브랜치 노드 라고 한다)

최종적으로 개별키(리프 페이지)를 포함하는 페이지에 도달하며, 각 키의 값을 포함하거나 값을 찾을 수있는 페이지의 참조를 포함한다.

B트리에 존재하는 키의 값을 갱신하려면, 키를 포함하고 있는 리프 페이지를 검색하고 페이지의 값을 바꾼 다음 페이지를 디스크에 다시 기록하는 과정이 필요하다. 새로운 키를 추가하기 위해선 새로운 키를 포함하는 범위의 페이지를 찾아 해당 페이지에 키와 값을 추가한다.

만일 여유 공간이 없다면 페이지 하나를 반쯤 채워진 페이지로 나누고, 상위 페이지가 새로운 키 범위의 하위 부분을 알 수 있도록 갱신한다.

![image](https://github.com/akfls221/23-11-DesigningDataIntensiveApplications/assets/71249347/963728b7-c081-43ee-8072-6cd29c997078)

이 알고리즘을 통해 트리의 균형을 유지하는것을 보장하며, n개의 키를 가진 B트리는 깊이가 항상 `O(log n)`이다. (보통 데이터베이스에선 3, 4정도의 깊이면 충분한 페이지 검색이 이루어진다.)

### 신뢰할 수 있는 B트리 만들기 / 최적화

- 데이터베이스가 고장 상황에서 스스로 복구할 수 있도록 일반적으로 디스크 상에 쓰기 전 로그(write-ahead log, `WAL`) 혹은 재 실행 로그(`redo log`)라고 하는 데이터 구조를 추가한다.
쓰기 전 로그는 트리 페이지에 변경된 내용을 적용하기 전에 모든 변경 사항을 기록하는 추가 전용 파일로 데이터베이스 고장 이후 복구 될 때 일관성  있는 상태로 B트리를 다시 복원하는데 사용된다.
- 일부 데이터베이스의 경우 WAL 대신 `쓰기 시 복사(copy-on-write)`를 사용하기도 하며, 변경된 페이지를 다른 위치에 기록하고 트리 상위 페이지의 새로운 버전을 만들어 새로운 위치를 가리키게 한다.
- 같은 자리의 페이지 갱신 시 다중 스레드가 동시에 B트리에 접근한다면 주의 깊게 동시성 제어가 필요하며, 이를 위해 `래치(가벼운 잠금(lock))`을 활용해 데이터 구조를 보호한다.
- 페이지에 전체 키를 저장하지 않고 키를 축약해 써 공간을 절약할 수 있으며, 이를 통해 트리 깊이 수준을 낮출 수 있다.
- 트리에 포인터를 추가하여 각 리프 페이지가 양쪽 형제 페이지에 대한 참조를 가져 상위 페이지로 다시 이동하지 않아도 순서대로 키를 스캔할 수 있게 한다.
- B트리 변형인 프랙탈 트리의 경우 디스크 찾기를 줄이기 위해 LSM 구조를 일부 빌렸다.

### B트리와 LSM비교

일반적으로 B트리가 LSM트리보다 구현 성숙도가 더 높지만 LSM트리의 성능 특성때문에 관심을 받고있다. 일반적으로 LSM트리의 경우 쓰기에서 더 빠른 반면 B트리는 읽기에서 더 빠르다고 여긴다.

그러나, 비교가 유효하려면 실제 필요한 작업부하로 시스템 테스트를 진행해야 한다.

- 쓰기증폭
 데이터베이스가 한 번의 쓰기 요청을 처리하는 동안 실제 디스크에는 여러 번의 쓰기를 야기하는 효과를 말하며, 이는 SSD처럼 블록 덮어쓰기 횟수가 제한적인 경우 중요한 관심사이다.
  B트리의 경우 쓰기 전 로그(WAL)과 트리 페이지에 기록 즉, 최소 두 번 기록이 필요하다.
  해당 페이지 내 몇 바이트만 바뀌어도 전체 페이지를 기록해야 하는 오버헤드도 있다.

하지만 LSM트리의 경우 여러 페이지를 매번 덮어쓰는 것이 아니라 순차적으로 컴팩션된 SS 테이블 파일을 쓰기 때문에 B트리보다 쓰기 증폭 면에선 더 효율적이다. 또한 이 차이는 순차 쓰기가 임의 쓰기보다 빠른 자기 디스크에서 중요하다.
- 성능
LSM트리의 경우 컴팩션 과정이 때로는 진행 중인 읽기와 쓰기의 성능에 영향을 준다.
한정적인 디스크 자원에서 비싼 컴팩션 연산이 끝날 때 까지 요청이 대기해야 하는 상황이 발생할 수 있다. 이에 반해 B트리의 성능은 LSM트리보다 예측하기가 쉽다.

LSM트리의 경우 초기 쓰기 와 백그라운드에서 수행되는 컴팩션 스레드가 한정된 디스크 영역을 공유해야 한다. 데이터베이스가 점검 커질수록 컴팩션을 위한 많은 대역폭이 필요하며, 결국 컴팩션이 유입 쓰기 속도를 따라갈 수 없다. 이는 읽기 성능의 저하를 불러오기 때문에, 이런 상황 감지를 위해 명시적 모니터링이 필요하다.
- 파편화
B트리의 경우 페이지를 나누거나 로우가 기존 페이지에 맞지 않을 때 페이지의 일부 공간은 사용하지 않게 되는등 디스크 공간 일부가 남는다. 그러나 LSM트리의 경우 페이지 지향 적이지 않고 주기적으로 파편화를 없애기 위해 SS테이블을 다시 기록하기 때문에 파편화가 훨씬 적다.
레벨 컴팩션을 사용하면 특히 더 그렇다.
- 트랜잭션 시맨틱
B트리의 경우 각 키가 색인의 한 곳에만 정확하게 존재한다는 장점이 있다. 반면 LSM의 경우 다른 세그먼트에 같은 키의 다중 복사본이 존재할 수 있다. 이런 측면 때문에 강력한 트랜잭션 시맨틱을 제공하는 데이터베이스에는 B트리가 훨씬 매력적이

## 기타 색인 구조키

지금 까지 살펴본 key-value 색인의 대표적인 예는 기본키(primary-key)에 대한 설명이다.

보통의 데이터베이스에선 `보조 색인(secondary index)`를 사용하는 방식도 매우 일반적이며, 관계형 데이터 베이스에선 `CREATE INDEX`를 통해 보조 색인 생성이 가능하며, 보통 효율적인 조인 수행에 결정적 역할을 한다.

보조색인은 키가 고유하지 않아 같은 키를 가진 많은 로우가 있을 수 있으며, 이는 색인의 각 값에 일치하는 로우 식별자 목록을 만들거나, 로우 식별자를 추가해 각 키를 고유하게 만드는 방법이 있다.

### 색인 안에 값 저장하기

색인에서 키는 질문의 실제 로우 거, 다른 곳에 저장된 로우를 가리키는 참조다.
후자의 경우 로우가 저장된 곳을 힙 파일 이라고 하며, 각 색인은 힙 파일에서 위치만 참조하고 실제 데이터는 일정한 곳에 유지한다.

색인에서 힙 파일로 다시 이동하는 일은 읽기 성능에 불이익이 너무 많기 때문에 어떤 상황에서는 색인 안에 바로 색인된 로우를 저장하는 편이 바람직하며, 이를 `클러스터드 색인` 이라고한다.

클러스터드 인덱스와 비클러스터드 인덱스 사이의 절충안을 `커버링 인덱스` 라고 하며, 이 색인은 색인 안에 테이블의 칼럼 일부를 저장하고, 인덱스만을 사용해 일부 질의에 응답이 가능하다.

![image](https://github.com/akfls221/23-11-DesigningDataIntensiveApplications/assets/71249347/bfef745b-1660-4b6d-b7d4-5142e8252d01)

위 사진은 MySQL의 InnoDB의 ClusterdIndex와 Non-clusterdIndex의 관계도이며, 기본적으로 `기본키는 언제나 클러스터드 인덱스`가 되고, `보조 색인의 리프노드는 클러스터드 인덱스를 참조`한다

### 다중 칼럼 색인

다중 칼럼 색인의 가장 일반적 유형은 결합 색인으로, 하나의 칼럼에 다른 칼럼을 추가하는 방식이다. 

예시로 (성, 이름)을 키로 전화번호를 값으로 하는 색인을 제공하는 구조에서, 특정 성을 가진 모든 사람을 찾거나 특정 성 이름 조합을 가진 모든 사람을 찾을 때도 해당 색인을 사용할 수 있다. 그러나, 특정 이름을 가진 모든 사람을 찾을 때는 필요가 없다.

특히 지리 공간 데이터에서 중요하게 사용되며, 여러 방법이 있겠지만 일반적으로 `R트리` 처럼 전문 공간 색인을 사용하여 효율적으로 응답이 가능하다

![image](https://github.com/akfls221/23-11-DesigningDataIntensiveApplications/assets/71249347/46d228e1-8773-46b5-8e3e-6ce2ea2e791e)


이때 `MBR(도형을 감싸는 최소 사각형)`을 통해 반경 계산이 가능하다.

### 전문 검색과 퍼지색인

전문 검색 엔진은 일반적으로 특정 단어를 검색시에 해당 단어의 동의어로 질의를 확정하고, 단어의 문법적 활용을 무시하고 동일한 문서에서 서로 인접해 나타난 단어를 검색하거나 언어학적으로 텍스트를 분석해 사용하는 등 다양한 기능을 제공한다.

### 모든 것을 메모리에 보관

지금까지 설명한 데이터 구조는 모두 디스크 한계에 대한 해결책이다. 디스크는 지속성 측면과 램보다 저렴한 가격이라는 장점이 있어, 다루기 어려움에도 불구하고 사용해왔다.

그러나 램이 점점 저렴해지며, 가격 논쟁은 무의미해지고, 데이터셋 대부분은 그다지 크지 않기 때문에 메모리에 전체를 보관하는 방식도 현실적이게 되었다.

지속성을 목표로하는 인메모리 데이터베이스의 경우 배터리 전원 공급 RAM과같은 특수 하드웨어를 사용하거나 디스크에 변경사항의 로그를 기록하거나, 디스크에 주기적인 스냅샷을 기록하는 등의 방법이 있다.

인메모리 데이터베이스의 경우 재 시작시에 특수 하드웨어를 사용하지 않는 경우 디스크나 네트워크를 통해 복제본을 다시 적재해야 한다

성능 외에도 인메모리 데이터베이스는 또 다른 영역으로 디스크 기반 색인으로 구현하기 어려운 데이터 모델을 제공한다. 예를 들어 레드스의 우선순위 큐와 SET 같은 다양한 데이터 구조를 제공한다.

## 트랜잭션 처리나 분석

데이터베이스가 많은 여러 종류의 데이터(블로그, 게임 주소록)를 사용하기 시작했지만 기본적인 접근 패턴은 비즈니스 트랜잭션 처리와 유사하다. 보통 애플리케이션은 색인을 사용해 일부 키에 대한 적은 수의 레코드를 찾으며, 레코드는 사용자 입력을 기반으로 삽입 되거나 갱신된다. 이러한 대화식 애플리케이션을 `온라인 트랜잭션 처리(OLTP)`라고 한다.

그러나 데이터베이스를 데이터 분석에도 점점 더 많이 사용하기 사작하며, 원시 데이터를 반환하는 것이 아니라 많은 수의 레코드를 스캔해 레코드당 일부 칼럼만 읽어 집게, 통계를 계산해 내야한다.

이런 질의는 보통 비즈니스 분석가가 작성하며, 비즈니스 인텔리전스를 작성하는데 사용된다.

이런 데이터베이스 사용패턴을 트랜잭션 처리와 구별하기 위해 `온라인 분석처리(OLAP)`라고 부른다.

![image](https://github.com/akfls221/23-11-DesigningDataIntensiveApplications/assets/71249347/938bb4d0-3877-44e7-8f30-959b2b54bcee)

처음에는 두 시스템에 동일한 데이터베이스를 사용해 왔으며, 이와 관련해 SQL이 매우 유연한 모습을 보였다, 그럼에도 90년대 초반 회사들은 OLTP시스템을 분석 목적으로 사용하지 않고 개별 데이터베이스에서 분석을 수행하였으며, 이를 `데이터 웨어 하우스`라고 불렀다.

### 데이터 웨어하우징

데이터 웨어하우스는 분석가들이 OLTP작업에 영향을 주지 않고 마음껏 질의할 수 잇는 개별 데이터베이스다.  이는 회사 내의 모든 다양한 OLTP시스템에 있는 데이터의 읽기 전용 복사본이며, 주기적으로 데이터 덤프등을 통해 추출하고 분석 친화적인 스키마로 변환하여 정리한 후 적재한다.이 과정을 `ETL(Extract-Transform-Load)`라고 한다.

웨어하우스의 큰 장점은 분석 접근 패턴에 맞게 최적화 할 수 있다는 점이며, 앞의 색인 알고리즘은 OLAP에서는 별로 좋지 않은 편이다.

![image](https://github.com/akfls221/23-11-DesigningDataIntensiveApplications/assets/71249347/10a739bb-8e6f-4677-96cf-e7991625cbd4)

표면적으로는 OLTP 와 웨어하우스 모두 SQL 질의 인터페이스를 지원하기 때문에 비슷해 보이지만, 각각 매우 다른 질의 패턴에 최적화 되어있어 내부 시스템은 완전히 다르다.

### 분석용 스키마 : 별 모양 스키마, 눈꽃송이 스키마

![image](https://github.com/akfls221/23-11-DesigningDataIntensiveApplications/assets/71249347/08a0e508-9fe1-49bd-b831-0a19aa566f0a)

그림과 같이 스키마 중심에 사실 테이블이 있으며, 사실 테이블의 일부 칼럼은 제품이 판매된 가격과 공급자로 부터 구매한 비용등의 속성이다. 이러한 사실 테이블의 각 칼럼은 차원 테이블이라 부르는 다른 테이블을 가리키는 외래 키 참조다.

즉, 사실 테이블의 각 로우는 이벤트(고객의 제품 구매 등)를 나타내고 차원은 이벤트의 속성인 육하원칙을 나타낸다.

이처럼 테이블 관계가 시각화 될 때 사실 테이블이 가운데 있고 차원 테이블로 둘러싸고 있다는 사실에서 `별 모양 스키마란` 이름이 비롯되었으며, 이 템플릿의 변형을 `눈꽃송이 모양 스키마`라고 하며, 차원테이블이 하위차원으로 더 세분화 된다.

### 칼럼 지향 저장소

웨어 하우스의 사실 테이블은 보통 100개이상의 칼럼이지만, 일반적인 데이터 웨어하우스 질의는 한 번에 4개 또는 5개 칼럼만 접근한다. 이 질의는 많은 수의 로우에 접근하지만 몇개의 칼럼에만 접근할 필요가 있으며 다른 칼럼은 무시한다.

대부분의 OLTP 저장소는 `로우지향 방식`으로 데이터를 배치한다. 즉 테이블에서 한 로우의 모든 값은 서로 인접하게 저장된다. 이는 모든 로우를 메모리로 적재한 다음 구문을 해석해 필요한 조건을 충족하지 않는 로우를 필터링 해야 하며, 이는 오랜 시간이 걸릴 수 있다.

칼럼 지향 저장소의 기본 개념은 이와 반대로 각 `칼럼 별로 모든 값을 함께 저장`한다.

![image](https://github.com/akfls221/23-11-DesigningDataIntensiveApplications/assets/71249347/0b52bf09-8826-45de-8928-38429dc57093)

이러한 칼럼 지향 저장소 배치는 각 칼럼 파일에 포함된 로우가 모두 같은 순서인 점에 의존하며, 로우 전체 값을 다시 모으려면 개별 칼럼 파일의 23번째 항목을 가져온 다음 테이블의 23번째 로우 형태로 함께 모아 구성할 수 있다.

### 칼럼 압축

질의에 필요한 칼럼을 디스크에 읽어 적재하는 작업 외에도 데이터를 압축하면 디스크 처리량을 더 줄일 수 있다.

![image](https://github.com/akfls221/23-11-DesigningDataIntensiveApplications/assets/71249347/1d36ff3f-68f3-4c0a-b646-e8c384bd6ec5)

고유값(product_sk)하나가 하나의 비트맵이고 각 로우는 한 비트를 가지며, 만약 로우가 해당 값을 가지면 비트는 1이고 그렇지 않으면 0이다.

고유값이 매우 작으면 비트맵은 로우당 하나의 비트로 저장이 가능하지만, 고유값이 많을 경우 대부분의 비트맵은 0이 더많다.(이런 상황을 `희소(sparse)`하다고 한다.) 이런 경우 위 그림의 하단부에 있는 내용과 같이 `런 렝스 부호화`를 통해 칼럼의 부호화를 현저히 줄일 수 있다.

### 메모리 대역폭과 벡터화 처리

- 수백만 로우를 스캔해야 하는 데이터 웨어하우스 질의는 디스크로부터 메모리로 데이터를 가져오는 대역폭이 큰 병목이다.
- 디스크로부터 적재한 데이터 양 줄이기 외에도 칼럼 저장소 배치는 CPU 주기를 효율적으로 사용하기에 적합하다.
- 칼럼 압축을 통해 L1 캐시에 더 많은 로우를 저장하고, 비트 AND와 OR 같은 연산자를 통해 압축된 칼럼 데이터 덩어리를 많이 연산할 수 있습니다. 이를 `벡터화 처리`라고 한다.

### 칼럼 저장소의 순서정렬

칼럼 저장소에서는 로우가 저장되는 순서가 반드시 중요하지는 않다. 새로운 로우를 삽입하는 작업은 각 칼럼 파일에 덧붙여 추가하는 것을 의미하기 때문에 삽입된 순서로 저장하는 방식이 가장 쉽다. 하지만 이전 SS 테이블과 같이 순서를 도입해 이를 색인 메커니즘으로 사용이 가능하다.

다만 각 칼럼을 독립적으로 정렬할 경우 더 이상 칼럼의 어떤 항목이 동일한 로우에 속하는지 알 수 없기 때문에, 한 칼럼의 k번째 항목이 다른 칼럼의 k번째 항목과 같은 로우에 속한다는 것을 알고 있으니 로우를 재구성한다.

이러한 정렬은 특정 범위에 대한 제품을 그룹화 하거나 필터링하는 질의에 도움이 된다.

정렬된 순서의 또 다른 장점은 칼럼 압축에 도움이 되며, 기본 정렬 칼럼에 고유 값을 많이 포함하지 않는다면 정렬 후 기본 정렬 칼럼은 연속해서 같은 값이 연속해 반복된다. 간단한 런 렝스 부호화는 수십억 개의 로우를 가진 테이블이라도 수 킬로바이트로 압축이 가능하다.

이런 압축효과는 보통 첫 번째 정렬 키에서 가장 강력하며, 두 번째나 세 번째는 그보다 뒤섞여 있어 반복된 값이 그리 길지 않다.

### 다양한 순서 정렬

하나의 장비가 고장 나도 데이터를 잃지 않으려면 데이터를 여러 장비에 복재해 두는 작업이 필요하다. 이때 복제 데이터를 서로 다른 방식으로 정렬해서 저장하면 질의를 처리할 때 질의 패턴에 가장 적합한 버전을 사용할 수 있다.

칼럼 지향 저장에서 여러 정렬 순서를 갖는 것은 로우 지향 저장에서 2차 색인을 갖는 것과 비슷하나,

로우 지향은 한 곳(힙 파일, 클러스터드 색인)에 모든 로우를 유지하고, 2차 색인은 일치하는 로우를 가리키는 포인터만 포함한다는 점에서 다르다.  컬럼 포인터는 없고 단지 값을 포함한 칼럼만 존재한다.

### 칼럼 지향 저장소에 쓰기

칼럼 지향 저장소, 압축, 정렬은 모두 읽기 질의를 더 빠르게 하지만 쓰기를 어렵게 한다.

좋은 해결책으로 앞에서 봤던 LSM 트리 처럼 모든 쓰기는 먼저 인 메모리 저장소로 이동해 정렬된 구조에 추가하고 디스크에 쓸 준비를 한다. 이후 디스크의 칼럼 파일에 병합하고 대량으로 새로운 파일에 기록한다. 

질의는 디스크의 칼럼 데이터와 메모리의 최근 쓰기를 모두 조사해 두 가지를 결합해야 한다.

### 집계: 데이터 큐브와 구체화 뷰

데이터 웨어하우스의 다른 측면으로 `구체화 집계` 가 있다. 동일한 집계를 많은 다양한 질의에서 사용한다면 매번 원시 데이터를 처리하는 일은 낭비다. 이에, 자주 사용하는 일부 카운트나, 합을 캐시하는 방식인 `구체화 뷰`가 있다.

관계형 데이터 모델에선 보통 이런 캐시를 `가상 뷰` 로 정의한다. 구체화 뷰는 디스크에 기록된 질의 결과의 실제 복사본이지만, 가상뷰는 단지 질의를 작성하는 단축키라는 차이가 있다.

참고)

![image](https://github.com/akfls221/23-11-DesigningDataIntensiveApplications/assets/71249347/d93e660c-18fd-4540-83f5-57a73a2eca02)

MSA 의 구체화 뷰 패턴으로 쿼리 테이블과 클라이언트 애플리케이션의 화면과 일대일 대응을 함으로써 복잡한 SQL join (여기에서는 여러 마이크로서비스의 조회) 을 처리하지 않고 데이터 조회를 할 수 있다

원본 데이터 변경시 구체화 뷰는 원본 데이터의 비정규화된 복사본으로 구체화 뷰를 갱신해야 하며, 이런 갱신으로 인한 쓰기 비용이 비싸 OLTP구조에선 자주 사용하지 않지만 데이터 웨어하우스의 경우 읽기의 비중이 높아 합리적인 선택이다.

일반화된 구체화 뷰의 특별한 사례로 `데이터 큐브` 또는 `OLAP` 큐브가 있다.

![Uploading image.png…]()

구체화 데이터 큐브의 장점은 특정 질의를 효과적으로 미리 계산했기 때문에 해당 질의를 수행할 때 매우 빠르다. 다만 원시 데이터에 질의하는 것과 동일한 유연성이  없다는 단점이 있어 데이터 큐브와 같은 집계 값은 특정 질의에 대한 성능 향상에만 사용한다.
