
# 10장 일괄 처리

한 사람의 영향도가 너무 큰 시스템은 성공하기 어렵다. 초기 설계가 완료되고 상당히 견고해지면 여러 사람이 다양한 관점을 가지고 각각 실험을 진행하면서 실제 테스트가 시작된다.
- 도널드 크누스

기존 1 ~ 2부에서는 시스템에 데이터를 요청하거나 지시를 보낸 후 잠시 뒤에 해당시스템으로 결과를 반환 받는 시스템을 다뤘다.
- 요청 -> 응답
- 질의 -> 결과

3가지 데이터 시스템

| 항목 | 내용 |
| --- | --- |
| 서비스(온라인 시스템) | 서비스는 클라이언트로부터 요청이나 지시가 올때까지 기다린다. 요청 하나가 들어오면 서비스는 가능한 빨리 요청을 처리해서 응답을 되돌려 보내려 한다. 응답 시간은 서비스 성능을 측정할ㄷ 때 중요한 지표다. 때론 가용성이 매우 중요한데 클라이언트가 서비스에 접근하지 못하면 사용자는 오류 메시지를 받을지 모른다. |
| 일괄 처리 시스템(오프라인 시스템) | 일괄 처리 시스템은 매우 큰 입력 데이터를 처리하는 작업을 수행하고 결과 데이터를 생산한다. 일괄 처리 작업은 수 분에서 때론 수 일이 걸리기 때문에 대개 사용자가 작업이 끝날 때까지 대기하지 않는다. 대신 대부분 하루에 한번 수행과 같이 반복적인 일정으로 수행한다. 일괄 처리 작업의 주요 성능 지표로는 처리량이 대표적인다. 처리량은 입력 데이터 중 특정 크기만큼 처리할 때 걸리는 시간으로 나타낸다. 이번 장에서는 일괄 처리 시스템에 대해 논의한다. |
| 스트림 처리 시스템(준실시간 시스템) | 스트림 처리는 온라인가ㅗ 오프라인/일괄 처리 사이의 어딘가에 있기 때문에 때론 준실시간 처리라 불린다. 스트림 처리 시스템은 일괄 처리 시스템과 마찬가지로 요청에 대해 응답하지 않으며 입력 데이터를 소비하고 출력 데이터를 생산한다. 그러나 일괄 처리 작업은 정해진 크기의 입력 데이터를 대상으로 작동하지만 스트림 처리는 입력 이벤트가 발생한 후 직후 바로 작동한다. 이런 차이 때문에 스트림 처리 시스템은 같은 작업을 하는 일괄 처리 시스템보다 지연 시간이 낮다. 스트림 처리는 일괄 처리를 기반으로 하므로 11장에서 다룬다. |

이번 장에서 살펴보겠지만 **일괄 처리는 신뢰할 수 있고 확장 가능하며 유지보수하기 쉬운 애플리케이션을 구축하는 데 매우 중요한 구성요소**다.

예를 들면 2004년에 발표된 일괄 처리 알고리즘인 MapReduce는 다소 과한 면이 있지만 "구글을 대규모로 확장 가능하게 만든 알고리즘"으로 불렸다.

맵리듀스는 이전에 데이터 웨어하우스용으로 개발했던 병렬 처리 시스템보다 상당히 저수준 프로그래밍 모델이다. 그러나 **범용 하드웨어만을 사용해 처리한 데이터 규모 면에서 상당히 진보**했다. 지금은 **맵리듀스의 중요성이 떨어지고 있지만** 왜 **일괄 처리가 유용한지 명확하게 그림을 그려주기 때문에 맵리듀스를 이해할 가치는 충분**하다.


## 10.1. 유닉스 도구로 일괄 처리하기

- 유닉스 프로그램과 파이프로 데이터 처리하기 

### 10.1.1. 단순 로그 분석

```bash
cat /var/log/nginx/access.log |
	awk '{print $7}' |
	sort |
	uniq -c |
	sort -r -n |
	head -n 5
 27 /
  9 400
  4 /favicon.ico
  2 google.com:443
  1 ssl-judge2.api.proxyscrape.com:443

cat /var/log/nginx/access.log |
> awk '{print $1}' |
> sort |
> uniq -c |
> sort -r -n |
> head -n 5
      5 185.142.236.43
      4 31.7.58.42
      4 220.231.101.34
      4 167.94.138.52
      3 185.224.128.187
```

유닉스 도구를 사용해 위처럼 웹 로그를 분석할 수 있다.

#### 10.1.1.1. 연쇄 명령 대 맞춤형 프로그램
- 프로그래밍 언어를 사용해 위와 같은 작업을 하는 간단한 프로그램을 작성할 수도 있다.
	- 책에서는 Ruby로
#### 10.1.1.2. 정렬 대 인메모리 집계
- 위의 루비 스크립트는 URL 해시  테이블을 메모리에 유지한다.
- 유닉스 파이프라인 예제에는 이런 해시 테이블이 없다.
- 어떤 접근법이 더 좋을지는 다른 URL이 얼마나 되느냐에 따라 다르다.
	- 작업 세트가 충분히 작다면 인메모리 해시 테이블도 잘 동작한다.
	- 하지만 허용 메모리보다 작업 세트가 크다면 정렬 접근법을 사용하는 것이 좋다.
		- 데이터 청크를 메모리에서 정렬하고 청크를 세그먼트 파일로 디스크에 저장한다.
		- 그 다음 각각 정렬된 세그먼트 파일 여러 개를 한 개의 큰 정렬 파일로 병합한다.
		- GNU Coreutils에 포함된 sort 유틸리티는 메모리보다 큰 데이터셋을 자동으로 디스크로 보내고 자동으로 여러 CPU 코어에서 병렬로 정렬한다. (메모리 부족 없이 큰 데이터셋으로 확장 가능함)

### 10.1.2. 유닉스 철학

바로 앞의 예제와 같이 연쇄 명령을 사용해 쉽게 로그 파일을 분석할 수 있었던 것은 우연이 아니다. 
```
유닉스 파이프를 발명한 더그 맥일로이는 1964년에 유닉스 파이프를 이와 같이 설명했다: 다른 방법으로 데이터 처리가 필요할 때 정원 호스와 같이 여러 다른 프로그램을 연결하는 방법이 필요하다. 이것은 I/O 방식이기도 하다. 
- 데이터중심 애플리케이션 설계 (390page)
```

1978년 기술된 유닉스 철학
1. 각 프로그램이 한 가지 일만 하도록 작성하라. 새 작업을 하려면 기존 프로그램을 고쳐 새로운 '기능'을 추가해 프로그램을 복잡하게 만들기보다는 새로운 프로그램을 작성하라
2. 모든 프로그램의 출력은 아직 알려지지 않은 다른 프로그램의 입력으로 쓰일 수 있다고 생각하라. 불필요한 정보로 출력이 너저분해서는 안 된다. 입력 형식으로 엄격하게 열을 맞춘다거나 이진 형태를 사용하지 마라. 대화형 입력을 고집하지 마라.
3. 소프트웨어를 빠르게 써볼 수 있게 설계하고 구축하라. 심지어 운영체제도 마찬가지다. 수 주 안에 끝내는 것이 이상적이다. 거슬리는 부분은 과감히 버리고 새로 구축하라.
4. 프로그래밍 작업을 줄이려면 미숙한 도움보단 도구를 사용하라. 도구를 빌드하기 위해 한참 둘러가야 하고 게다가 사용 후 바로 버린다고 할지라도 도구를 써라.

자동화, 빠른 프로토타이핑, 증분 반복, 실험 친화, 큰 프로젝트를 청크로 나누어 처리하기와 같은 방법은 오늘날의 애자일 및 DevOps 운동과 매우 흡사하고 놀랍게도 40년이 지났지만 거의 바뀌지 않았다.

sort는 한 가지 일을 잘 해내는 프로그램의 훌륭한 예다. sort의 구현은 대부분의 프로그래밍 언어에 포함된 표준 라이브러리보다 확실히 뛰어나다. 표준 라이브러리는 처리하는 데이터를 디스크로 흘려보내지 않고, 다중 스레드를 쓰는 게 분명히 이득이 상황에서도 다중 스레드를 사용하지 않는다.

bash 같은 유닉스 셸을 사용하면 작은 프로그램들을 가지고 놀랄 만큼 강력한 데이터 처리 작업을 쉽게 구성할 수 있다.

#### 10.1.2.1. 동일 인터페이스

어떤 프로그램의 출력을 다른 프로그램의 입력으로 쓰고자 한다면 이들 프로그램은 같은 데이터 형식을 사용해야 한다. 즉 호환 가능한 인터페이스를 써야 한다. 
유닉스에서 인터페이스는 파일(좀 더 정확히는 파일 디스크립터)이다. 파일은 단지 순서대로 정렬된 바이트의 연속이다. 파일은 이처럼 단순해서 같은 인터페이스로 파일시스템의 실제 파일, 프로세스 간의 통신 채널(유닉스 소켓, 표준입력, 표준 출력), 장치 드라이버, TCP 연결을 나타내는 소켓 등 다른 여러 가지 것을 표현할 수 있다.

많은 유닉스 프로그램은 연속된 바이트를 아스키 텍스트로 취급한다.
로그 분석 예제에서 바로 이점을 활용해 awk, sort, uniq, head 프로그램은 입력 파일을 \n(개행문자 아스키 0x0A) 문자로 분리된 레코드로 다룬다. \n가 선택된 이유는 딱히 없다. 애초에 이런 목적으로 사용하려고 만든 0x1E가 아스키 레코드 분리자로 훨씬 좋은 선택일지도 모른다. 어쨌든 같은 레코드 분리자를 사용해 표준화했기 때문에 이 모든 프로그램이 상호 운영 가능하다.
각 레코드를 파싱하는 건 더욱 애매하다. 유닉스 도구는 대개 한 줄을 공백이나 탭 문자로 분리해 필드로 만든다. 하지만 CSV, 파이프 등의 다른 부호화 방법도 사용한다.
동일 인터페이스로 아스키 텍스트는 큰 문제가 없지만 그다지 깔끔하지 않다. 로그 분석 예제는 URL을 추출하려고 {print $7}을 사용했다. 하지만 가독성이 좋지 않다. 이상적으로 하자면 {print $request_url}이나 비슷한 형태일 것이다.
완벽하지도 않음에도 심지어 수십 년이 지났어도 유닉스의 동일 인터페이스는 여전히 대단하고, 오늘날 유닉스 도구처럼 매끄럽게 협동하는 프로그램이 있다는 건 정상이 아니라 예외적이다.

#### 10.1.2.2. 로직과 연결의 분리

유닉스 도구의 다른 특징으로 표준 입력(stdin)과 표준 출력(stdout)을 사용한다는 점을 들 수 있다. 프로그램을 실행하고 아무것도 설정하지 않는다면 stdin은 키보드로부터 들어오고 stdout은 화면으로 출력한다. 혹은 파일에서 입력을 가져와 다른 파일로 출력을 재전송할 수도 있다. **파이프는 한 프로세스의 stdout을 다른 프로세스의 stdin과 연결한다.** 
이때 중간 데이터를 디스크에 쓰지 않고 작은 인메모리 버퍼를 사용해 프로세스 간 데이터를 전송한다. (필요한 경우라면 프로그램에서 직접 파일을 읽고 쓸 수도 있지만 프로그램이 특정 파일의 경로가 어디에 있는지 신경 쓰지 않고 stdin과 stdout만으로 처리하고 싶다면 유닉스 접근법이 가장 좋다.)
- 프로그램은 입력이 어디서부터 들어오는지 출력이 어디로 나가는지 신경 쓰거나 알 필요가 없어진다.
- 프로그램에서 입출력을 연결하는 부분을 분리하면 작은 도구로부터 큰 시스템을 구성하기 훨씬 수월하다.
- 느슨한 결합, 지연 바인딘, 제어 반전이라고도 한다.

장점: 연쇄 명령어의 중간에 IP 주소를 국가 코드로 바꾸는 코드 등을 끼워 넣기 쉽다.
단점: 프로그램이 여러 개의 입력을 받거나 여러 개의 출력이 필요할 때는 까다롭다, 프로그램의 출력을 파이프를 이용해 네트워크와 연결하지는 못한다. 

#### 10.1.2.3. 투명성과 실험

유닉스 도구가 성공적인 이유 중 하나는 진행 사항을 파악하기가 상당히 쉽기 때문이다.
- 유닉스 명령에 들어가는 **입력 파일은 일반적으로 불변으로 처리**된다. (다양한 명령행 옵션을 사용해가며 명령을 수행해도 입력 파일 변화가 없다)
- 어느 시점이든 파이프라인을 중단하고 출력을 파이프를 통해 `less` 로 보내 원하는 형태의 출력이 나오는지 확인할 수 있다.
```bash
cat /var/log/nginx/access.log |
> awk '{print $1}' |
> sort |
> uniq -c |
> sort -r -n |
> head -n 5 |
> less
```
- 특정 **파이프라인 단계의 출력을 파일에 쓰고 그 파일을 다음 단계의 입력으로 사용**할 수 있다. 이렇게 하면 **전체 파이프라인을 다시 시작하지 않고 다음 단계부터 재시작**할 수 있다. (파이프라인 일부가 실패하여 재시작할 때 또는, 한 데이터셋을 중복 사용하는 로직이 있을 때 유용)

- RDB의 질의 최적화 두고와 비교하면 불친절하지만 유용하고 프로토타이핑 하기에 좋다.
- 하지만 **단일 장비에서만 실행된다는게 단점이고 바로 이 점이 하둡 같은 도구가 필요한** 이유다.

## 10.2. 맵리듀스와 분산 파일 시스템

맵리듀스는 **유닉스 도구와 비슷한 면이 있지만 수천 대의 장비로 분산해서 실행**이 가능하다는 점에서 차이가 있다. 맵리듀스는 유닉스 도구와 마찬가지로 상당히 불친절하고 무차별 대입 방법이지만 대신 엄청나게 효율적인 도구다. **단일 맵리듀스 작업은 하나 이상의 입력을 받아 하나 이상의 출력을 만들어 낸다는 점에서 단일 유닉스 프로세스와 유사**하다.

유닉스 도구와 마찬가지로 맵리듀스 작업은 입력을 수정하지 않는다. (출력만 만들뿐)
출력 파일은 순차적으로 한 번만 쓰여지고 파일에 이미 쓰여진 부분은 고치지 않는다.

유닉스 도구는 stdin, stdout을 입력과 출력으로 사용하는데 맵리듀스 작업은 분산 파일 시스템상의 파일을 입력과 출력으로 사용한다. 하둡 맵리듀스 구현에서 이 파일 시스템은 HDFS(Hadoop, Distiributed File System)라고 하는데 GFS를 재구현한 오픈소스다.

HDFS 외에도 GlusterFS, QFS 등 다양한 분산 파일 시스템이 있고 AWS S3, Azure Blob, 오픈스택 스위프트 같은 객체 저장소도 여러면에서 유사하다.

HDFS는 비공유 원칙을 기반으로하는데 NAS, SAN 아키텍처에서 사용하는 공유 디스크 방식과는 반대다. 공유 디스크 저장소는 중앙 집중 저장 장치를 사용하는 데 맞춤형 하드웨어나 특별한 네트워크 인프라를 사용하기도 한다. 하지만 비공유 방식은 특별한 하드웨어가 필요없다. 일반적인 데이터센터 네트워크에 연결된 컴퓨터면 충분하다.

HDFS는 각 장비에서 실행되는 데몬 프로세스로 구성되고 다른 노드가 해당 장이에 저장된 파일에 접근 가능하게끔 네트워크 서비스를 제공한다. HDFS는 범용 하드웨어와 오픈소스 소프트웨어를 사용하기 때문에 확장성이 뛰어나 수만대의 장비를 묶어 실행하기도 한다. 

- 매퍼가 키를 기준으로 데이터를 파티셔닝해서 리듀서에게 전달함
- 특정 키에 데이터가 쏠려 있다면 특정 리듀서에게 작업이 몰릴 수 있기에 대책이 필요함
- 여러번의 맵-리듀스 작업이 반복되어 워크플로가 만들어질 수 있음
- 각 맵-리듀스 작업별로 데이터 파일이 디스크에 저장됨
### 10.2.1. 맵리듀스 작업 실행하기

맵리듀스는 HDFS 같은 분산 파일 시스템 위에서 대용량 데이터셋을 처리하는 코드를 작성하는 프로그래밍 프레임워크다. 

1. 입력 파일을 읽는다. 레코드로 쪼갠다. 웹 서버 로그 예제에서 로그의 각 줄이 레코드가 된다. 즉 레코드 분리자로 \n을 사용한다.
2. 각 입력 레코드마다 매퍼 함수를 호출해 키와 값을 추출한다. 예제에서 매퍼 함수는 awk '{print $7}'인데 URL($7)을 키로 추출하고 값은 빈 값으로 한다.
3. 키를 기준으로 키-값 쌍을 모두 정렬한다. 이 과정은 로그 예제에서 첫 번째 sort명령에 해당한다.
4. 정렬된 키-값 쌍 전체를 대상으로 리듀스 함수를 호출한다. 같은 키가 여러 번 등장했다면 정렬 과정에서 해당 키-값 쌍은 서로 인접한다. 그래서 같은 키를 가지는 값들을 따로 메모리 상에 유지하지 않고도 쉽게 결합할 수 있다. 예제에서 uniq -c 명령에 해당한다. 이 명령은 키가 같으면서 인접한 레코드의 수를 센다.

맵리듀스 작업 하나는 4가지 단계로 수행한다. 2단계(맵)과 4단계(리듀스)는 사용자가 직접 작성한 데이터 처리 코드다. 1단계는 파일을 나누어 레코드를 만드는 데 입력 형식 파서를 쓴다. 3단계는 정렬 단계로 맵리듀스에 내재하는 단계라서 직접 작성할 필요가 없다. 매퍼의 출력은 리듀스로 들어가기 전에 이미 정렬됐기 때문이다.

맵리듀스 작업을 생성하려면 다음과 같이 동작하는 **매퍼와 리듀서라는 두 가지 콜백 함수를 구현**해야 한다.

매퍼(Mapper)
- 매퍼는 모든 입력 레코드마다 한 번씩만 호출된다. 매퍼는 입력 레코드로부터 키와 값을 추출하는 작업이다. 각 입력으로부터 생성하는 키-값 쌍은 빈 쌍을 포함해 원하는 만큼 생성 가능하다. 매퍼는 입력 레코드로부터 다음 레코드까지 상태를 유지하지 않기 때문에 각 레코드를 독립적으로 처리한다.
리듀서(Reducer)
- 맵리듀스 프로엠워크는 매퍼가 생산한 키-값 쌍을 받아 같은 키를 가진 레코드를 모으고 해당 값의 집합을 반복해 리듀서 함수를 호출한다. 리듀서는 출력 코드를 생산한다. 출력 레코드의 한 예로 동일한 URL이 출현한 횟수가 있다.
#### 10.2.1.1. 맵리듀스의 분산 실행

유닉스 명령어 파이프라인과 맵리듀스의 가창 큰 차이점은 맵리듀스는 병렬로 수행하는 코드를 직접 작성하지 않고도 여러 장비에서 동시에 처리 가능하다는 점이다.
매퍼와 리듀서는 한 번에 하나의 레코드만 처리하고 입력이 어디서 오는지 출력이 어디로 가는지 신경 쓰지 않는다. 맵리듀스 프레임워크가 장비 간에 데이터가 이동하는 복잡한 부분을 처리하기 때문이다.

분산 연산에서 매퍼와 리듀서로 표준 유닉스 도구를 사용하는 것도 가능하다. 하지만 대개는 일반적인 프로그래밍 언어로 함수를 작성한다. 하둡 맵리듀스에서 매퍼와 리듀스는 각각 특정 인터페이스를 구현한 자바 클래스다. 몽고와 카우치는 매퍼와 리듀스가 자바스크립트 함수다.

![[Pasted image 20231204224329.png]]

- m1~m3: 매퍼가 읽어오는 파일 블록 (입력)
- r1~r3: 리듀서가 저장하는 파일 (출력)

대부분의 경우 맵 태스크에서 실행될 애플리케이션 코드는 작업이 할당된 장비에 아직 존재하지 않기 때문에 
1. 맵리듀스 프레임워크가 작업을 수행하기에 적절한 장비로 코드(Java를 예로들면 JAR)를 복사한다.
2. 복사가 끝나면 장비에서 매퍼 태스크가 시작된다.
3. 입력 파일을 읽기 시작하면 입력 파일에서 한 번에 하나씩 읽어 매포 콜백 함수로 전달한다. 매퍼의 출력은 키-값 쌍으로 구성된다.

리듀서 측 연산도 파티셔닝 된다. 맵 태스크 수는 입력 파일의 블록 수로 결정되지만 리듀스 태스크 수는 사용자가 정한다. 즉 맵 태스크 수와 리듀스 태스크 수는 다를 수 있다.
맵리듀스 프레임워크는 같은 키를 가진 모든 키-값 쌓을 같은 리듀서에서 처리하는 것을 보장하는데, 특정 키-값 쌍이 어느 리듀스 태스크에서 수행될지 결정하기 위해서 키의 해시값을 사용한다.

키-값 쌍은 반즈시 정렬돼야 하지만대개 데이터셋이 매우 크기 때문에 일반적인 정렬 알고리즘으로 한 장비에서 모두 정렬하기는 쉽지 않다.그렇기 때문에 단계를 나누어 정렬을 수행한다.
1. 먼저 각 맵 태스크는 키의 해시값을 기반으로 출력을 리듀서로 파티셔닝한다.
2. 그리고 각 파티션을 매퍼의 로컬 디스크에 정렬된 파일로 기록한다.
3. 매퍼가 입력 파일을 읽어서 정렬된 출력 파일을 기록하기를 완료하면 맵리듀스 스케줄러는 그 매퍼에서 출력 파일을 가져올 수 있다고 리듀서에게 알려준다.
4. 리듀서는 각 매퍼와 연결해서 리듀서가 담당하는 파티션에 해당하는 정렬된 키-값 쌍 파일을 다운로드한다.
5. 리듀서를 기준으로 파티셔닝하고 정렬할 뒤 매퍼로부터 데이터 파티션을 복사하는 과정을 셔플(Shuffle)이라고 한다. (셔플이라면 카드를 섞는 것이라 생각하지 쉽지만 맵리듀스에서 셔플은 임의로 섞지 않는다)
6. 리듀스 태스크는 매퍼로부터 파일을 가져와 정렬된 순서를 유지하면서 병합한다. (결과적으로 리듀서는 여러 블록의 데이터가 정렬된 값을 입력값으로 받음)

#### 10.2.1.2. 맵리듀스 워크플로

맵리듀스 작업 하나로 해결할 수 있는 문제의 범위는 제한적이다.
로그 분석 예제에서 단일 맵리듀스로 작업으로 URL당 페이지뷰 수를 구할 수 있지만 가장 인기 있는 URL을 구할 수는 없다. 그러기 위해서는 추가로 정렬 작업이 필요하다.

따라서 맵리듀스 작업을 연결해 워크플로(Workflow)로 구성하는 방식은 꽤 일반적이다. 맵리듀스 작업 하나의 출력을 다른 맵리듀스 작업의 입력으로 사용하는 식이다.

하둡 맵리듀스 프레임워크는 워크플로를 직접 제공하지 않기 때문에 맵리듀스 작업은 디렉토리 이름을 통해 암묵적으로 연결된다. 첫번 째 작업이 HDFS상에 지정된 디렉토리에 파일을 저장하게하고(출력) 두번째 작업은 해당 디렉토리의 파일을 입력으로 사용한다.
첫번째, 두번째 작업은 완전히 독립적이다.

연결된 맵리듀스 작업은 유닉스 명령 파이프라인(소량의 메모리 버퍼를 사용해 한 프로세스의 출력이 다른 프로세스의 입력으로 전달되는 방식)과 달리 각 명령의 출력을 임시 파일에 쓰고 다음 명령이 그 임시 파일로부터 입력을 읽는 방식이다. 이 설계는 장단점이 있는데 419Page '중간 상태 구체화'에서 다시 논의하다.

일괄 처리 작업의 출력은 작업이 성공적으로 끝났을 때만 유효하다. 그렇기 때문에 워크플로 상에서 해당 작업의 입력 디렉토리를 생성하는 선행 작업이 완전히 끝나야만 다음 작업을 시작할 수 있다. 하룹 맵리듀스 작업 간 수행 의존선을 관리하기 위해 다양한 스케줄러가 개발 됐다. (우지, 아즈카반, 루이지, 에어플로우, 핀볼 등)

- 이런 스케줄러에는 일괄 처리 집합을 유지보수할 때 유용한 관리기능이 있다. 추천 시스템을 구축하는 데 사용하는 워크플로는 50~100개가 일반적이다.

### 10.2.2. 리듀스 사이드 조인과 그룹화

### 10.2.3. 사용자 활동 이벤트 분석 예제

#### 10.2.3.1. 정렬 병합 조인

- 사용자 데이터베이스
- 사용자 활동 매퍼

#### 10.2.3.2. 같은 곳으로 연관된 데이터 가져오기
#### 10.2.3.3. 같은 곳으로 연관된 데이터 가져오기

#### 10.2.3.4. 그룹화

#### 10.2.3.5. 쏠림 다루기

### 10.2.4. 맵 사이드 조인

#### 10.2.4.1. 브로드캐스트 해시 조인
#### 10.2.4.2. 파티션 해시 조인

#### 10.2.4.3. 맵 사이드 병합 조인

#### 10.2.4.4. 맵 사이드 조인을 사용하는 맵리듀스 워크플로

### 10.2.5. 일괄 처리 워크플로의 출력

#### 10.2.5.1. 검색 색인 구축

#### 10.2.5.2. 일괄 처리의 출력으로 키-값을 저장

#### 10.2.5.3. 일괄 처리 출력에 관한 철학

### 10.2.6. 하둡과 분산 데이터베이스의 비교

#### 10.2.6.1. 저장소의 다양성

#### 10.2.6.2. 처리 모델의 다양성

#### 10.2.6.3. 빈번하게 발생하는 결함을 줄이는 설계

- 맵리듀스와 MPP 데이터베이스를 비교할 때 설계 방식에서 큰 차이점 두가지가 두드러진다.
- 결함을 다루는 방식과 메모리 및 디스크를 사용하는 방식이 그 두 가지다.

일괄 처리 작업은 사실상 "식탁 아래에서 조각들을 모은다", 우선순위가 높은 프로세스가 필요한 작업을 수행한 뒤에 남은 자원을 사용해 연산을 수행한다.


## 10.3. 맵리듀스를 넘어

### 10.3.1. 중간 상태 구체화

#### 10.3.1.1. 데이터플로 엔진

#### 10.3.1.2. 내결함성

#### 10.3.1.3. 구체화에 대한 논의

### 10.3.2. 그래프와 반복 처리

- 전체 그래프에서 오프라인으로 처리를 수행하거나 분석을 하는 등 일괄 처리 맥락에서 그래프를 살펴보는 것도 흥미롭다.
- 추천 엔진 같은 머신러닝이다 랭킹 시스템 분야에서도 그래프 처리의 필요성이 떠오르고 있다. 예를 들면 가장 유명한 그래프 분석 알고리즘 중 하나인 페이지랭크를 들 수 있다.

#### 10.3.2.1. 프리글 처리 모델

#### 10.3.2.2. 내결함성

#### 10.3.2.3. 병렬 실행


### 10.3.3. 고수준 API와 언어

#### 10.3.3.1. 선언형 질의 언어로 전환

#### 10.3.3.2. 다양한 분야를 지원하기 위한 전문화


## 정리

분산 일괄 처리 프레임워크가 해결해야 할 두 가지 중요한 문제가 있다.
- 파티셔닝
- 내결함성

맵리듀스에서 사용하는 몇 가지 조인 알고리즘
- 정렬 병합 조인
- 브로드캐스트 해시 조인
- 파티션 해지 조인

일괄처리 시스템은 입력을 그대로 두고 출력만 만들기에 재시작하기 쉽고 쉽게 적용할 수 있다.