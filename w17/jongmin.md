
# 10장 일괄 처리

한 사람의 영향도가 너무 큰 시스템은 성공하기 어렵다. 초기 설계가 완료되고 상당히 견고해지면 여러 사람이 다양한 관점을 가지고 각각 실험을 진행하면서 실제 테스트가 시작된다.
- 도널드 크누스

기존 1 ~ 2부에서는 시스템에 데이터를 요청하거나 지시를 보낸 후 잠시 뒤에 해당시스템으로 결과를 반환 받는 시스템을 다뤘다.
- 요청 -> 응답
- 질의 -> 결과

3가지 데이터 시스템

| 항목 | 내용 |
| --- | --- |
| 서비스(온라인 시스템) | 서비스는 클라이언트로부터 요청이나 지시가 올때까지 기다린다. 요청 하나가 들어오면 서비스는 가능한 빨리 요청을 처리해서 응답을 되돌려 보내려 한다. 응답 시간은 서비스 성능을 측정할ㄷ 때 중요한 지표다. 때론 가용성이 매우 중요한데 클라이언트가 서비스에 접근하지 못하면 사용자는 오류 메시지를 받을지 모른다. |
| 일괄 처리 시스템(오프라인 시스템) | 일괄 처리 시스템은 매우 큰 입력 데이터를 처리하는 작업을 수행하고 결과 데이터를 생산한다. 일괄 처리 작업은 수 분에서 때론 수 일이 걸리기 때문에 대개 사용자가 작업이 끝날 때까지 대기하지 않는다. 대신 대부분 하루에 한번 수행과 같이 반복적인 일정으로 수행한다. 일괄 처리 작업의 주요 성능 지표로는 처리량이 대표적인다. 처리량은 입력 데이터 중 특정 크기만큼 처리할 때 걸리는 시간으로 나타낸다. 이번 장에서는 일괄 처리 시스템에 대해 논의한다. |
| 스트림 처리 시스템(준실시간 시스템) | 스트림 처리는 온라인가ㅗ 오프라인/일괄 처리 사이의 어딘가에 있기 때문에 때론 준실시간 처리라 불린다. 스트림 처리 시스템은 일괄 처리 시스템과 마찬가지로 요청에 대해 응답하지 않으며 입력 데이터를 소비하고 출력 데이터를 생산한다. 그러나 일괄 처리 작업은 정해진 크기의 입력 데이터를 대상으로 작동하지만 스트림 처리는 입력 이벤트가 발생한 후 직후 바로 작동한다. 이런 차이 때문에 스트림 처리 시스템은 같은 작업을 하는 일괄 처리 시스템보다 지연 시간이 낮다. 스트림 처리는 일괄 처리를 기반으로 하므로 11장에서 다룬다. |

이번 장에서 살펴보겠지만 **일괄 처리는 신뢰할 수 있고 확장 가능하며 유지보수하기 쉬운 애플리케이션을 구축하는 데 매우 중요한 구성요소**다.

예를 들면 2004년에 발표된 일괄 처리 알고리즘인 MapReduce는 다소 과한 면이 있지만 "구글을 대규모로 확장 가능하게 만든 알고리즘"으로 불렸다.

맵리듀스는 이전에 데이터 웨어하우스용으로 개발했던 병렬 처리 시스템보다 상당히 저수준 프로그래밍 모델이다. 그러나 **범용 하드웨어만을 사용해 처리한 데이터 규모 면에서 상당히 진보**했다. 지금은 **맵리듀스의 중요성이 떨어지고 있지만** 왜 **일괄 처리가 유용한지 명확하게 그림을 그려주기 때문에 맵리듀스를 이해할 가치는 충분**하다.


## 10.1. 유닉스 도구로 일괄 처리하기

- 유닉스 프로그램과 파이프로 데이터 처리하기 

### 10.1.1. 단순 로그 분석

```bash
cat /var/log/nginx/access.log |
	awk '{print $7}' |
	sort |
	uniq -c |
	sort -r -n |
	head -n 5
 27 /
  9 400
  4 /favicon.ico
  2 google.com:443
  1 ssl-judge2.api.proxyscrape.com:443

cat /var/log/nginx/access.log |
> awk '{print $1}' |
> sort |
> uniq -c |
> sort -r -n |
> head -n 5
      5 185.142.236.43
      4 31.7.58.42
      4 220.231.101.34
      4 167.94.138.52
      3 185.224.128.187
```

유닉스 도구를 사용해 위처럼 웹 로그를 분석할 수 있다.

#### 10.1.1.1. 연쇄 명령 대 맞춤형 프로그램
- 프로그래밍 언어를 사용해 위와 같은 작업을 하는 간단한 프로그램을 작성할 수도 있다.
	- 책에서는 Ruby로
#### 10.1.1.2. 정렬 대 인메모리 집계
- 위의 루비 스크립트는 URL 해시  테이블을 메모리에 유지한다.
- 유닉스 파이프라인 예제에는 이런 해시 테이블이 없다.
- 어떤 접근법이 더 좋을지는 다른 URL이 얼마나 되느냐에 따라 다르다.
	- 작업 세트가 충분히 작다면 인메모리 해시 테이블도 잘 동작한다.
	- 하지만 허용 메모리보다 작업 세트가 크다면 정렬 접근법을 사용하는 것이 좋다.
		- 데이터 청크를 메모리에서 정렬하고 청크를 세그먼트 파일로 디스크에 저장한다.
		- 그 다음 각각 정렬된 세그먼트 파일 여러 개를 한 개의 큰 정렬 파일로 병합한다.
		- GNU Coreutils에 포함된 sort 유틸리티는 메모리보다 큰 데이터셋을 자동으로 디스크로 보내고 자동으로 여러 CPU 코어에서 병렬로 정렬한다. (메모리 부족 없이 큰 데이터셋으로 확장 가능함)

### 10.1.2. 유닉스 철학

바로 앞의 예제와 같이 연쇄 명령을 사용해 쉽게 로그 파일을 분석할 수 있었던 것은 우연이 아니다. 
```
유닉스 파이프를 발명한 더그 맥일로이는 1964년에 유닉스 파이프를 이와 같이 설명했다: 다른 방법으로 데이터 처리가 필요할 때 정원 호스와 같이 여러 다른 프로그램을 연결하는 방법이 필요하다. 이것은 I/O 방식이기도 하다. 
- 데이터중심 애플리케이션 설계 (390page)
```

1978년 기술된 유닉스 철학
1. 각 프로그램이 한 가지 일만 하도록 작성하라. 새 작업을 하려면 기존 프로그램을 고쳐 새로운 '기능'을 추가해 프로그램을 복잡하게 만들기보다는 새로운 프로그램을 작성하라
2. 모든 프로그램의 출력은 아직 알려지지 않은 다른 프로그램의 입력으로 쓰일 수 있다고 생각하라. 불필요한 정보로 출력이 너저분해서는 안 된다. 입력 형식으로 엄격하게 열을 맞춘다거나 이진 형태를 사용하지 마라. 대화형 입력을 고집하지 마라.
3. 소프트웨어를 빠르게 써볼 수 있게 설계하고 구축하라. 심지어 운영체제도 마찬가지다. 수 주 안에 끝내는 것이 이상적이다. 거슬리는 부분은 과감히 버리고 새로 구축하라.
4. 프로그래밍 작업을 줄이려면 미숙한 도움보단 도구를 사용하라. 도구를 빌드하기 위해 한참 둘러가야 하고 게다가 사용 후 바로 버린다고 할지라도 도구를 써라.

자동화, 빠른 프로토타이핑, 증분 반복, 실험 친화, 큰 프로젝트를 청크로 나누어 처리하기와 같은 방법은 오늘날의 애자일 및 DevOps 운동과 매우 흡사하고 놀랍게도 40년이 지났지만 거의 바뀌지 않았다.

sort는 한 가지 일을 잘 해내는 프로그램의 훌륭한 예다. sort의 구현은 대부분의 프로그래밍 언어에 포함된 표준 라이브러리보다 확실히 뛰어나다. 표준 라이브러리는 처리하는 데이터를 디스크로 흘려보내지 않고, 다중 스레드를 쓰는 게 분명히 이득이 상황에서도 다중 스레드를 사용하지 않는다.

bash 같은 유닉스 셸을 사용하면 작은 프로그램들을 가지고 놀랄 만큼 강력한 데이터 처리 작업을 쉽게 구성할 수 있다.

#### 10.1.2.1. 동일 인터페이스

어떤 프로그램의 출력을 다른 프로그램의 입력으로 쓰고자 한다면 이들 프로그램은 같은 데이터 형식을 사용해야 한다. 즉 호환 가능한 인터페이스를 써야 한다. 
유닉스에서 인터페이스는 파일(좀 더 정확히는 파일 디스크립터)이다. 파일은 단지 순서대로 정렬된 바이트의 연속이다. 파일은 이처럼 단순해서 같은 인터페이스로 파일시스템의 실제 파일, 프로세스 간의 통신 채널(유닉스 소켓, 표준입력, 표준 출력), 장치 드라이버, TCP 연결을 나타내는 소켓 등 다른 여러 가지 것을 표현할 수 있다.

많은 유닉스 프로그램은 연속된 바이트를 아스키 텍스트로 취급한다.
로그 분석 예제에서 바로 이점을 활용해 awk, sort, uniq, head 프로그램은 입력 파일을 \n(개행문자 아스키 0x0A) 문자로 분리된 레코드로 다룬다. \n가 선택된 이유는 딱히 없다. 애초에 이런 목적으로 사용하려고 만든 0x1E가 아스키 레코드 분리자로 훨씬 좋은 선택일지도 모른다. 어쨌든 같은 레코드 분리자를 사용해 표준화했기 때문에 이 모든 프로그램이 상호 운영 가능하다.
각 레코드를 파싱하는 건 더욱 애매하다. 유닉스 도구는 대개 한 줄을 공백이나 탭 문자로 분리해 필드로 만든다. 하지만 CSV, 파이프 등의 다른 부호화 방법도 사용한다.
동일 인터페이스로 아스키 텍스트는 큰 문제가 없지만 그다지 깔끔하지 않다. 로그 분석 예제는 URL을 추출하려고 {print $7}을 사용했다. 하지만 가독성이 좋지 않다. 이상적으로 하자면 {print $request_url}이나 비슷한 형태일 것이다.
완벽하지도 않음에도 심지어 수십 년이 지났어도 유닉스의 동일 인터페이스는 여전히 대단하고, 오늘날 유닉스 도구처럼 매끄럽게 협동하는 프로그램이 있다는 건 정상이 아니라 예외적이다.

#### 10.1.2.2. 로직과 연결의 분리

유닉스 도구의 다른 특징으로 표준 입력(stdin)과 표준 출력(stdout)을 사용한다는 점을 들 수 있다. 프로그램을 실행하고 아무것도 설정하지 않는다면 stdin은 키보드로부터 들어오고 stdout은 화면으로 출력한다. 혹은 파일에서 입력을 가져와 다른 파일로 출력을 재전송할 수도 있다. **파이프는 한 프로세스의 stdout을 다른 프로세스의 stdin과 연결한다.** 
이때 중간 데이터를 디스크에 쓰지 않고 작은 인메모리 버퍼를 사용해 프로세스 간 데이터를 전송한다. (필요한 경우라면 프로그램에서 직접 파일을 읽고 쓸 수도 있지만 프로그램이 특정 파일의 경로가 어디에 있는지 신경 쓰지 않고 stdin과 stdout만으로 처리하고 싶다면 유닉스 접근법이 가장 좋다.)
- 프로그램은 입력이 어디서부터 들어오는지 출력이 어디로 나가는지 신경 쓰거나 알 필요가 없어진다.
- 프로그램에서 입출력을 연결하는 부분을 분리하면 작은 도구로부터 큰 시스템을 구성하기 훨씬 수월하다.
- 느슨한 결합, 지연 바인딘, 제어 반전이라고도 한다.

장점: 연쇄 명령어의 중간에 IP 주소를 국가 코드로 바꾸는 코드 등을 끼워 넣기 쉽다.
단점: 프로그램이 여러 개의 입력을 받거나 여러 개의 출력이 필요할 때는 까다롭다, 프로그램의 출력을 파이프를 이용해 네트워크와 연결하지는 못한다. 

#### 10.1.2.3. 투명성과 실험

유닉스 도구가 성공적인 이유 중 하나는 진행 사항을 파악하기가 상당히 쉽기 때문이다.
- 유닉스 명령에 들어가는 **입력 파일은 일반적으로 불변으로 처리**된다. (다양한 명령행 옵션을 사용해가며 명령을 수행해도 입력 파일 변화가 없다)
- 어느 시점이든 파이프라인을 중단하고 출력을 파이프를 통해 `less` 로 보내 원하는 형태의 출력이 나오는지 확인할 수 있다.
```bash
cat /var/log/nginx/access.log |
> awk '{print $1}' |
> sort |
> uniq -c |
> sort -r -n |
> head -n 5 |
> less
```
- 특정 **파이프라인 단계의 출력을 파일에 쓰고 그 파일을 다음 단계의 입력으로 사용**할 수 있다. 이렇게 하면 **전체 파이프라인을 다시 시작하지 않고 다음 단계부터 재시작**할 수 있다. (파이프라인 일부가 실패하여 재시작할 때 또는, 한 데이터셋을 중복 사용하는 로직이 있을 때 유용)

- RDB의 질의 최적화 두고와 비교하면 불친절하지만 유용하고 프로토타이핑 하기에 좋다.
- 하지만 **단일 장비에서만 실행된다는게 단점이고 바로 이 점이 하둡 같은 도구가 필요한** 이유다.

## 10.2. 맵리듀스와 분산 파일 시스템

맵리듀스는 **유닉스 도구와 비슷한 면이 있지만 수천 대의 장비로 분산해서 실행**이 가능하다는 점에서 차이가 있다. 맵리듀스는 유닉스 도구와 마찬가지로 상당히 불친절하고 무차별 대입 방법이지만 대신 엄청나게 효율적인 도구다. **단일 맵리듀스 작업은 하나 이상의 입력을 받아 하나 이상의 출력을 만들어 낸다는 점에서 단일 유닉스 프로세스와 유사**하다.

유닉스 도구와 마찬가지로 맵리듀스 작업은 입력을 수정하지 않는다. (출력만 만들뿐)
출력 파일은 순차적으로 한 번만 쓰여지고 파일에 이미 쓰여진 부분은 고치지 않는다.

유닉스 도구는 stdin, stdout을 입력과 출력으로 사용하는데 맵리듀스 작업은 분산 파일 시스템상의 파일을 입력과 출력으로 사용한다. 하둡 맵리듀스 구현에서 이 파일 시스템은 HDFS(Hadoop, Distiributed File System)라고 하는데 GFS를 재구현한 오픈소스다.

HDFS 외에도 GlusterFS, QFS 등 다양한 분산 파일 시스템이 있고 AWS S3, Azure Blob, 오픈스택 스위프트 같은 객체 저장소도 여러면에서 유사하다.

HDFS는 비공유 원칙을 기반으로하는데 NAS, SAN 아키텍처에서 사용하는 공유 디스크 방식과는 반대다. 공유 디스크 저장소는 중앙 집중 저장 장치를 사용하는 데 맞춤형 하드웨어나 특별한 네트워크 인프라를 사용하기도 한다. 하지만 비공유 방식은 특별한 하드웨어가 필요없다. 일반적인 데이터센터 네트워크에 연결된 컴퓨터면 충분하다.

HDFS는 각 장비에서 실행되는 데몬 프로세스로 구성되고 다른 노드가 해당 장이에 저장된 파일에 접근 가능하게끔 네트워크 서비스를 제공한다. HDFS는 범용 하드웨어와 오픈소스 소프트웨어를 사용하기 때문에 확장성이 뛰어나 수만대의 장비를 묶어 실행하기도 한다. 

- 매퍼가 키를 기준으로 데이터를 파티셔닝해서 리듀서에게 전달함
- 특정 키에 데이터가 쏠려 있다면 특정 리듀서에게 작업이 몰릴 수 있기에 대책이 필요함
- 여러번의 맵-리듀스 작업이 반복되어 워크플로가 만들어질 수 있음
- 각 맵-리듀스 작업별로 데이터 파일이 디스크에 저장됨
### 10.2.1. 맵리듀스 작업 실행하기

맵리듀스는 HDFS 같은 분산 파일 시스템 위에서 대용량 데이터셋을 처리하는 코드를 작성하는 프로그래밍 프레임워크다. 

1. 입력 파일을 읽는다. 레코드로 쪼갠다. 웹 서버 로그 예제에서 로그의 각 줄이 레코드가 된다. 즉 레코드 분리자로 \n을 사용한다.
2. 각 입력 레코드마다 매퍼 함수를 호출해 키와 값을 추출한다. 예제에서 매퍼 함수는 awk '{print $7}'인데 URL($7)을 키로 추출하고 값은 빈 값으로 한다.
3. 키를 기준으로 키-값 쌍을 모두 정렬한다. 이 과정은 로그 예제에서 첫 번째 sort명령에 해당한다.
4. 정렬된 키-값 쌍 전체를 대상으로 리듀스 함수를 호출한다. 같은 키가 여러 번 등장했다면 정렬 과정에서 해당 키-값 쌍은 서로 인접한다. 그래서 같은 키를 가지는 값들을 따로 메모리 상에 유지하지 않고도 쉽게 결합할 수 있다. 예제에서 uniq -c 명령에 해당한다. 이 명령은 키가 같으면서 인접한 레코드의 수를 센다.

맵리듀스 작업 하나는 4가지 단계로 수행한다. 2단계(맵)과 4단계(리듀스)는 사용자가 직접 작성한 데이터 처리 코드다. 1단계는 파일을 나누어 레코드를 만드는 데 입력 형식 파서를 쓴다. 3단계는 정렬 단계로 맵리듀스에 내재하는 단계라서 직접 작성할 필요가 없다. 매퍼의 출력은 리듀스로 들어가기 전에 이미 정렬됐기 때문이다.

맵리듀스 작업을 생성하려면 다음과 같이 동작하는 **매퍼와 리듀서라는 두 가지 콜백 함수를 구현**해야 한다.

매퍼(Mapper)
- 매퍼는 모든 입력 레코드마다 한 번씩만 호출된다. 매퍼는 입력 레코드로부터 키와 값을 추출하는 작업이다. 각 입력으로부터 생성하는 키-값 쌍은 빈 쌍을 포함해 원하는 만큼 생성 가능하다. 매퍼는 입력 레코드로부터 다음 레코드까지 상태를 유지하지 않기 때문에 각 레코드를 독립적으로 처리한다.
리듀서(Reducer)
- 맵리듀스 프로엠워크는 매퍼가 생산한 키-값 쌍을 받아 같은 키를 가진 레코드를 모으고 해당 값의 집합을 반복해 리듀서 함수를 호출한다. 리듀서는 출력 코드를 생산한다. 출력 레코드의 한 예로 동일한 URL이 출현한 횟수가 있다.
#### 10.2.1.1. 맵리듀스의 분산 실행

유닉스 명령어 파이프라인과 맵리듀스의 가창 큰 차이점은 맵리듀스는 병렬로 수행하는 코드를 직접 작성하지 않고도 여러 장비에서 동시에 처리 가능하다는 점이다.
매퍼와 리듀서는 한 번에 하나의 레코드만 처리하고 입력이 어디서 오는지 출력이 어디로 가는지 신경 쓰지 않는다. 맵리듀스 프레임워크가 장비 간에 데이터가 이동하는 복잡한 부분을 처리하기 때문이다.

분산 연산에서 매퍼와 리듀서로 표준 유닉스 도구를 사용하는 것도 가능하다. 하지만 대개는 일반적인 프로그래밍 언어로 함수를 작성한다. 하둡 맵리듀스에서 매퍼와 리듀스는 각각 특정 인터페이스를 구현한 자바 클래스다. 몽고와 카우치는 매퍼와 리듀스가 자바스크립트 함수다.

![[Pasted image 20231204224329.png]]

- m1~m3: 매퍼가 읽어오는 파일 블록 (입력)
- r1~r3: 리듀서가 저장하는 파일 (출력)

대부분의 경우 맵 태스크에서 실행될 애플리케이션 코드는 작업이 할당된 장비에 아직 존재하지 않기 때문에 
1. 맵리듀스 프레임워크가 작업을 수행하기에 적절한 장비로 코드(Java를 예로들면 JAR)를 복사한다.
2. 복사가 끝나면 장비에서 매퍼 태스크가 시작된다.
3. 입력 파일을 읽기 시작하면 입력 파일에서 한 번에 하나씩 읽어 매포 콜백 함수로 전달한다. 매퍼의 출력은 키-값 쌍으로 구성된다.

리듀서 측 연산도 파티셔닝 된다. 맵 태스크 수는 입력 파일의 블록 수로 결정되지만 리듀스 태스크 수는 사용자가 정한다. 즉 맵 태스크 수와 리듀스 태스크 수는 다를 수 있다.
맵리듀스 프레임워크는 같은 키를 가진 모든 키-값 쌓을 같은 리듀서에서 처리하는 것을 보장하는데, 특정 키-값 쌍이 어느 리듀스 태스크에서 수행될지 결정하기 위해서 키의 해시값을 사용한다.

키-값 쌍은 반즈시 정렬돼야 하지만대개 데이터셋이 매우 크기 때문에 일반적인 정렬 알고리즘으로 한 장비에서 모두 정렬하기는 쉽지 않다.그렇기 때문에 단계를 나누어 정렬을 수행한다.
1. 먼저 각 맵 태스크는 키의 해시값을 기반으로 출력을 리듀서로 파티셔닝한다.
2. 그리고 각 파티션을 매퍼의 로컬 디스크에 정렬된 파일로 기록한다.
3. 매퍼가 입력 파일을 읽어서 정렬된 출력 파일을 기록하기를 완료하면 맵리듀스 스케줄러는 그 매퍼에서 출력 파일을 가져올 수 있다고 리듀서에게 알려준다.
4. 리듀서는 각 매퍼와 연결해서 리듀서가 담당하는 파티션에 해당하는 정렬된 키-값 쌍 파일을 다운로드한다.
5. 리듀서를 기준으로 파티셔닝하고 정렬할 뒤 매퍼로부터 데이터 파티션을 복사하는 과정을 셔플(Shuffle)이라고 한다. (셔플이라면 카드를 섞는 것이라 생각하지 쉽지만 맵리듀스에서 셔플은 임의로 섞지 않는다)
6. 리듀스 태스크는 매퍼로부터 파일을 가져와 정렬된 순서를 유지하면서 병합한다. (결과적으로 리듀서는 여러 블록의 데이터가 정렬된 값을 입력값으로 받음)

#### 10.2.1.2. 맵리듀스 워크플로

맵리듀스 작업 하나로 해결할 수 있는 문제의 범위는 제한적이다.
로그 분석 예제에서 단일 맵리듀스로 작업으로 URL당 페이지뷰 수를 구할 수 있지만 가장 인기 있는 URL을 구할 수는 없다. 그러기 위해서는 추가로 정렬 작업이 필요하다.

따라서 맵리듀스 작업을 연결해 워크플로(Workflow)로 구성하는 방식은 꽤 일반적이다. 맵리듀스 작업 하나의 출력을 다른 맵리듀스 작업의 입력으로 사용하는 식이다.

하둡 맵리듀스 프레임워크는 워크플로를 직접 제공하지 않기 때문에 맵리듀스 작업은 디렉토리 이름을 통해 암묵적으로 연결된다. 첫번 째 작업이 HDFS상에 지정된 디렉토리에 파일을 저장하게하고(출력) 두번째 작업은 해당 디렉토리의 파일을 입력으로 사용한다.
첫번째, 두번째 작업은 완전히 독립적이다.

연결된 맵리듀스 작업은 유닉스 명령 파이프라인(소량의 메모리 버퍼를 사용해 한 프로세스의 출력이 다른 프로세스의 입력으로 전달되는 방식)과 달리 각 명령의 출력을 임시 파일에 쓰고 다음 명령이 그 임시 파일로부터 입력을 읽는 방식이다. 이 설계는 장단점이 있는데 419Page '중간 상태 구체화'에서 다시 논의하다.

일괄 처리 작업의 출력은 작업이 성공적으로 끝났을 때만 유효하다. 그렇기 때문에 워크플로 상에서 해당 작업의 입력 디렉토리를 생성하는 선행 작업이 완전히 끝나야만 다음 작업을 시작할 수 있다. 하룹 맵리듀스 작업 간 수행 의존선을 관리하기 위해 다양한 스케줄러가 개발 됐다. (우지, 아즈카반, 루이지, 에어플로우, 핀볼 등)

- 이런 스케줄러에는 일괄 처리 집합을 유지보수할 때 유용한 관리기능이 있다. 추천 시스템을 구축하는 데 사용하는 워크플로는 50~100개가 일반적이다.

### 10.2.2. 리듀스 사이드 조인과 그룹화

### 10.2.3. 사용자 활동 이벤트 분석 예제

#### 10.2.3.1. 정렬 병합 조인

- 사용자 데이터베이스
	- 사용자 ID, 생일, 이메일 주소
- 사용자 활동 데이터
	- 사용자 ID, 사용자 활동 내역
	- ...
- 2개 데이터 셋을 사용자 ID 기준으로 파티셔닝해 같은 리듀서에 보낸 후 처리한다.
	- 여기서 항상 사용자 데이터베이스를 먼저보고 사용자 활동 데이터를 조인한다.

#### 10.2.3.2. 같은 곳으로 연관된 데이터 가져오기

- 같은 키를 가진 키-값 쌍은 모두 같은 목적지로 배달된다 (같은 리듀서로 배달된다)

#### 10.2.3.3. 그룹화

- SQL의 Group By와 유사

#### 10.2.3.4. 쏠림 다루기

- **키 하나에 너무 많은 데이터가 연관**된다면 "같은 키를 가지는 모든 레코드를 같은 장소로 모으는" 패턴은 제대로 동작하지 않는다. (같은 키를 하나의 리듀서 노드에 보낼 수 없음, 리듀서가 터짐..)
	- 예를 들자면 팔로워가 수백만 명인 유명 인사
- 이렇게 불균형한 활성 데이터베이스를 린치핀 객체 또는 핫 키라 한다.
- 유명 인사 한 사람에 관련된 모든 활동을 리듀서 한개에서 모은다면 상당한 쏠림 현상이 생긴다. 이런 현상을 핫스팟 이라고한다. (한 리듀서가 다른 리듀서보다 엄청나게 많은 레코드를 처리해야함)
- **모든 매퍼와 리듀서가 완전히 끝나야지만 맵 리듀스 작업이 끝나**기 때문에 가자으 느린 리듀서가 병목이 된다.

해결 방법
- **핫 키**를 **여러 리듀서에 퍼뜨려서 처리**하게 한다.
- 조인을 수행할 때 매퍼는 **핫 키를 가진 레코드를 여러 리듀서 중 임의로 선택한 하나로 레코드**를 보낸다.

### 10.2.4. 맵 사이드 조인

- 지난 절에서 설명한 여러 조인 알고리즘은 실제 조인 로직을 리듀서에서 수행하기 때문에 리듀스 사이드 조인이라한다.
- 매퍼는 각 입력 레코드에서 키와 값을 추출해 추출한 키-값 쌓을 리듀서 파티션으로 할당하고 키별로 정렬하는, 즉 입력 데이터를 준비하는 역할을 한다.
- 리듀스 사이드 접근법의 장점은 입력 데이터에 대한 특정 가정이 필요없다는 점이다. 입력 데이터의 속성과 구조가 무엇이든 매퍼는 데이터를 조인할 준비를 할 수 있다. 그러나 정렬 후 리듀서로 복사 한 뒤 리듀서 입력을 병합하는 모든 과정에 드는 비용이 상당하다는 점이 큰 담점이다.
- 반면 입력 데이터에 대해 특정 가정이 가능하다면 맵사이드 조인으로 불리는 기법을 사용해 조인을 더 빠르게 수행할 수 있다. 이 접근법은 축소된 맵리듀스 작업으로, 리듀서는 물론 정렬 작업도 없다. 대신 각 매퍼가 할 작업은 분산 파일 시스템에서 단순히 입력 파일 블럭 하나를 읽어 다시 해당 분산 파일 시스템에 출력하는 것이 전부다.

#### 10.2.4.1. 브로드캐스트 해시 조인

- **작은 테이블을 인 메모리 해시 테이블**로 만들고 **큰 테이블의 데이터를 하나씩 조회**해서 조인한다.
#### 10.2.4.2. 파티션 해시 조인

	Pass

#### 10.2.4.3. 맵 사이드 병합 조인

	Pass

#### 10.2.4.4. 맵 사이드 조인을 사용하는 맵리듀스 워크플로

- 맵 사이드 조인을 수행하기 위해서는 크기, 정렬, 입력 데이터의 파티셔닝 같은 제약 사항이 따른다.
- 조인 전략을 최적화할 때는 분산 파일 시스템 내 저장된 데이터셋의 물리적 레이아웃 파악이 중요하다.
- 하둡 생태계에서 데이터셋 파티셔닝 관련 메타데이터를 관리하는데 H카탈로그나 하이브 메타스토어를 사용하기도 한다.

### 10.2.5. 일괄 처리 워크플로의 출력

- 일괄 처리를 하는 이유가 무엇인가? 일괄 처리 워크플로의 출력은 어디에 쓰이는가?
- 트랜잭션 처리도 아니고 분석도 아니다.
- 일괄 처리는 입력데이터셋 대부분을 스캔하는 것이 일반적이라 분석에 더 가깝다. 그러나 맵리듀스 작업의 워크플로는 분석 목적으로 사용하는 SQL 질의와는 다르다. 일괄 처리의 출력은 흔히 보고서가 아닌 다른 형태의 구조다.

#### 10.2.5.1. 검색 색인 구축

맵리듀스는 구글에서 검색 엔진에 사용할 색인을 구축하기 위해 처음 사용됐었는데 그 당시 사용된 워크플로는 5~10개의 맵리듀스 작업으로 구현됐다.

정해진 문서 집합을 대상으로 전문 검색이 필요하다면 일괄 처리가 색인을 구축하는 데 매우 효율적이다. 
1. 매퍼는 필요에 따라 문서 집합을 파티셔닝하고
2. 각 리듀서가 해당 파티션에 대한 색인을 구축한다
3. 그리고 색인 파일은 분산 파일 시스템에 저장한다.
문서 기준으로 파티셔닝해 색인을 구축하는 과정은 병렬화가 매우 잘 된다. (빨리 처리할 수 있다.)
키워드로 검색엔진에 질의하는 연산은 읽기 전용이라서 색인 파일을 한번 생성하면 불변이다.

#### 10.2.5.2. 일괄 처리의 출력으로 키-값을 저장

검색 색인은 일괄 처리 워크플로 출력의 한 가지 예제일 뿐이다.
다른 예로 분류기 같은 머신러닝 시스템 (스팸 필터, 이상 검출, 이미지 인식)을 구축하거나 추천 시스템을 구축할 수 있다.

이런 일괄 처리 작업의 결과는 흔히 일종의 데이터베이스가 된다.
- 예를 들어 사용자 ID로 조회해 친구 추천
- 상품 ID로 질의해 관련 상품 목록 가져오기

일괄 처리 작업의 결과물을 다른 데이터 저장소와 연동해 조회한다. 이것은 실시간이 될 수도 벌크 작업이 될 수도 있다.

#### 10.2.5.3. 일괄 처리 출력에 관한 철학

이번 장 전반부에서 설명한 유닉스 철학은 데이터플로가 **프로그램이 입력을 읽어 출력을 내놓는다**로 명확하기 때문에 실험을 장려한다.
이 과정에서 입력은 변하지 않은 채 새 출력이 이전 출력을 완벽하게 교체한다. 이 과정에는 아무런 부수 효과가 없다. 이는 시스템 상태를 엉망으로 만들지 않고도 얼마든지 원하는 만큼 프로그램을 수정하거나 디버깅 용도로 명령을 재실행할 수 있다는 뜻이다.
- 원본 데이터는 망가지지 않는다, 일괄 처리 결과물은 파생데이터이다.

맵리듀스 작업도 마찬가지 철학으로 출력을 취급한다. 입력을 불편으로 처리하고 외부 데이터베이스에 기록하는 등의 부수 효과를 피하기 때문에 일괄 처리 작업은 좋은 성능을 내면서도 유지보수가 훨씬 간단하다.

### 10.2.6. 하둡과 분산 데이터베이스의 비교

지금까지 살펴본 대로 하둡은 유닉스의 분산 버전과 다소 비슷하다. HDFS는 파일 시스템이고 맵리듀스는 특별한 방식으로 구현된 유닉스 프로세스다.

대규모 병렬 처리 (massively parallel processing, MPP) 머신과 맵리듀스의 가장 큰 차이점을 보면 MPP 머신은 특정 용도의 장비 클러스터에서 분석 SQL질의를 수행하는 바면, 맵리듀스와 분산 파일 시스템의 조합은 아무 노드에서나 가능하다.

#### 10.2.6.1. 저장소의 다양성

데이터베이스는 특정 모델을 따라 데이터를 구조화해야 한다. 반면 분산 파일시스템의 파일은 어떤 데이터 모델과 인코딩을 사용해서도 기록할 수 있는 연속된 바이트일 뿐이다. (텍스트, 이미지, 비디오, 센소 판독 값, 게놈 시퀀스 등 어떤 형태도 저장 가능)

극단적으로 말하자면 하둡은 데이터가 어떤 형태라도 상관없이 HDFS로 덤프할 수 있는 가능성을 열어 놓았다.
데이터를 어떻게 처리할지는 덤프 이후에 생각할 수 있다.
반대로 MPP 데이터베이스를 사용하면 대개 데이터베이스 특화된 저장 형태로 데이터를 모델링 해야 한다.

당연히 순수주의자 관점에서 보면 세심하게 모델링하고 데이터를 가져오는게 바람직한 작업이다. 데이터베이스 사용자가 작업하기 좋은 양질의 데이터를 가지게 되기 때문이다. 그러나 현실에서는 이상적인 데이터 모델을 만들려고 하기보다 데이터를 빨리 사용하게 만드는 것이 더 가치 있다.

MPP 데이터베이스가 요구하는 세심한 스키마 설계는 중앙 집중식 데이터 수집을 느리게 만들 수 있다. 원시 데이터를 수집하고 스키마 설계는 나중에 고민하면 데이터 수집의 속도가 올라간다 (데이터 레이크)
(ETL, ELT)
- Extract -> Transform -> Load
- Extract -> Load -> Transform

데이터 레이크에 데이터를 덤핑 후 데이터를 해석하는 부담은 데이터셋 생성자에게 이전 시켜 분담할 수도 있다.
(디커플링)

#### 10.2.6.2. 처리 모델의 다양성

MPP 데이터베이스는 일체식 구조로서 디스크 저장소 레이아웃과 질의 계획, 스케줄링과 실행을 다루는 소프트웨어 조각들이 긴밀하게 통합된다. 이 구성 요소들은 데이터베이스의 특정한 필요에 따라 튜닝하거나 최적화하기 때문에 전체 시스템은 설계된 질의 유형에 대해서 매우 좋은 성능을 얻을 수 있다. (거의 SQL 질의 사용)

반면 SQL 질의만으로 모든 문제를 해결할 수 없을 때도 있는데 하둡 생태계는 다양한 다른 연동 툴을 제공한다.

#### 10.2.6.3. 빈번하게 발생하는 결함을 줄이는 설계

맵리듀스와 MPP 데이터베이스를 비교할 때 설계 방식에서 큰 차이점 두가지가 두드러진다.
결함을 다루는 방식과 메모리 및 디스크를 사용하는 방식이 그 두 가지다.
일괄 처리는 온라인 시스템에 비해 결함에 덜 민감하다. 일괄 처리 작업이 실패하더라도 즉시 사용자에게 영향을 주지 않으면서 언제든지 다시 실행할 수 있기 때문이다.

질의 실행 중에 한 방지만 죽어도 MPP 데이터베이스 대부분은 전체 질의가 중단되고, 질의를 다시 제출하든지 다시 아니면 자동으로 재실행 된다.
- 일반적인 질의는 수초~수분 내로 끝내 이런 방식으로 오류를 다루는 방식도 재시도 비용이 크지 않아 수용 가능하다.
- 빠른 연산을 위해 메모리에서 거의 해결한다.

하지만 맵리듀스는 태스크의 실패를 견딜 수 있다. 개별 태스크 수준에서 작업을 재수행하기 때문에 전체 작업으로 보면 영향을 받지 않는다. 또한 맵리듀스는 데이터를 되도록 디스크에 기록하려 한다. 한편으로는 내결함성을 확보하기 위함이고 다른 한편으로는 메모리에 올리기에는 데이터셋이 너무 크다는 가정 때문이다.


맵리듀스 접근법은 대용량 작업에 더 적합하다. 많은 데이터를 처리하고 오랜 시간 수행하는 작업이라면 그 사이에 최소한 태스크 하나는 실패할 가능성이 높다. 이 경우 태스크 하나가 실패했다고 작업 전체를 재수행하는 일은 분명 낭비다.


맵리듀스가 메모리를 아껴 쓰고 태스크 수준에서 복구하는 이유를 이해하려면 원래 맵리듀스를 설계한 환경을 살펴보면 도움이 된다.
- 구글은 혼합 사용 데이터 센터를 사용하고 있었고 이곳에서는 온라인 프로덕션 서비스와 오프라인 일괄 처리 작업이 같은 장비에서 실행된다.
- 온라인 프로덕선 서비스는 우선순위가 낮은 태스크를 종료하고 선점할 수 있다.
- 따라서 우선순위가 낮은 오프라인 일괄 처리 작업은 종료가 빈번했다.

일괄 처리 작업은 사실상 "식탁 아래에서 조각들을 모은다", **우선순위가 높은 프로세스가 필요한 작업을 수행한 뒤에 남은 자원을 사용해 일괄 처리 연산을 수행**한다.

태스크가 그렇게 자주 종료되지 않는 환경이라면 맵리듀스를 이런 식으로 설계한 점으 선뜻 이해하기 어렵다.

## 10.3. 맵리듀스를 넘어

### 10.3.1. 중간 상태 구체화

- 중간 상태의 출력
	- 추천 시스템을 구축할 때 사용하는 복잡한 워크플로는 맵리듀스 작업이 50~100개로 구성된다. 여기에는 49~99개의 중간상태가 존재한다.
- 중간 상태를 파일로 기록하는 과정을 구체화라고 한다.

단점
- 맵리듀스 작업은 입력을 생성하는 모든 선행 작업이 완료됐을 때만 시작 가능하다. 선행 작업을 기다려야한다.
- 매퍼는 종종 중복되기도 한다. (리듀서에서 막 기록된 동일한 파일을 다시 한번 매퍼가 읽어서 파티셔닝과 정렬 단계를 준비한다)
- 중간 상태를 저장하는 것은 중간 상태 파일들이 여러 장비에 걸쳐 복제됐다는 의미인데 중간상태의 의미없는 데이터에는 과잉조치다.

#### 10.3.1.1. 데이터플로 엔진

#### 10.3.1.2. 내결함성

#### 10.3.1.3. 구체화에 대한 논의

### 10.3.2. 그래프와 반복 처리

- 전체 그래프에서 오프라인으로 처리를 수행하거나 분석을 하는 등 일괄 처리 맥락에서 그래프를 살펴보는 것도 흥미롭다.
- 추천 엔진 같은 머신러닝이다 랭킹 시스템 분야에서도 그래프 처리의 필요성이 떠오르고 있다. 예를 들면 가장 유명한 그래프 분석 알고리즘 중 하나인 페이지랭크를 들 수 있다.

#### 10.3.2.1. 프리글 처리 모델

#### 10.3.2.2. 내결함성

#### 10.3.2.3. 병렬 실행


### 10.3.3. 고수준 API와 언어

#### 10.3.3.1. 선언형 질의 언어로 전환

#### 10.3.3.2. 다양한 분야를 지원하기 위한 전문화


## 정리

분산 일괄 처리 프레임워크가 해결해야 할 두 가지 중요한 문제가 있다.
- 파티셔닝
- 내결함성

맵리듀스에서 사용하는 몇 가지 조인 알고리즘
- 정렬 병합 조인
- 브로드캐스트 해시 조인
- 파티션 해지 조인

일괄처리 시스템은 입력을 그대로 두고 출력만 만들기에 재시작하기 쉽고 쉽게 적용할 수 있다.