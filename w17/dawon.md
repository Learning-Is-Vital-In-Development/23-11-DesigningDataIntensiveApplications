
![image](https://github.com/Learning-Is-Vital-In-Development/23-11-DesigningDataIntensiveApplications/assets/60343930/cbf4277f-68ad-4225-9510-c0d1aec86e9d)

2부에서는 request, response, query, result에 관한 내용을 다뤘다.
  - 이번장에서는 맵리듀스 알아보고 맵리듀스와 다른 일괄처리 알고리즘과 프레임워크 살펴볼 것임
  - 현대 데이터 시스템에서 이것을 어떻게 사용하는지 알아본다. 일단 우선 표준 유닉스 도구를 사용해 데이터 처리하는 것을 볼 것임.
  - 유닉스가 주는 아이디어와 교훈이 대규모 이기종 분산시스템으로 이어진다.  

시스템을 3가지 유형으로 구분

    - 서비스(온라인 시스템) 
        1) 서비스는 클라이언트로부터 요청이나 지시가 들어올 때까지 기다림, 응답시간은 성능측정에 중요한 지표이며, 가용성이 중요하다.

    - 일괄 처리 시스템(오프라인 시스템) : 처리량이 대표적인 지표
        1) 일괄처리는 신뢰할 수 있고 확장 가능하며 유지보수하기 쉬운 애플리케이션을 구축하는데 매우 중요한 요소 
        2) 2004년 발표한 일괄처리 알고리즘인 MapReduce은 이후에 하둡, 카우치DB, 몽고DB등 다양한 오픈소스 시스템에서 구현
        3) 데이터 웨어하우스용으로 개발했던 병렬 처리 시스템보다 상당히 저수준 프로그래밍 모델이다. 
           그러나 범용 하드웨어만을 사용해 처리한 데이터 규모 면에서 상당히 진보
        4) 지금은 맵리듀스 중요성이 떨어지지만 일괄처리가 왜 유용한지 알려주기 때문에 이해해야함 
    
    - 스트림 처리 시스템(준실시간 시스템) : near-real-time processing / nearline processing
        1) 온라인과 오프라인 사이의 어딘가에 위치하기에 준실시간 처리라고 부릅니다. 일처리 작업은 정해진 크기의 
          입력 데이터를 대상으로 작동하지만 스트림 처리는 입력 이벤트가 발생한 직후 바로 작동한다.
-------
### 1. 유닉스 도구로 일괄 처리하기
웹서버가 있고 들어온 요청이 처리될 때마다 로그 파일에 한 줄씩 추가한다. 
예) 아래 로그 한줄 nginx의 기본 액세스 로그 형식을 사용

로그 형식 정의
![image](https://github.com/Learning-Is-Vital-In-Development/23-11-DesigningDataIntensiveApplications/assets/60343930/5500df96-dada-4d5f-93e7-cca80c11f287)

로그가 들어올때마다 위와 같은 로그 정의서에 따라 해석이 된다.
 
### 2. 단순 로그 분석
다양한 도구를 사용해 트래픽 보고서를 깔끔하게 만들 수 있다.
![image](https://github.com/Learning-Is-Vital-In-Development/23-11-DesigningDataIntensiveApplications/assets/60343930/1160d0ec-e704-47a7-88c4-04e537be2a70)

위는 기본 유닉스 도구를 이용해 웹사이트에서 가장 인기가 높은 페이지 5개를 뽑는 유닉스 셸에서 작성한 내용이다.
익숙하지 않다면 이해하기 쉽지 않지만 이 방식은 상당히 강력하다.

### 3. 연쇄 명령 대 맞춤형 프로그램 
루비로 작성하면 다음과 같다.
![image](https://github.com/Learning-Is-Vital-In-Development/23-11-DesigningDataIntensiveApplications/assets/60343930/a64c8df6-aecc-4844-9d51-84eec2004cab)

유닉스 연쇄 파이프보다 간결하지 않지만 더 읽기 쉽다.
표면적인 문법의 차이를 빼고 두가지 방법은 실행 흐름이 크게 다르다.

### 4. 정렬 대 인메모리 집계
루비스크립트 : URL 해시 테이블을 메모리에 유지함
유닉스 파이프라인 : 해시테이블 x 

중소 규모의 웹사이트 대부분은 고유 URL과 해당 URL 카운트를 대략 1GB 메모리에 담을 수 있다.
반면 허용 메모리보다 작업 세트가 크다면 정렬 접근법을 사용하는 것이 좋다. -> SS테이블과 LSM트리에서 설명한 원리와 유사
먼저 데이터 청크를 메모리에 정렬하고 청크를 세그먼트 파일로 디스크에 저장한다.
그다음 각각 정렬된 세그먼트 파일 여러 개를 한 개의 큰 정렬 파일로 병합한다.

### 5. 유닉스 철학
유닉스 파이프라인 
-> 다른 방법으로 데이터 처리가 필요할 때 정원 호스와 같이 여러 다른 프로그램을 연결하는 방법이 필요하다. 이것은 I/O 방식이기도 하다.

### 6. 동일 인터페이스
어떤 프로그램의 출력을 다른 프로그램의 입력으로 쓰고자한다면 이들 프로그램은 같은 데이터 형식을 사용해야한다. -> 호환 가능한 인터페이스
유닉스에서 인터페이스는 파일(파일 디스크립터) -> 파일은 단지 순서대로 정렬된 바이트의 연속 
- 동일 데이터 모델인 데이터베이스 간에도 한쪽에서 다른쪽으로 데이터 옮기는게 쉽지 않다. 데이터 발칸화(balkanization)되는 이유는 유닉스 도구와 같은 통합이 부족해서

### 7. 로직 연결과 연결의 분리

유닉스 도구의 다른 특징 중 하나는 표준 입력(stidn)과 표준 출력(stdout)을 사용한다는 점이다.
이러한 경우와 같이 입력이 어디서부터 들어오는지, 출력이 어디로 나가는지 신경을 쓰거나 알 필요가 없다.
이러한 형태를 느슨한 결합(loose coupling) , 지연 바인딩(late binding), 또는 제어 반전(inversion of control) 이라고도 한다.

파이프는 한 프로세스의 stdout을 다른 프로세스의 stdin과 연결한다. 
이때 중간 데이터를 디스크에 쓰지 않고 작은 인메모리 버퍼를 사용해 프로세스 간 데이터를 전송한다.
 
하지만 stdin과 stdout 사용시 몇가지 제약 사항이 있다.
    - 프로그램 출력을 파이프 이용해 네트워크와 연결하지 못한다.

### 8. 투명성과 실험
유닉스 도구가 성공적인 이유 중 하나는 진행 사항을 파악하기가 상당히 쉽기 때문이다.
    -유닉스 명령에 들어가는 입력 파일은 일반적으로 불변으로 처리된다.
    -어느 시점이든 파이프라인을 중단하고 출력을 파이프를 통해 less로 보내 원하는 형태의 출력이 나오는지 확인할 수 있다.
    -특정 파이프라인 단계의 출력을 파일에 쓰고 그 파일의 다음 단계의 입력으로 사용할 수 있다.

이러한 가장 큰 제약은 단일 장비에서만 실행되며 이러한 이유로 하둡 같은 도구가 필요하다.

### 9. 맵리듀스와 분산 파일 시스템
맵리듀스는 유닉스 도구와 비슷한 면이 있지만 수천대의 장비로 분산해서 실행이 가능하다. 
단일모드(The standalone mode) 맵리듀스 작업은 하나 이상의 입력을 받아 하나 이상의 출력을 만들어낸다는 점에서 단일 유닉스 프로세스와 유사하다.

1) 출력 파일은 순차적으로 한번만 쓰여지고 파일에 이미 쓰여진 부분은 고치지 않는다.
2) 분산 파일 시스템 상의 파일을 입력과 출력으로 사용한다. 
3) 하둡 맵리듀스 구현에서 파일시스템은 HDFS(Hadoop Distributed File System)이라고 하는데 GFS(Google File System)를 재구현한 오픈소스이다.
    - HDFS외에도 GlusterFS, QFS(Quantcast File) 등 다양한 분산 파일 시스템이 있다.
    - 아마존 S3, 애저 blob저장소, 오픈스택 스위프트 같은 객체 저장소도 여려면에서 유사하다. -> 이번장에서는 대부분 HDFS 사용함. 
4)HDFS는 비공유 원칙을 기반으로 하는데 NAS와 SAN 아키텍처에서 사용하는 공유 디스크 방식과는 반대다.
5) HDFS는 각 장비에서 실행되는 데몬 프로세스로 구성되며 다른 노드가 해당 장비에 저장된 파일에 접근하게끔 네트워크 서비스를 제공한다.
6) 네임노드라 부르는 중앙 서버는 특정 파일 블록이 어떤 장비에 저장됐는지 추적한다.
-> HDFS는 개념적으로 매우 큰 하나의 파일 시스템이고 데몬이 실행 중인 모든 장비의 디스크를 사용할 수 있다. 

7) 장비가 죽거나 디스크가 실패하는 경우를 대비하기 위해 파일 블록은 여러 장비에 복제된다. (단순 복제 혹은 삭제 코딩)
   RAID랑 비슷하지만 파일의 접근과 복제가 특별한 하드웨어 장치 없이 평범한 데이터 센터 네트워크 상에서 이뤄진다는 점이다.

### 10. 맵리듀스 작업 실행하기
맵리듀스란? 
    - HDFS 같은 분산 파일 시스템 위에서 대용량 데이터 셋을 처리하는 코드를 작성하는 프로그램이 프레임 워크
        1) 입력 파일을 읽고 레코드로 쪼갠다. 웹 서버 로그 예제의 로그 한줄이 레코드가 된다. (레코드 분리자 \n사용)
        2) 각 입력 레코드마다 mapper함수 호출해서 키와 값 추출한다. 
        3) 키를 기준으로 키-값 쌍 모두 정렬. 이 과정은 로그 예제에서 첫번째 sort에 해당
        4) 청렬된 키-값 쌍 전체를 대상으로 reduce 함수 호출
    - 맵리듀스 작업하나는 4단계로 수행된다. 2&4단계 map,reduce는 사용자가 직접 작성한 데이터 처리코드.
매퍼(mapper)
    - 매퍼는 모든 입력 레코드마다 한 번씩만 호출하며, 레코드로부터 키와 값을 추출하는 작업이다. 각 레코드는 독립 처리된다.
리듀서(reducer)
    - 매퍼가 생산한 키-값 쌍을 받아 같은 키를 가진 레코드를 모으고 출력 레코드를 생산한다. 예시로 동일 URL의 출현 횟수가 있다. 

### 11. 맵리듀스의 분산 실행 
하둡 맵리듀스 작업에서 데이터플로를 보여준다. (그림)
    - 맵리듀스 작업의 병렬 실행은 파티셔닝을 기반으로 한다. 
    - 작업 입력으로 HDFS상의 디렉토리를 사용하는 것이 일반적. 
    - 입력 디렉토리 내 각 파일 또는 파일 블록을 독립 파티션으로 간주한다. -> 맵 태스크에서 처리하는
    - 맵리듀스 스케쥴러 : 사진에는 없지만 장비 RAM,CPU 여유가 있다면 데이터 가까이에서 연산하기 원리에 따라 스케줄러는 입력 파일이 있는 장비에서 작업을 수행함.
        -> 이 원리를 적용하면 네트워크 통해 입력 파일 복사 부담 & 네트워크 부하 감소하고 지역성이 증가한다.


맵 태스크에서 실행될 애플리케이션 코드는 맵리듀스 프레임워크가 작업을 수행하기 적절한 장비로 코드를 복사함
복사 후 매퍼 태스크 시작되고 입력 파일에서 한번에 레코드 하나씩을 읽어 매퍼 콜백 함수로 전달한다. -> 매퍼의 출력은 키-값 쌍으로 구성.
리듀서 연산도 파티셔닝 된다. 
맵 태스크 수는 입력 파일의 블록수로 결정
리듀스 테스크는 사용자가 설정 -> 맵/리듀스 태스크 수는 다를 수 있다. 
맵리튜스 프레임워크는 같은 키면 같은 키를 가진 모든 키-값 쌍을 같은 리듀서에서 처리됨을 보장하는데, 
특정 키-값 쌍이 어느 리듀스 태스크에서 수행될지 결정하기 위해 키의 해시값을 사용한다.
리듀서를 기준으로 파티셔닝 하고 정렬한 뒤 매퍼로부터 데이터 파티션을 복사하는 과정을 "셔플"이라고 한다. -> 맵리듀스에서 셔플은 임의로 섞지 X

### 12. 맵리듀스 워크플로
맵리듀스 작업 하나로 해결할 수 있는 문제의 범위는 제한적이다. 
    -> 로그 분석예제에서 처럼 단일 맵리듀스 작업으로 URL당 페이지뷰 수는 구해도 가장 인기 있는 URL은 구할 수 없다 때문에 추가 정렬작업 필요
따라서 맵리듀스 작업을 연결해 workflow로 구성하는 방식은 꽤 일반적이다. 
    -> 맵리듀스 작업 하나의 출력을 다른 맵리듀스 작업의 입력으로 사용하는 식
선행 작업이 완전히 끝나야만 다음 작업을 시작할 수 있다.

스케줄러 : Oozie, Azkaban, Luigi, Airflow, Pinball
    - 추천 시스템 구축하는데 사용하는 워크플로는 50개에서 100개가 일반적이다. 
하둡용 고수준 도구 : Pig, Hive, Cascading, Crunch, FlumeJava
    - 다중 맵리듀스를 서로 적절하게 자동으로 엮어 워크플로를 설정한다. 
 
### 13. 리듀스 사이드 조인과 그룹화 
join은 2장에서 데이터 모데로가 질의 언어 논할 떄 다뤘다. 연관된 레코드 양쪽에 모두 접근해야할시 조인은 필수! 
-> 비정규화 작업으로 조인을 줄일 수 있지만 완전 제거는 힘들다. 
    - 관계형 모델 : 외래키 foreign key
    - 문서형 모델 : 문서 참조 document reference
    - 그래프 모델 : 간선 edge 
데이터베이스는 일반적으로 색인(index)를 활용해 레코드 위치를 찾는다.
맵 리듀스는 이러한 색인 개념이 없어서 입력 파일 전체 내용을 읽는다. -> 전체 테이블 스캔 full table scan 연산이라 칭한다. 
    -> 적은 수 레코드 읽을 시 매우 비효율적 

### 14. 사용자 활동 이벤트 분석 예제
사용자 활동 이벤트와 사용자 데이터베이스를 활용해서 연산을 시킬 떄 
    - 간단 구현 : 하나씩 활동 이벤트 훑으며 나오는 모든 사용자 ID마다 원격 서버에 있는 사용자 DB에 질의 -> 데이터 과부화 되기 쉬움
    - 권장 구현 : 데이터 사본을 가져와 이벤트 로그가 저장된 분산 파일 시스템에 저장하기 
        -> 사용자DB와 사용자 활동 레코드가 같은 HDFS상에 위치하여 맵리듀스를 사용해 연관된 레코드 끼리 모두 같은 장소로 모아 효율적 처리 가능!
        -> 일괄 처리에서 처리량 높이기 위해 가능한 한 장비내에서 연산을 수행해야하기 때문

### 15. 정렬 병합 조인
같은 사용자의 활동 이벤트와 사용자 레코드는 리듀서의 입력으로 서로 인접해서 들어간다. 
보조정렬(secondary sort) 
    - 리듀서가 항상 사용자 DB를 먼저 보고 활동 이벤트를 시간 순으로 보게 하는 식으로 맵리듀스에서 작업 레코드를 재배열하기도 한다. 
보조 정렬 이후 리듀서가 수행하는 로직은 간단함
    - 리듀서는 지역변수에 생년월일 저장하고 그다음부터 같은 사용자 ID가 동일하 ㄴ이벤트 순회해서 url - viewer age in year 이렇게 쌍 출력
    - 그러면 맵리듀스 작업들이 각 url마다 본 사람의 연령분포 계산하고 연령대별 클러스터링 가능
    - 리듀서는 특정 사용자 ID의 모든 레코드를 한번에 처리하므로 한번에 사용자 한명의 레코드만 메모리에 유지하면 되므로 네트워크에 아무 요청 보낼 필요가 없다.
        -> 정렬 병합 조인 sort merge join 이라고 한다. 매퍼 출력이 키로 정렬된 후에 리듀서가 조인의 양측의 정렬된 레코드 목록 병합하기 때문.

### 16. 같은 곳으로 연관된 데이터 가져오기 
병합 정렬 조인 중 매퍼와 정렬 프로세스는 특정 사용자 ID로 조인 연산을 할 때 필요한 모든 데이터를 한 곳으로 모은다. 
그래서 사용자 ID 별로 리듀서를 한 번만 호출한다. -> 필요한 데이터를 사전에 줄세웠기 때문에 처리량 높게 메모리 부담 낮게 유지 가능

맵리듀스 프로그래밍 모델은 연산 물리적 네트워크 통신 / 테이터 처리 애플리케이션 로직 분리-> 전형적 데이터베이스 사용유형과 대조적
데이터 베이스로부터 데이터 가져오는 요청은 애플리케이션 코드 내에서 발생한다. 
맵리듀스는 모든 네트워크 통신을 직접 관리하기 때문에 특정 장비가 죽어도 고민할 필요가 없다. 
맵리듀스는 애플리케이션 로직에 영향이 가지않게 실패한 태스크는 확실하게 재시도 한다.

### 17. 그룹화 
맵리듀스로 그룹화 연산을 구현하는 가장 간단한 방법은 매퍼가 키-값 쌍을 생성할 때 그룹화할 대상을 키로 하는 것이다. 
그러면 파티션 및 정렬 프로세스가 같은 키를 가진 모든 레코드를 같은 리듀서로 모은다. 즉 맵리듀스 위에서 그룹화와 조인의 구현은 상당히 유사!
    얘) 특정 사용자가 취한 일련의 활동을 찾기 위해 사용자 세션별 활동 이벤트를 수집 분석할때도 일반적으로 그룹화를 사용한다. 
        -> 세션화 (sessionization) 
        -> 사용자가 vesion1 & 2를 비교해서 어디서 더 구매했는지 AB테스트 가능 혹은 어떤 마케팅 활동이 더 가치있는지 분석하는데 활용

### 18.쏠림 다루기
키 하나에 너무 많은 데이터가 연관되면 같은 키 가지는 모든 레코드를 같은 장소로 모은 패턴이 제대로 작동 안함
    예) 소셜 네트워크에서 소수의 유명인사는 팔로워가 수백만명에 이르기도 하지만 일반 사람들은 많아봐야 수백명 연결
        -> 이러한 불균형한 활성 데이터베이스 레코드를 린치핀 객체 linchpin object 또는 핫키 hot key라 함
        - 유명인사에 대한 모든 활동을 리듀서 한개에서 모은다면 상당한 쏠림현상이 생긴다 -> hot spot 
        - 모든 매퍼와 리듀서가 완전히 끝나야지만 맵리듀스 작업이 끝나기 때문에 가장 느린 리듀서가 작업을 완료할때까지 후속 잡업은 시작을 못함
핫스팟 작업 완화 알고리즘 
- pig skewed join
    -> 핫키 판단을 위해 샘플링하고, 조인 수행 시 임의로 선택한 리듀서로 보냄. 핫 키를 여러 리듀서에 퍼뜨려서 처리하게 하는 방법
    -> 파티셔닝된 데이터베이스에서 핫스팟을 경감시키기 위해 랜덤화 사용하는 기법과 유사 
- HIVE는 쏠린 조인을 최적화 할 때 다른 방법을 사용한다. 
    - 핫키는 테이블 메타데이터에 명시적으로 지정하고 핫키와 관련된 레코드를 나머지 키와는 별도 파일에 저장한다. 
      해당 테이블에서 조인할 때 핫키를 가지는 레코드는 맵사이드 조인(amp side join)을 사용해 처리한다.

### 19. 맵 사이드 조인 map side join
지난 절 설명한 여러 조인 알고리즘은 실제 조인을 리듀서에서 수행하기 때문에 reduce side join이라 한다. 
여기서 매퍼는 각 입력 레코드에서 키와 값을 추출해 추출한 키-값 쌍을 리듀서 파티션으로 할당하고 키별로 정렬하는, 입력데이터 준비역할을 한다.
    -> 리듀스 사이드 접근법
        장점 :  입력 데이터에 대한 특정 가정이 필요없다. 입력 데이터의 속성과 구조가 무엇이든 매퍼는 데이터를 조인할 준비 가능 
        단점 : 정렬 후 리듀서로 복사한 뒤 리듀서 입력 병합하는 모든 과정 비용이 상당. 허용된 메모리 버퍼에 따라 데이터 여러번 디스크 저장해야할수도
    -> 맵 사이드 조인 접근법
        입력 데이터 특정이 가능하다면 더 빠른 조인 방법. 축소된 맵리듀스 작업으로 리듀서는 물론 정렬 작업도 없다. 
        대신 각 매퍼가 분산 파일 시스템에서 단순히 입력 파일 블럭 하나를 읽어 다시 해당 분산 파일 시스템에 출력하는 것이 전부

### 20. 브로드캐스트 해시 조인
브로드 캐스트 해시 조인(broad cast hash join) 
    -> 브로드 캐스트라는 단어는 큰 입력의 파티션 하나를 담당하는 각 매퍼는 작은 입력 전체를 읽는 다는 것
    - 브로드캐스트라는 단어는 큰 입력의 파티션 하나를 담당하는 각 매퍼는 작은 입력 전체를 읽는 다는 것을 의미한다. 
     (그래서 실질적으로 작은 입력을 큰 입력의 모든 파티션에 "브로드 캐스트"한다.) 
    - 각 조인의 입력을 인메모리 해시 테이블로 적재하는 대신 로컬 디스크에 읽기 전용 색인으로 작은 조인 입력을 정하기 도함. 

### 21. 파티션 해시 조인
파티션 해시 조인은 조인할 두입력 모두를 같은 키와 해시 함수를 기반으로 같은 파티셔닝해야 작동한다.
제대로 파티셔닝이 작동했다면 조인할 레코드가 모두 같은 번호 파티션에 위치해있고, 각 매퍼는 각 입력 데이터셋 중 파티션 한개만 읽어도 충분하다. 
    -> 각 매퍼의 해시테이블에 적재해야할 데이터 양을 줄일 수 있음
HIVE에서는 partitioned hash join을 하이브에서는 bucketed map join이라고 한다. 

### 22. 맵 사이드 병함 조인
입력 데이터셋이 같은 방식으로 파티셔닝 됐을 뿐 아니라 같은 키 기준으로 정렬되었을 시 변형된 맵 사이드 조인 적용 가능
map side merge join 이 가능하면 선행 맵리듀스 작업이 이미 입력 데이터셋을 파티셔닝하고 정렬해놓았다는뜻 

### 23. 맵 사이드 조인을 사용하는 맵리듀스 워크플로
리듀스 사이드 조인 (조인 키로 파티셔닝 후 정렬 출력) / 맵 사이드 조인 (큰입력과 동일방법으로 파티셔닝 후 정렬) 
    -> 파티션 조인을 하든 브로드캐스트 조인을 하든 큰 조인 입력의 파일 블록마다 맵태스크가 실행됨
맵 사이드 조인을 수행하기 위해서는 크기,정렬, 입력 데이터의 파티셔닝 같은 제약 사항이 따름 
하둡 생태계에서는 데이터셋 파티셔닝 관련 메타데이터를 관리하는데 H카탈로그나 HIVE메타스토어를 사용하기도 한다. 

### 24. 일괄처리 워크플로의 출격
일괄 처리는 어디에 적합할까? 트랜잭션 처리(OLTP)도 아니고 분석(OLAP)도 아니다. -> 굳이 따지자면 입력데이터셋을 대부분 스캔하는게 일반적이라 분석에 가깝다.
그러나 맵리듀스 작업의 워크플로는 분석 목적으로 사용하는 sql질의와 다르다.

### 25. 검색 색인 구축
 색 엔진 색인 구축을 위해 구글에서 맵리듀스 사용.
정해진 문서 집합을 대상으로 전문 검색이 필요하다면 일괄 처리가 색인을 구축하는 데 매우 효율적이다.
매퍼는 필요에 따라 문서 집합을 파티셔닝 하고 각 리듀서가 해당 파티션에 대한 색인을 구축한다.
 
### 26. 일괄 처리의 출력으로 키-값을 저장
분류기 같은 머신러닝 시스템(스팸 필터, 이상 검출, 이미지 인식 등)을 구축하거나 추천 시스템을 구축할 수도 있다.
일괄 처리 값을 저장해야 하는데 이를 DB에 태우면 각종 문제가 생길 수 있다. (DB 과부하, 네트워크 요청으로 인한 성능 저하 등등)
그래서 내부에 일괄 처리 작업 내부에 데이터베이스 파일을 생성해서 저장한다.(Voldmort, Terrapin, ElephantDB, HBase Bulk loading)
 
### 27. 일괄 처리 출력에 관한 철학
코드에 버그가 있어 출력이 잘못되거나 오염됐다면 코드를 이전 버전으로 돌리고 작업을 재수행해 간단하게 출력을 고칠 수 있다. (인적 내결함성)
minimizing irreversibility
연결 작업과 로직을 분리.

### 28. 하둡 분산 데이터 베이스 비교 

MPP(Massively Parallel Processing, 분석 SQL을 병렬 질의에 초점) 
MapReduce & Distributed File System(아무 프로그램이나 실행할 수 있는 운영체제 같은 속성)

### 29. 저장소 다양성
MPP
    - 대게 데이터베이스에 특화된 저장형태로 가져오기 전에 데이터와 질의 형태를 신중하게 선행 모델링 해야함
    - 보기에 이상적이지만 현실에서는 이상적인 데이터 모델을 만들려고 하기보다 빨리 사용하는게 더 가치있다.
    - 세심한 스키마 설계는 중앙 집중식 데이터 수집을 느리게 만든다. 
-> data lake개념: 원시데이터수집하고 스키마 설계 나중에 고민하면 데이터 수집 속도 올라감
하둡 
    - data dumping: 제약 없는 데이터 덤핑은 데이터가 어떤 형태여도 상관없다 HDFS로 덤프 가능 
    - schema-on-read 접근법 : 데이터 해석은 소비자가 해결할 문제! 
    - 원시 상태로 덤프하는 것만으로 여러 변환이 가능하다 이접근법은 초밥 원리 sushi principle이라고 함.-> 원시데이터가 더 좋다
    - ETL 프로세스 구현하는데 종종 쓰임 트랜잭션 처리 시스템에서 데이터를 원시 형태로 분산 파일 시스템에 덤프
      그 후 맵리듀스 작업은 데이터 정리 후 관계형으로 변환 후 데이터 분석 위해 MPP 데이터 웨어하우스로 옮긴다. 

### 30. 처리 모델 다양성
머신러닝, 추천 시스템, 전문 검색 색인 등 범용적인 데이터 처리 모델이 필요한 경우가 있다.
맵리듀스를 이용하면 자신이 작성한 코드를 대용량 데이터셋 상에서 쉽게 실행할 수 있다

HDFS와 맵리듀스가 있으면 그 위에 SQL질의 실행 엔진 구축가능! 
    -> HIVE가 그런 역할을 한다.
시간이 흘러 맵리듀스가 너무 제한 적이고 어떤 형태의 처리에서는 성능도 나쁘다는 것을 깨달았다. 
    -> 하둡 위에서 다른 다양한 처리 모델이 개발 되었다. (SQL과 맵리듀스만으로는 불충분)
결정적으로 이런 다양한 처리 모델은 모두 단일 공유 클러스터 장비에서 실행되고 분산 파일 시스템상에 존재하는 동일한 파일에 접근 가능하다
하둡 접근법은 다른 종류 처리를 위해 여러 다른 특정 시스템으로 데이터를 보낼 필요가 없다. 
하둡 시스템은 동일한 클러스터 내에서 다양한 작업부하를 함께 지원할 수 있을정도로 충분히 유연하다. 
    -> 데이터 옮길 필요 x 데이터 가치를 창출하기 쉽고 새로운 처리 모델 실험도 쉽다!

### 31. 빈번하게 발생하는 결함을 줄이는 설계 
맵리듀스는 실패를 견딜 수 있고, 개별 태스크 수준에서 작업을 재수행한다.
또한 데이터를 되도록 디스크에 기록하려 한다.
일괄 처리 작업은 우선순위가 낮을 수 있는데, 온라인 서비스에서 쓰고 남은 자원을 모아 연산을 수행할 수 있게 되어 있다.
