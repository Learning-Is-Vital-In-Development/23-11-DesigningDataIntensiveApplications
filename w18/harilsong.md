# 일괄 처리

시스템을 구축하는 방식에는 아래와 같은 3가지 방식이 자주 사용된다.

- 서비스(온라인 시스템)
- **일괄 처리 시스템(오프라인 시스템)**
- 스트림 처리 시스템(준실시간 시스템)

이 중 일괄 처리는 신뢰할 수 있고 확장 가능하며 유지보수하기 쉬운 애플리케이션을 구축하는 데 매우 중요한 구성요소.

일괄 처리 알고리즘인 **맵리듀스(MapReduce)** 는 "구글을 대규모로 확장 가능하게 만든 알고리즘"이라 불렸다. 이후 [[Hadoop|Hadoop]], [[Couch DB]], [[MongoDB]] 등 다양한 오픈소스 시스템에서 구현됐다.

## 유닉스 도구로 일괄 처리하기

### 단순 로그 분석

```bash
cat /var/log/nginx/access.log | # 로그를 읽는다
    awk '{print $7}' | # 줄마다 공백으로 분리해서 7번째 필드만 출력
    sort | # 알파벳 순으로 정렬
    uniq -c | # 중복을 제거하며 중복 횟수를 함께 출력
    sort -r -n | # -n 옵션을 사용하여 첫 번째로 나타나는 숫자를 기준으로 내림차순(-r) 정렬
    head -n 5. # 앞에서부터 5줄만(-n 5) 출력
```

이런  유닉스 명령 방식은 짧지만 상당히 강력하다. 수 기가바이트의 로그 파일을 수 초 내로 처리할 수 있고, 필요에 따라 분석 방법을 수정하기 쉽다.

```bash
# 설치된 formula 중에서 원하는 목록을 리스트업하기, uninstall 의 인자로 전달하면 한 번에 삭제도 가능하다
brew list --formula | fzf -m >> ~/selected
```

#### 연쇄 명령 대 맞춤형 프로그램

```ruby
counts = Hash.new(0)

File.open('/var/log/nginx/access.log') do |file|
    file.each do |line|
        url = line.split[6]
        counts[url] += 1
    end
end

top5 = counts.map{|url, count| [count, url] }.sort.reverse[0...5]
top5.each{|count, url| puts "#{count} #{url}"}
```

이 프로그램은 유닉스 파이프보다 간결하지는 않지만 더 읽기 쉽다. 그러나 두 가지 방법은 실행 흐름이 크게 다르다. 대용량 파일을 분석해보면 차이가 확연히 드러난다.

#### 정렬 대 인메모리 집계

앞선 루비 스크립트는 URL 해시 테이블을 메모리에 유지한다. 해시 테이블에는 각 URL 이 출현한 수를 매핑한다. 유닉스 파이프라인 예제에는 이런 해시 테이블이 없다. 대신 정렬된 목록에서 같은 URL 이 반복해서 나타난다.

- 중소 규모의 웹사이트 대부분은 고유 URL 과 해당 URL 카운트를 대략 1GB 메모리에 담을 수 있음
- 작업 세트(임의 접근이 필요한 메모리 양)이 충분히 작다면 인메모리 해시테이블도 잘 작동

**허용 메모리보다 작업 세트가 크다면 정렬 접근법**을 사용하는 것이 좋다.

1. 데이터 청크를 메모리에서 정렬하고 청크를 세그먼트 파일로 디스크에 저장
2. 각각 정렬된 세그먼트 파일 여러 개를 한 개의 큰 정렬 파일로 병합
3. 병합 정렬은 순차적 접근 패턴을 따르고 이 패턴은 디스크 상에서 좋은 성능을 보여줌

GNU Coreutils(리눅스)에 포함된 sort 유틸리티는 메모리보다 큰 데이터셋을 자동으로 디스크로 보내고 자동으로 여러 CPU 코어에서 병렬로 정렬한다. 따라서 유닉스 연쇄 명령이 메모리 부족 없이 큰 데이터 셋으로 확장 가능하며, 병목이 있다면 디스크에서 입력 파일을 읽는 속도일 것이다.

### 유닉스 철학

1. 각 프로그램이 한 가지 일만 하도록 작성하라. 새 작업을 하려면 새로운 프로그램을 작성하라.
2. 모든 프로그램의 출력은 다른 프로그램의 입력으로 쓰일 수 있다고 생각하라.
3. 소프트웨어를 빠르게 써볼 수 있도록 설계하고 구축하라.
4. 프로그래밍 작업을 줄이려면 미숙한 도움보단 도구를 사용하라. 사용 후 바로 버린다고 할지라도 도구를 써라.

sort 는 이 훌륭한 예다. sort 의 구현은 대부분의 프로그래밍 언어에 포함된 표준 라이브러리보다 확실히 뛰어나다. 단독으로는 그렇게 유용하지 않지만, 다른 도구(uniq 등)와 결합할 때 비로소 강력해진다.

bash 같은 유닉스 셸을 사용하면 작은 프로그램들을 가지고 놀랄 만큼 강력한 데이터 처리 작업을 쉽게 구성할 수 있다. 많은 도구가 서로 다른 그룹, 사용자에 의해 만들어졌음에도 유닉스에 이런 결합성을 부여하는 것은 무엇일까?

#### 동일 인터페이스

어떤 프로그램의 출력을 다른 프로그램의 입력으로 쓰고자 한다면 이들 프로그램은 같은 데이터 형식을 사용해야 한다. 특정 프로그램이 다른 어떤 프로그램과도 연결 가능하려면 프로그램 모두가 같은 입출력 인터페이스를 사용해야 한다.

**유닉스에서의 인터페이스는 파일(좀 더 정확히는 파일 디스크립터)** 이다. 파일은 단지 순서대로 정렬된 바이트의 연속이다. 다음과 같은 것들을 표현할 수 있다.

- 파일시스템의 실제 파일
- 프로세스 간의 통신 채널(유닉스 소켓, 표준 입력, 표준 출력)
- 장치 드라이버
- TCP 연결을 나타내는 소켓

이 정도로 매끄럽게 협동하는 프로그램이 있다는 건 아주 예외적이다. 동일한 데이터 모델인 데이터베이스 간에도 한쪽에서 다른 쪽으로 데이터를 옮기는 게 쉽지 않다.

#### 로직과 연결의 분리

유직스 도구의 다른 특징으로는 표준 입력(stdin)과 표준 출력(stdout)을 사용한다는 점. 파이프는 한 프로세스의 stdout 을 다른 프로세스의 stdin 과 연결한다. 이 때 **중간 데이터를 디스크에 쓰지 않고 작은 인메모리 버퍼를 사용해 프로세스 간 데이터를 전송**한다.

프로그램에서 입출력을 연결하는 부분을 분리하면 작은 도구로부터 큰 시스템을 구성하기가 훨씬 수월하다.

프로그램을 직접 작성해 운영체제에서 지원하는 도구와 같이 사용할 수 있다. 프로그램을 단순히 stdin 으로부터 입력을 읽어 stdout 으로 출력하도록 작성하면 데이터 처리 파이프라인에 바로 끼워 사용할 수 있다.

#### 투명성과 실험

- 유닉스 명령에 들어가는 입력 파일은 일반적으로 불변으로 처리된다.
- 어느 시점이든 파이프라인을 중단하고 출력을 파이프를 통해 less 로 보내 원하는 형태의 출력이 나오는지 확인할 수 있다.
- 특정 파이프라인 단계의 출력을 파일에 쓰고 그 파일을 다음 단계의 입력으로 사용할 수 있다.

유닉스 도구는 관계형 데이터베이스의 질의 최적화 도구와 비교하면 상당히 불친절하고 단순하지만, 놀라울 정도로 유용해서 실험용으로 매우 좋다.

유닉스 도구를 사용하는데 **가장 큰 제약은 단일 장비에서만 실행된다는 점**이다. 바로 이 점이 [[Hadoop]] 같은 도구가 필요한 이유다.

## 맵리듀스와 분산 파일 시스템

- 유닉스 도구와 비슷한 면이 있지만 수천 대의 장비로 분산해서 실행이 가능하다는 점에서 차이.
- 분산 파일 시스템 상의 파일을 입력과 출력으로 사용

하둡 맵리듀스 구현에서 이 파일 시스템은 HDFS(Hadoop Distributed File System)라고 하는데 GFS(Google File System)를 재구현한 오픈소스다.

HDFS 는 **비공유 원칙을 기반**으로 하는데 NAS(Network Attached Storage)와 SAN(Storage Area Network) 아키텍처에서 사용하는 공유 디스크 방식과는 반대다.

- 각 장비에서 실행되는 데몬 프로세스로 구성
- 네임노드(NameNode)라고 부르는 중앙 서버는 특정 파일 블록이 어떤 장비에 저장됐는지 추적
- 파일 블록은 여러 장비에 복제

### 맵리듀스 작업 실행하기

#### 맵리듀스의 분산 실행

#### 맵리듀스 워크플로

### 리듀스 사이드 조인과 그룹화

#### 사용자 활동 이벤트 분석 예제

#### 정렬 병합 조인

#### 같은 곳으로 연관된 데이터 가져오기

#### 그룹화

#### 쏠림 다루기

### 맵 사이드 조인

#### 브로드캐스트 해시 조인

#### 파티션 해시 조인

#### 맵 사이드 병합 조인

#### 맵 사이즈 조인을 사용하는 맵리듀스 워크플로

### 일괄 처리 워크플로의 출력

#### 검색 색인 구축

#### 일괄 처리의 출력으로 키-값을 저장

#### 일괄 처리 출력에 관한 철학

### 하둡과 분산 데이터베이스 비교

#### 저장소의 다양성

#### 처리 모델의 다양성

#### 빈번하게 발생하는 결함을 줄이는 설계

## 맵리듀스를 넘어

### 중간 상태 구체화

#### 데이터플로 엔진

#### 내결함성

#### 구체화에 대한 논의

### 그래프와 반복 처리

#### 프리글 처리 모델

#### 내결함성

#### 병렬 실행

### 고수준 API 와 언어

#### 선언형 질의 언어로 전환

#### 다양한 분야를 지원하기 위한 전문화

## 정리

