## 스트림 처리

일괄처리는 입력의 변화가 일정 시간이 지나야 반영된다는 문제가 있다.<br>
실시간성이 중요한 서비스에서 이런 지연은 치명적이고, 이를 해결하기 위해 스트림 처리가 등장했다.

"스트림"이란 시간 흐름에 따라 점진적으로 생산된 데이터이다.<br>
유닉스의 stdin / stdout, 프로그래밍 언어(느긋한 리스트(lazy lists)), 자바의 FileInputStream, TCP,오디오와 비디오 전송 등


## 이벤트 스트림 전송

||일괄처리|스트림처리|
|:--:|:--|:--|
|입력|파일|이벤트|
|변환|레코드의 연속으로 변환|텍스트문자열/JSON/이진 형태 등으로 부호화|
|소비|한번 기록하면 여러 작업에서 읽기 가능|생산자(producer/publisher)가 이벤트를 만들면 복수의 소비자(consumer, subscriber)가 처리 가능|
|식별|관련 레코드 집합을 파일 이름으로 식별|토픽이나 스트림으로 관련 이벤트를  묶는다|

이론상 DB와 폴링으로 스트리밍이 가능하지만 지연성이 낮아야할수록 폴링이 잦아지고, 커넥션 등 오버헤드가 커진다.
또한 새로운 이벤트마다 노티를 주는 방식도, 데이터베이스의 트리거를 사용할 수 있지만 기능이 제한적이다.

### 메시징 시스템

새로운 이벤트를 소비자에게 알려주는 일반적인 방법으로 메시징 시스템(messaging system)이 있다. 
메시징 시스템을 구축하는 가장 간단한 방법은 생산자와 소비자 사이에 유닉스 파이프나 TCP 연결과 같은 직접 통신 채널을 사용하는 것으로,  대부분의 메시징 시스템이 이러한 기본 모델을 확장해 사용하고 있다. 

- 소비자가 메시지를 처리하는 속도보다 생산자가 메시지를 빠르게 전송한다면?
  - 메시지를 버린다.
  - 큐에 메세지를 버퍼링한다.
  - 배압(backpressure)한다. 흐름 제어(flow control)라고도 하며 생산자가 메시지를 더 보내지 못하게 막는다.
    - 유닉스 파이프와 TCP는 배압을 사용한다.
- 노드가 죽거나 일시적으로 오프라인이 된다면 어떻게 될까? 손실되는 메시지가 있을까?
  - 지속성이 중요하다면 디스크에 기록하거나 복제본을 생성한다. 이는 비용이 든다.
  - 유실돼도 괜찮다면 같은 하드웨어에서 처리량은 높이고 지연시간은 낮출 수 있다.


### 생산자에서 소비자로 메시지 직접 전달하기

많은 메시지 시스템은 중간 노드를 거치지 않고 생산자와 소비자간에 직접 통신한다.

- UDP 멀티 캐스트는 낮은 지연이 필수인 주식 시장과 같은 금융 산업에서 많이 사용된다.  UDP 자체로는 신뢰성이 낮아도 애플리케이션 단의 프로토콜은 읽어버린 패킷을 복구할 수 있다. (생산자는 필요할 떄 패킷 재전송을 할 수 있도록 전송한 패킷을 기억해야 한다.)
- ZeroMQ같은 브로커가 필요없는 메시징 라이브러리와 나노메시지(nanomsg)가 이와 유사한 접근법을 사용하는데 TCP 또는 IP 멀티캐스트 상에서 발행/구독 메시징을 구현한다.
- StatsD과 BruBeck은 지표 수집 및 모니터링에 UDP 메시징을 사용한다. 
- 소비자가 네트워크에 서비스를 노출하면 생산자는 직접 HTTP나 RPC 요청을 직접 보낼 수 있다. webhook의 기본 아이디어로 서비스 콜백 URL을 다른 서비스에 등록하는 형식으로 이벤트가 발생할 때마다 콜백 URL로 요청을 보낸다.

  
직접 메시징 시스템은 메시지가 유실될 가능성을 고려한 코드 작성이 되야 한다.<br>
소비자가 오프라인이기에 메시지를 전달하지 못하는 상황에서 전송된 메시지는 유실될 수 있고, 이런 실패한 메시지 전송을 재시도하다 생산자 장비가 죽으면 재시도 하려 했던 메시지 버퍼를 잃어버릴 수 있기에 문제가 있다. 

### 메시지 브로커

 > [생산자] - 메세지전송 -> [브로커(메세지큐)] - 메세지읽기 -> [소비자]

브로커에 데이터가 모이기 때문에 클라이언트 상태변경으로 인한 유실에 쉽게 대처할 수 있다.<br>
경우에 따라 메모리에만 보관/디스크에 기록(유실 방지), 큐 사이즈 확대 등의 설정도 가능하다.

### 메시지 브로커와 데이터베이스의 비교

|DB|메시지 브로커|
|:--:|:--:|
|명시적으로 데이터가 삭제될 떄까지 데이터를 보관|대부분은 메시지 전송이 끝나면 자동으로 메시지를 삭제|
|보조 색인 지원| 특정 패턴과 부합하는 토픽의 부분 집합을 구독하는 방식|
|질의 결과는 일반적으로 질의 시점의 데이터 스냅숏을 기준으로 한다|임의 질의를 지원하지 않지만 데이터가 변하면 클라이언트에게 알려준다| 


### 복수 소비자

복수 소비자가 같은 토픽에서 메시지를 읽을 떄 사용하는 패턴은 다음과 같다. 

![image](https://github.com/rachel5004/23-11-DesigningDataIntensiveApplications/assets/75432228/f33bdf23-384b-4bd8-b316-8d3c1a047df4)


- `로드 밸런싱` : 여러 소비자가 하나의 토픽을 소비하는 작업을 공유
  - 각 메시지는 소비자 중 하나로 전달된다.
  - 브로커는 메시지를 전달할 소비자를 임의로 지정한다.
  - 메시지 처리 비용이 높아 처리를 병렬화 하기 위해 소비자를 추가 하고 싶을 때 유용하다.
  - JMS에서는 공유 구독(shared subscription)이라 한다.
  - AMQP는 같은 큐를 소비하는 클라이언트를 여러개 둬 로드밸런싱 구현이 가능하다.
- `팬 아웃` : 각 메시지를 복수 개의 소비자로 전달
  - 각 메시지는 모든 소비자에게 전달된다.
  - 여러 독립적인 소비자가 브로드캐스팅된 동일 메시지를 모두 볼 수 있다.
  - 일괄 처리에서 사용하는 방법과 동일

이 두 가지 패턴은 함께 사용 할 수도 있다. <br>
두 개의 소비자 그룹에서 하나의 토픽을 구독하고 각 그룹은 모든 메시지를 받지만 그룹 내에선 각 메시지를 하나의 노드만 받게 할 수 있다. 


### 확인 응답과 재전송

클라이언트는 메세지 처리가 끝나면 브로커에게 `확인 응답` 을 보내 메세지 큐에서 제거할 수 있게 해야한다.<br>
브로커는 확인 응답을 받지 못하면 실패로 간주하고 다른 소비자에게 다시 전송한다.

![image](https://github.com/rachel5004/23-11-DesigningDataIntensiveApplications/assets/75432228/96c0a222-b7cd-48fc-877e-fd083beff807)

때문에 위 처럼 소비자 1에서 m4 → m3 → m5 순으로 메시지를 처리하는 경우가 생기게 된다.

부하 균형 분산 기능을 사용하지 않고 소비자마다 독립된 큐를 사용하면 문제를 피할수 있으나, 아니라면 메세지간 인과성이 중요한 서비스에서는 치명적이다.

### 파티셔닝된 로그
네트워크 상에서 패킷을 전송하거나 네트워크 서비스에 요청하는 작업은 보통 영구적 추적을 남기지 않는 일시적 연산이다. 

메세지 브로커에서 이미 소비된 메시지는 복구할 수 없고, 소비자를 다시 실행해도 동일한 결과를 받을 수 없다.<br>
메시징 시스템에 새로운 소비자를 추가한다면 추가된 등록 시점 이후의 메시지부터 받기 시작하며 이전 메시지는 다시 읽을 수 없다. 

DB의 지속성 + 메세징시스템의 짧은 지연시간 = 로그 기반 메세지 브로커

### 로그를 사용한 메시지 저장소

로그는 단순히 디스크에 저장된 추가 전용 레코드의 연속이다. <br>
생산자가 보낸 메시진 로그 끝에 추가하고 소비자는 로그를 순차적으로 읽어 메시지를 받는다. 소비자가 로그 끝에 도달하면 새 메시지가 추가됐다는 알림을 기다린다.

유닉스 도구 tail -f는 파일에 추가되는 데이터를 감시하는데 본질적으로 이 구조와 동일하다. 


![image](https://github.com/rachel5004/23-11-DesigningDataIntensiveApplications/assets/75432228/17206195-23e5-472d-98c0-d8920b2daa7f)

- 각 파티션 내에서 브로커는 모든 메시지에 오프셋이라 부르는, 단조 증가하는 순번을 보여한다.
- 파티션은 추가 전용이고, 파티션 내 전체 메시지는 전체 순서가 있기에 순번을 부여하는 것은 타당하다. (다른 파티션 간 메시지의 순서는 보장하지 않는다.)
- 아파치 카프카(Apache Kafka), 아마존 키네시스 스트림(Amazon Kinesis Stream), 트위터의 분산 로그(DistributedLog)
- 이러한 메시지 브로커는 모든 메시지를 디스크에 저장하지만 여러 장비에 메시지를 파티셔닝해 초당 수백만 개의 메시지를 처리할 수 있고 메시지를 복제함으로써 장애에 대비할 수 있다.

> 참고: JMS (Java Message Service)
> Java를 사용해 메시지 지향 미들웨어(Message-Oriented Middleware, MOM)를 비동기 메시지 전송을 단순화하는 API로 스트림 처리와 결합해 대규모 분산 시스템에서 실시간 데이터 처리를 할 수 있으며 다음과 같은 메시지 모델들을 지원한다. 
> 1. Point-to-Point: 메시지를 큐(Queue)에 저장하고, 하나 이상의 컨슈머에 전달한다. 각 메시지는 오직 하나의 컨슈머에게만 전달된다. 
> 2. Publish-Subscribe: 퍼블리셔가 특정 토픽(Topic)에 메시지를 게시하면 해당 토픽을 구독하는 모든 구독자에게 브로드캐스팅된다.


### 로그 방식과 전통적인 메시징 방식의 비교


로그 방식 (예: Apache Kafka):
1. 내구성: 메시지를 영구적으로 저장하고 순서를 유지하여 높은 내구성을 제공한다.
2. 재생성 가능: 컨슈머가 이미 처리한 메시지를 다시 처리할 수 있게 하며 이러한 점은 디버깅에 유용하다.
3. 고성능: 데이터를 연속적으로 저장하고 메시지를 빠르게 전달하므로 대량의 데이터 처리에 적합하다.
4. 확장성: 클러스터를 통해 수평적으로 확장할 수 있습니다.

전통적인 메시징 방식 (예: JMS, RabbitMQ, ActiveMQ)
1. 유연한 메시지 처리: 메시지를 큐나 토픽으로 분리하여 다양한 메시지 처리 패턴을 지원한다.
2. 상태 관리: 메시지 상태를 메시징 시스템에서 추적하고 관리할 수 있다. (Ex:  메시지가 전송되었는지, 처리되었는지 등).
3. 전송 보장: 메시지 전송 여부 확인 및 실패시 재전송할 수 있는 기능을 제공한다.
4. 메시지 필터링: 구독자가 특정 조건을 기반으로 메시지를 선택적으로 수신할 수 있다.


로그 기반 접근법은 팬 아웃 메시징 방식을 제공하기에 대용량 데이터 처리 및 확장성과 내구성을 가질 수 있다.<br>
반면 전통적인 메시징 방식은 메시지 처리를 유연하게 하고 상태 관리를 하는데 중점을 둔다. 

- `JMS / AMQP 방식의 메시지 브로커`
  - 메시지 처리 비용이 비싸고,
  - 메시지 단위로 병렬화 처리하고 싶고
  - 메시지 순서는 중요하지 않다면
- `로그 기반 메세지 브로커`
  - 메시지 처리량이 많고,
  - 메시지를 처리하는 속도가 빠르지만
  - 메시지 순서가 중요하다면


### 소비자 오프셋

파티션 하나를 순서대로 처리하면, 소비자의 현재 오프셋을 기준으로 이전은 이미 처리한 메시지, 이후는 아직 처리하지 않은 메시지다.<br>
따라서 브로커는 개별 메시지마다 보내는 확인 응답을 추적할 필요가 없고, 주기적으로 소비자 오프셋을 기록하면 된다.<br>
추적 오버헤드 감소, 일괄처리 및 파이프라이닝을 수행할 수 있는 기회를 제공해 처리량을 늘리는데 도움이 된다.


이 방식은 단일 리더 DB 복제에서 사용되는 로그 순차 번호(log sequence number)와 비슷하다.<br>
메시지 브로커가 DB의 리더처럼 동작하고 소비자가 팔로워처럼 동작한다. <br>
그래서 소비자 노드에 장애가 발생할 경우 소비자 그룹 내 다른 노드에 장애가 발생한 소비자의 파티션을 할당하고 기록된 오프셋 메시지를 처리하기 시작한다. <br>
장애가 발생한 소비자가 처리했지만 아직 오프셋을 기록하지 못한 메시지가 있다면 이 메시지는 재시작할 때 두 번 처리된다. 

### 디스크 공간 사용

로깅을 하다보면 디스크 공간이 가득차게 될 것이다. 

- 로그를 여러 조각으로 나눠 오래된 것부터 삭제하거나 보관 저장소로 이동(Ex: DB)
- 소비자의 소비가 너무 늦어서 메시지 생산 속도를 따라잡지 못하면, 소비자의 오프셋이 이미 삭제된 조각을 가리킬 수도 있고 이는 메시지 유실을 의미한다. 
- 로그는 크기가 제한된 버퍼로 구현하고버퍼가 가득 차면 오래된 메시지 순서대로 버린다.
  - 원형 버퍼(circular buffer) or 링 버퍼(ring buffer)라 한다.


### 소비자가 생산자를 따라갈 수 없을 때

로그 기반 메세지 브로커는 메시지 버리기, 버퍼링, 배압하기 중 **대용량이지만 고정 크기의 버퍼를 사용하는 버퍼링 형태**다.

- 소비자가 뒤처져 필요한 메시지가 디스크에 보유한 메시지보다 오래되면 필요한 메시지는 읽을 수 없다.
  - 그래서 브로커는 버퍼 크기를 넘는 오래된 메시지를 자연스럽게 버린다.
  - 소비자가 로그의 헤드로부터 얼마나 떨어졌는지를 모너티링해서 너무 많이 뒤처진다면 경고할 수도 있다. 
- 어떤 소비자가 너무 뒤처져서 메시지를 잃기 시작해도 해당 소비자만 영향을 받고 다른 소비자들의 메시지에 영향을 주지는 않는다.
  - 운영시에 프로덕션 서비스에 영향을 줄 우려 없이 개발, 테스트, 디버깅 목적으로 프로적션 로그를 소비하는 실험이 가능하다.
  - 소비자가 종료되거나 죽으면 자원 소비가 중단되고 소비자 오프셋만 남는다.
    - 전통적인 메시지 브로커는 소비자가 중단되면 그 소비자가 사용하던 큐를 삭제해줘야 한다.
    - 그렇지 않으면 큐에 불필요한 메시지가 누적되고 여전히 활성화된 소비자로 부터 계속 메모리를 뻇어가게 된다.
 
### 오래된 메시지 재생

로그 기반 메시지 브로커는 메시지를 소비하는게 파일을 읽는 작업과 유사하기 때문에 재처리가 가능하다.

## 데이터베이스와 스트림

### 시스템 동기화 유지하기

단일 시스템 중 데이터 저장과 질의, 처리 요구사항을 모두 만족하는 시스템은 없기 때문에 여러 기술을 조합해 사용한다.

- 사용자 요청에 대응하기 위한 OLTP DB
- 공통 요청의 응답 속도를 높이기 위한 캐시
- 검색 질의를 다루기 위한 전문 색인
- 분석용 데이터 웨어하우스

각각은 데이터의 복제본을 가지고 있고 데이터는 목적에 맞게 최적화된 형태로 저장된다. <br>
관련이 있거나 동일한 데이터가 여러 다른 장소에서 나타날 수 있기에 서로 동기화도 필수다. <br>
데이터 베이스에 아이템 하나가 갱신되면 캐시, 색인, 데이터 웨어하우소 같이 갱신되야 한다. 

### 변경 데이터 캡쳐

변경 데이터 캡처(change data capture, CDC)는 DB에 기록하는 모든 데이터의 변화를 관찰해 다른 시스템으로 데이터를 복제할 수 있는 형태로 추출하는 과정이다. <br>
CDC는 데이터가 기록되자마자 변경 내용을 스트림으로 제공할 수 있으면 특히 유용하다.

![image](https://github.com/rachel5004/23-11-DesigningDataIntensiveApplications/assets/75432228/d9adcaf4-4494-4f9f-b4ee-b29b1e02712e)

DB의 변경 사항을 캡처해 변경 사항을 검색 색인에 꾸준히 반영할 수 있다. 같은 순서로 로그 변경이 반영된다면 DB의 데이터와 색인이 일치할 것이다. 

#### 변경 데이터 캡처의 구현

검색 색인과 데이터 웨어하우스에 저장된 데이터는 레코드 시스템에 저장된 데이터의 또 다른 뷰일 뿐이기에 로그 소비자를 파생 데이터 시스템이라 할 수 있다.<br>
변경 데이터 캡처(Change Data Capture, CDC)는 파생 데이터 시스템이 레코드 시스템의 정확한 데이터 복제본을 가지게 하기 위해 레코드 시스템에 발생하는 모든 변경 사항을 파생 데이터 시스템에 반영하는 것을 보장하는 메커니즘이다. 


CDC 원본 데이터베이스(DB) 하나를 리더로, 나머지를 팔로워로 두어 변경 사항을 캡처한다.  <br>
로그 기반 메시지 브로커는 메시지 순서를 유지하기 때문에 원본 DB에서 변경 이벤트를 전송하기에 적합하다.


CDC는 메시지 브로커와 동일하게 비동기 방식으로 동작한다. 이는 레코드 DB 시스템이 변경 사항을 커밋하기 전 소비자에게 적용될 때까지 기다리지 않는다. <br>
이러한 설계는 느린 소비자가 추가되더라도 레코드 시스템에 미치는 영향이 적어 운영상 이점이 있지만, 복제 지연과 관련된 모든 문제가 발생할 수 있다는 단점이 있다.

> 비동기 팔로워에서 데이터를 읽을 때 리더의 데이터를 복제하기 전이라면 데이터의 불일치가 발생한다.

#### 초기 스냅숏

데이터베이스에서 발생한 모든 변경 로그가 있다면 로그를 재현해서 데이터베이스의 전체 상태를 재구축할 수 있다.<br>
그러나 대부분 모든 변경 사항을 영구적으로 보관하는 일은 디스크 공간이 많이 필요하고 모든 로그를 재생하는 작업도 오래 걸린다.<br>
따라서 로그를 적당히 잘라야 한다.

- 예시. 전문 색인을 새로 구축
  - 전체 데이터베이스 복사본이 필요하다. 전체 로그 히스토리가 없다면 일관성 있는 스냅숏을 사용해야 한다.

데이터베이스의 스냅숏은 스냅숏 이후에 변경 사항을 적용할 시점을 알기 위해 변경 로그의 위치(오프셋)에 대응되어야 한다.<br>
일부 CDC 도구는 이러한 스냅숏 기능을 내장하고 있으나 수작업으로 해야 하는 도구도 있다.

#### 로그 컴팩션

로그 히스토리의 양을 제한한다면 새로운 파생 데이터 시스템을 추가할 때마다 스냅숏을 만들어야 하는데 그에 대한 대안책이 로그 컴팩션(log compaction)이다.

> 저장 엔진은 주기적으로 같은 키의 로그 레코드를 찾아 중복을 제거하고 각 키에 대해 가장 최근에 갱신된 내용만 유지한다.


로그 구조화 저장엔진에서 특별한 널 값(툼스톤(tomstone))으로 갱신하는 것은 키의 삭제를 의미하고 로그 컴팩션을 수행할 때 실제로 값을 제거한다.<br>
하지만 툼스톤은 키를 덮어쓰거나 삭제하지 않는 한 영구적으로 유지한다. <br>
컴팩션한 로그를 저장하는 데 필요한 디스크 공간은 지금까지 데이터 베이스에 발생한 쓰기 수가 아니라 현재 DB에 있는 내용에 달려있다. <br>
같은 키를 여러 번 덮어썼다면 이전 값은 결국 가비지 컬렉션이 되고 최신 값이 유지된다. 

로그 기반 메시지 브로커와 CDC의 맥락에서도 마찬가지다. <br>
CDC 시스템에서 모든 변경에 기본키가 포함되게 하고 키의 모든 갱신이 해당 키의 이전 값을 교체한다면 특정 키에 대해 최신 쓰기만 유지하면 충분하다. 

이제는 검색 색인과 같은 파생 데이터 시스템을 재구축할 때마다 새 소비자는 컴팩션된 로그 토픽의 오프셋 0부터 시작해 순차적으로 DB의 모든 키를 스캔하면 된다. 로그에 DB에 있는 모든 키의 최신 값이 존재하는 것이 보장된다.(컴팩션 중인 경우 이전 값도 약간은 존재 가능)
즉 CDC 원본 DB의 스냅숏을 만들지 않고도 DB 콘텐츠 전체의 복사본을 얻을 수 있다. 

#### 변경 스트림용 API 지원

최근 DB들은 기능 개선이나 리버스 엔지니어링을 통해 CDC 지원을 하기보단 점진적으로 변경 스트림을 기본 인터페이스로 지원하기 시작했다. 

- RethinkDB : 질의 결과에 변경이 있을 때 알림을 받을 수 있게 구독이 가능한 질의를 지원
- FireBase와 CouchDB : 변경 피드 기반의 데이터 동기화를 지원
- Meteor와 MongoDB : oplog를 사용해 데이터 변경 사항을 구독하거나 사용자 인터페이스를 갱신

#### 이벤트 소싱

이벤트 소싱은 변경 데이터 캡처와 유사하게 애플리케이션 상태 변화를 모두 변경 이벤트 로그로 저장한다. <br>
변경 데이터 캡처와 가장 큰 차이점은 이 아이디어를 적용하는 추상화 레벨이 다르다는 점이다.

- 변경 데이터 캡처
  - 애플리케이션은 DB를 변경 가능한 방식으로 사용해 레코드를 자유롭게 갱신하고 삭제한다.
  - 변경 로그는 DB에서 저수준으로 추출한다(Ex: 복제 로그 파싱).
  - 변경 로그는 DB에서 추출한 쓰기 순서가 실제로 데이터를 기록한 순서와 일치하고 경쟁 조건이 나타나지 않게 보장한다.
  - DB에 기록하는 애플리케이션은 CDC가 실행 중인지 알 필요가 없다. 
- 이벤트 소싱
  - 애플리케이션 로직은 이벤트 로그에 기록된 불변 이벤트를 기반으로 명시적으로 구축한다.
  - 이때 이벤트 저장은 단지 추가만 가능하고 갱신이나 삭제는 권장하지 않거나 금지한다.
  - 이벤트는 저수준에서 상태 변경을 반영하는 것이 아닌 애플리케이션 수준에서 발생한 일을 반영하게끔 설계됐다. 

<details>
<summary>이벤트소싱, 연대기 데이터 모델, 이벤트 로그, 그리고 사실 테이블의 유사점</summary>
모두 시간에 따른 데이터의 변화를 표현하는데 중점을 두고 다음과 같은 유사성을 가진다. 
1. 시간 순서: 모두 시간 순서에 따라 데이터를 저장하고 처리한다. 이러한 구조를 통해 시간에 따른 데이터의 변화를 추적할 수 있습니다.
2. 추적 가능성: 이들 모델에서 발생한 이벤트나 데이터 변경은 시간에 따라 추적 가능하며, 이를 통해 과거 상태로 롤백하거나 데이터의 변화를 분석할 수 있다.
3. 이벤트 기반: 이벤트 소싱과 연대기 데이터 모델은 이벤트를 기반으로 데이터를 저장 및 관리한다. 이벤트 로그와 사실 테이블도 이벤트 또는 거래 데이터(Transaction Data)를 중심으로 구성되어 있다.
4. 추가 전용: 이벤트 소싱, 연대기 데이터 모델, 이벤트 로그에서는 데이터를 추가 전용(append-only)으로 저장한다. 이러한 방식은 데이터의 무결성을 유지하고 동시성 문제를 줄여준다. 별 모양 스키마의 사실 테이블에서도 대부분 추가 전용으로 데이터를 저장하며, 변경이 필요한 경우 새로운 행을 추가하는 방식을 사용한다.
5. 읽기 성능 최적화: 모두 읽기 성능을 최적화하는 데 중점을 두고 있으며, 이들 구조를 사용하면 데이터의 변경 내역을 쉽게 조회하고 분석할 수 있다.
6. 분산 시스템과의 호환성: 이들 모델은 시간 순서에 따라 데이터를 저장하고 처리하는 구조로 인해 분산 시스템에서도 잘 동작한다. 분산 환경에서도 데이터 일관성을 유지하고 동시성 문제를 해결하는 데 도움이 된다.
</details>

#### 이벤트 로그에서 현재 상태 파생하기

이벤트 로그 자체로는 별로 유용하다고 할 수 없다. 사용자는 현재 시스템이 어떤 상태인지가 궁금하지 수정 히스토리가 궁금하지 않다. <br>
이벤트 소싱을 사용하는 애플리케이션은 이벤트 로그를 가져와 사용자에게 보여주기 적합한 상태로 변환해야 한다. 

이 변환 과정은 로직을 자유롭게 사용할 수 있지만 결정적 과정이어야 한다.<br>
다시 수행하더라도 이벤트 로그로부터 동일한 애플리케이션 상태를 만들 수 있어야 하기 때문이다.

변경 데이터 캡처와 마찬가지로 이벤트 로그를 재현하면 현재 시스템 상태를 재구성할 수 있다. 하지만 로그 컴팩션은 다르게 처리해야 한다. 

- 레코드 갱신용 CDC이벤트는 일반적으로 레코드의 가장 새로운 버전을 보유한다. 그래서 기본키의 현재 값은 전적으로 기본키의 가장 최신 이벤트로 결정되고 같은 키의 이전 이벤트는 로그 컴팩션을 통해 버린다. 
- 반면 이벤트 소싱은 이벤트를 보다 상위 수준에서 모델링한다. 이벤트는 대개 사용자 행동의 결과로 발생한 상태 갱신 메커니즘이 아닌 사용자 행동 의도를 표현한다. 이 경우 뒤에 발생한 이벤트가 앞선 이벤트를 덮어쓰지 않는다. 그래서 마지막 상태를 재구축하기 위해 이벤트의 전체 히스토리가 필요하다. 이런 방식에선 로그 컴팩션이 불가능하다. 

이벤트 소싱을 사용하는 애플리케이션은 일반적으로 이벤트 로그에서 파생된 현재 상태의 스냅숏을 저장하는 메커니즈이 있기에 전체 로그를 반복해서 재처리할 필요는 없다. 하지만 이 메커니즘은 장애 발생 시 읽고 복구하는 성능을 높여주는 최적화에 불과하다. 이벤트 소싱 시스템에는 모든 원시 이벤트를 영원히 저장하고 필요할 때마다 모든 이벤트를 재처리할 수 있어야 한다는 의도가 있다.

#### 명령과 이벤트

이벤트 소싱 철학은 **이벤트와 명령(command)**을 구분하는 데 주의한다.

- 사용자 요청이 처음 도착했을 때 이 요청은 명령이다.
  - 이 시점에선 명령이 실패할 수도 있다. (예로 특정 무결성 조건을 위반하면 실패한다)
  - 그렇기에 애플리케이션은 명령이 실행 가능한지 확인해야 한다.
- 무결성이 검증되고 명령이 승인되면 명령은 지속성 있는 불변 이벤트가 된다. 

이벤트 스트림 소비자는 이벤트를 거질하지 못하고 소비자가 이벤트를 받은 시점에서 이벤트는 이미 불변 로그의 일부분이다. 따라서 명령의 유효성은 이벤트가 되기 전 동기식으로 검증해야 한다.  <br>
이를테면 직렬성 트랜잭션을 사용해 원자적으로 명령을 검증하고 이벤트를 발행할 수 있다. 

### 상태와 스트림 그리고 불변성

사건이 발생했다 취소되더라도 이벤트가 발생했다는 부분은 변하지 않는다. 모든 변경 로그(changelog)는 시간이 지남에 따라 바뀌는 상태를 나타낸다.

#### 불변 이벤트의 장점

- 장애 복구가 쉬워진다
  - 일괄 처리 출력에 관한 철학에서 본 것처럼 우연히 버그가 있는 코드를 배포해서 데이터베이스에 잘못된 데이터가 덮어쓰여졌다면 복구하기가 매우 어렵다.
  - 추가만 하는 불변 이벤트 로그를 썼다면 문제 상황의 진단과 복구가 훨씬 쉬워진다.
- 현재 상태보다 훨씬 많은 정보를 포함하고 있어 비즈니스에 활용할 수 있다.
  - 예) 쇼핑 웹사이트에서 고객이 장바구니에 항목 하나를 넣었다가 제거했다.
  - 주문 이행 관점에서는 두 번째 이벤트는 단지 첫 번째 이벤트를 취소한 것에 불과하지만 분석가에게는 고객이 특정 항목을 구매하려 했다가 하지 않았다는 것을 알 수 있는 유용한 정보다.
  - 이 정보는 이벤트 로그에 기록되지만 데이터베이스는 장바구니에서 항목을 제거했을 때 잃어버리는 정보다.

#### 동일한 이벤트 로그로 여러 가지 뷰 만들기

불변 이벤트 로그에서 가변 상태를 분리하면 동일한 이벤트 로그로 다른 여러 읽기 전용 뷰를 만들 수 있다. <br>
한 스트림이 여러 소비자를 가질 때와 동일하다.

- 분석 데이터베이스 도구 드루이드는 카프카로부터 직접 데이터를 읽어 처리한다.
- 피스타치오는 분산 Key-Value 저장소로 카프카를 커밋 로그처럼 사용한다.
- 카프카 커넥트 싱크는 카프카에서 여러 데이터베이스와 색인에 데이터를 내보낼 수 있다.

**장점**

- 이벤트 로그에서 데이터베이스로 변환하는 명시적인 단계가 있으면 시간이 흐름에 따라 어플리케이션을 발전시키기 쉽다.
  - 기존 데이터를 새로운 방식으로 표현하는 새 기능을 추가하려면 이벤트 로그를 사용해 신규 기능용으로 분리한 읽기 최적화된 뷰를 구축할 수 있다.  
- 기존 시스템을 수정할 필요가 없고 기존 시스템과 함께 운용이 가능하다.
  - 신/구 시스템을 나란히 구동하는 것은 기존 시스템에서 복잡한 스키마 이전을 수행하는 것보다 쉽다.
  - 구 시스템이 필요하지 않다면 기존 시스템을 내리고 사용하던 자원을 회수할 수도 있다.

#### 동시성 제어

이벤트 소싱과 CDC의 가장 큰 단점은 이벤트 로그의 소비가 대개 비동기로 이뤄진다는 점이다. <br>
그래서 사용자가 로그에 이벤트를 기록하고 이어서 로그에서 파생된 뷰를 읽어도 기록한 이벤트가 아직 읽기 뷰에 반영되지 않았을 가능성이 있다.

- 방법1 : 읽기 뷰의 갱신과 로그에 이벤트를 추가하는 작업을 동기식으로 처리
  - 트랜젝션에서 여러 쓰기를 원자적 단위로 결합해야 하므로 이벤트 로그와 읽기 뷰를 같은 저장 시스템에 담아야 한다.
  - 다른 시스템에 있다면 분산 트랜젝션이 필요해진다.
- **방법2 :  이벤트 로그로 현재 상태를 생성 (동시성 제어 측면이 단순)**
  - 다중 객체 트랜젝션은 단일 사용자 동작이 여러 다른 장소의 데이터를 변경해야 할 때 필요하다.
  - 이벤트 소싱을 사용하면 사용자 동작에 대한 설명을 자체적으로 포함하는 이벤트를 설계할 수 있다.
  - 그러면 사용자 동작은 한 장소에서 한 번 쓰기만 필요하다.
  - 즉 이벤트를 로그에 추가하기만 하면 되며 원자적으로 만들기 쉽다.

이벤트 로그와 애플리케이션 사앹를 같은 방식으로 파티셔닝하면(Ex: 3번 파티션에 있는 사용자의 이벤트를 처리할 때 애플리케이션 상태의 3번 파티션만 갱신하면 된다면) 간단한 단일 스레드 로그 소비자는 쓰기용 동시성 제어는 필요하지 않고, 단일 이벤트를 한 번에 하나씩 처리한다. 

파티션 내에서 이벤트의 직렬 순서를 정의하면 로그에서 동시성의 비결정성을 제거할 수 있다. 한 이벤트가 여러 개의 상태 파티션에 영향을 준다면 더 많은 작업이 필요하다. 
