# 3장 저장소와 검색

- 데이터베이스의 기본적인 작업 2가지
	- 1. 데이터를 저장
	- 2. 데이터를 제공

- 애플리케이션 개발자는 다양한 저장소 엔진중 `서비스의 작업 부하(Workload)에 적절한 저장소`를 선택해야함
	- 특히 트랜잭션 작업부하에 최적화된 엔진과 분석을 위해 최적화된 엔진 간에 큰 차이가 있음
- 저장소엔진이 좋은 성능을 내도록 튜닝하려면 저장소 내부에서 수행되는 작업에 대한 이해가 필요
- NoSQL, RDBMS
- 로그 구조(Log-Structured), B-Tree (Page-oriented)
	- Log
		- 애플리케이션 로그: 애플리케이션이 무슨일이 일어났는지 기술한 텍스트
		- 용어 자체의 일반적인 의미: `연속된` `추가 전용(Append-Only)` 레코드
			- 데이터의 맨 뒤에 지속적으로 레코드를 추가함
			- 한번 추가한 데이터의 변경은 없음
	- Page
		- 저장소를 페이지 단위로 나누고 해당 페이지의 레코드들을 지속적으로 재 갱신

```text
Log: 연속된 추가 전용 레코드 (애플리케인셔 무슨일이 일어났는지 기술한 텍스트를 넘어 보다 일반적인 의미)
```


## 3.1. 데이터베이스를 강력하게 만드는 데이터 구조

심플한 데이터 set(), get() 함수
```bash
#!/bin/bash

db_set() {
	echo "$1,$2" >> database
}

db_get() {
	grep "^$1," database | sed -e "s/^$1,//" | tail -n 1
}

```

- db_set: Append-only로 저장 시 좋은 성능을 보여줌
- db_get: 파일 전체를 읽어야함, 시간 복잡도: O(n) 

- db_get()의 성능을 개선하기 위해 다른 데이터 구조가 필요 (인덱스)
	- 인덱스는 기본데이터에서 파생된 추가적인 데이터
		1. 색인은 기존 데이터베이스의 내용에는 영향을 미치지 않음
		2. 하지만 기존 데이터의 변경 시 색인도 갱신하는 추가적인 작업이 필요하고 쓰기 속도가 느려짐
- 저장소 시스템의 중요한 트레이드 오프: 인덱스를 설정하면 `읽기 속도가 빨라지지만 저장 속도는 느려`진다.


### 3.1.1. 해시 색인

Key-value 형태로 색인 하는 것
- 프로그래밍 언어의 사전 타입과 유사
![[그림 3-1. 해시맵 색인.png]]]

위처럼 지속적으로 로그를 쌓다보면 디스크 공간이 부족해지는데 이를 극복하기 위해 컴팩션(compaction)을 수행함
- 컴팩션: 로그에서 중복된 키를 버리고 각 키의 최신 갱신 값만 유지

아래 그림 처럼 데이터 세그먼트 파일을 백스라운드  스레드에서 지속적으로 병합함
![[그림 3-3. 컴팩션과 세그먼트 병합.png]]


추가전용 로그 구조의 장점
- 추가와 세그먼트 병합은 순차적인 쓰기 작업이기 때문에 `데이터가 저장된 위치를 찾아 내용을 갱신하는 B-Tree의 페이지 방식` 보다 빠름
- 세그먼트 파일이 추가 전용이고 불편이기 때문에 동시성과 고장 복구가 간단함 (장애가 발생해도 갱신되기 전의 이전 값들이 그대로 있기에 이전 값들을 읽어 복구)
- 오래된 세그먼트들을 병합하여 시간이 지남에 따라 조각화되는 데이터 파일 문제를 피할 수 있음

해시 테이블 색인의 제한 사항
- 해시 테이블은 메모리에 저장해야 하므로 키가 너무 많으면 문제가 됨
- 해시 테이블은 범위 질의 (Range Scan)시에도 `모든 개별 키 값`을 조회해야하므로 1~9999와 같은 범위 조회 시  비효율적


### 3.1.2. SS테이블과 LSM 트리

- Sorted String Table
	- 키-값의 쌍을 키 순서로 정렬한 데이터

SS 테이블의 장점 (해시 테이블 색인의 제한 사항 극복)
- 특정 키를 찾기 위해 메모리에 모든 키의 색인을 유지할 필요 없이 아래 그림처럼 희소 색인(Sparse Index)을 유지해 검색할 수 있음
	- ex. handiwork를 찾기 위해 handbag 에서 시작해 handiwork가 나올때까지 스캔
- 요청 범위 내에서 키-값 쌍을 스캔해야 하기 때문에 해당 레코드들을 블록으로 그룹화하고 디스크에 쓰기전에 압축함 (따라서 희소 색인의 각 오프셋은 압축된 블록의 시작을 가리킴)
	- 이는 디스크 공간을 절약하고 I/O 대역폭 사용도 줄임

![[그림 3-5. 인메모리 색인을 가진 SS테이블.png]]

그림 3-5. 인메모리 색인을 가진 SS 테이블
- Log-Structured Merge-Tree

#### 3.1.2.1. SS테이블 생성과 유지
- 데이터를 키로 정렬하기
	- 디스크 상에도 정렬된 구조를 유지하는 일이 가능하지만 메모리에 유지하는 방법이 쉬움
	
1. 레드 블랙 트리나 AVL 트리와 같은 인메모리 균형 트리 자료 구조를 활용해 데이터를 키로 정렬함 (멤테이블, memtable 이라고도함)
2. 멤테이블이 임계값 보다 커지면 SS테이블 파일로 디스크에 기록함 (트리가 이미 키로 정렬된 키-값 쌍을 유지하고 있기에 저장이 수월)
3. 읽기요청 시 우선 멤 테이블에서 키를 찾고 그다음 디스크 상의 SS테이블 세그먼트 탐색
4. 가끔 SS테이블 세그먼트 파일을 합치는 병합, 컴팩션 과정을 수행함

#### 3.1.2.2. SS테이블에서 LSM 트리 만들기

- LSM(Log-Structured Merge-Tree)
	- 정렬된 파일 병합과 컴팩션 원리를 기반으로 하는 저장소 엔진을 LSM 저장소 엔진이라고 부름
- LSM을 적용한 저장소 예시: 레벨DB, 록스DB, 카산드라, HBase 등

#### 3.1.2.3. 성능 최적화

- 존재하지 않는 키를 찾는 경우 느린문제: 존재하지 않는 키를 찾으려는 경우 맴테이블 확인 후 가장 오래된 세그먼트까지 모두 확인해서 키의 존재 유무를 파악해야함 (블룸 필터로 극복, 블룸 킬퍼는 키가 데이터베이스에 존재하지 않음을 알려줌)
- 백그라운드에서 SS테이블을 지속적으로 병합함
	- SS테이블을 압축하고 병합하는 순서와 시기를 결정하는 전략 
		- 크기 계층 (size-tiered), 레벨 컴팩션 (leveled compaction)
		- 
### 3.1.3. B 트리

가장 많이 사용되는 색인 구조는 B-Tree 구조로 Log-Structured 색인과는 상당히 다름

- 로그 구조화 색인
	- 데이터베이스를 수 메가바이트 이상의 가변 크기를 가진 세그먼트로 나누고 항상 순차적으로 세그먼트를 기록함
- B-Tree 색인
	- 일반적으로 4~16Kb 크기의 고정 크기 블록이나 페이지로 데이터를 나누고 한번에 하나의 페이지에 읽기 또는 쓰기를 함
	- 데이터를 업데이트 할 때 데이터가 저장된 페이지를 찾아가 업데이트 하기에 저장된 페이지를 찾아야하고 페이지가 덮어씌워지면서 이전 값을 잃어버릴 수 있음

#### 3.1.3.1. 신뢰할 수 있는 B 트리 만들기

- B트리의 기본적인 쓰기 동작은 새로운 데이터를 디스크 상의 페이지에 덮어씌움
- 만약 여러 페이지에 덮어쓰기를 하다 일부 페이지만 기록하고 서버 장애가 발생한다면?
	- 장애가 발생하기 이전 시점으로 돌리기 어려움
	- 장애 복구를 위해 일반적으로 디스크상에 먼저 로그를 저장 함 (Write-Ahead Log, WAL, 재실행 로그 redo log라고도 함)
- 다중 스레드가 동시에 B트리에 접근해서 수정하려고 한다면?
	- 주의 깊은 동시성 제어가 필요
	- 동시성은 보통 Latch(래치) 라는 가벼운 잠금으로 제어

#### 3.1.3.2. B 트리 최적화

B 트리는 오랜기간 사용되었기 때문에 많은 최적화가 있었음

- 페이지 덮어 쓰기와 고장 복구를 위한 Write-Ahaed Log 유지 대신, 여러 버전의 페이지를 가지고 있기 
	- MVCC(Multi-Version Concurrency Control, 다중 버전 동시성 제어)
- 페이지에 전체 키를 저장하는게 아니라 키를 축약해서 쓰고 공간을 절약한다. 트리의 분기계수를 높이고 깊이 수준을 낮출 수 있음 (분기계수를 높인다: 한 페이지에 보다 많은 키값을 저장)
	- B-Tree의 깊이가 3일 때 저장할 수 있는 키값 수
		- 분기계수 500 = 500^3 = 125000000
		- 분기계수 200 = 200^3 =  8000000
- B-Tree의 페이지는 디스크상 어디에나 위치할 수 있고 이는 연속된 데이터 스캔시 비효율적이기에 리프 페이지를 디스크 상에 연속된 순서로 배치하려는 로직이 있음
- 트리의 리프에 포인터를 추가해 양쪽 형제페이지 간 이동할 수 있음 (트리를 타지 않고 레인지 스캔 가능)
- 프랙탈 트리: B 트리 변형, 디스크 찾기를 줄임


### 3.1.4. B 트리와 LSM 트리 비교

일반적으로 LSM 트리는 쓰기에서 빠른 반면 B 트리는 읽기에서 빠르다고 여김
- LSM 트리가 읽기에서 더 느린 이유: 각 컴팩션 단계에 있는 여러 가지 데이터 구조와 SS 테이블을 확인해야 함
#### 3.1.4.1. LSM 트리의 장점

B-Tree
- B-Tree 색인은 페이지 단위로 데이터를 업데이트 하기에 페이지의 레코드 1개만 변경되어 전체 레코드를 변경해야함
- B-Tree 는 데이터를 최소한 2번 기록 해야함 (WAL + Page)
	- 이렇게 한번 쓸 때 여러번 쓰는 작업을 쓰기 증폭 이라고함
	- 디스크에 여러번 데이터 쓰기 작업을 해야하고 이는 디스크의 수명에 영향을 줌 
	- 또한 쓰기가 많은 애플리케이션의 경우 디스크에 쓰는 속도가 병목 (성능 비용 발생)

LSM 트리
- LSM 트리는 순차쓰기를 하기 때문에 높은 처리량을 높게 유지할 수 있고 상대적으로 쓰기 증폭이 낮음
- 데이터가 페이지 지향적이지 않고 주기적으로 병합하기 때문에 데이터가 파편화되지 않고 압축률이 좋음

#### 3.1.4.2. LSM 트리의 단점
- 컴팩션 과정이 읽기와 쓰기 성능에 영향을 
	- LSM 트리의 경우 저장소 엔진의 응답시간 상위 백분위(p99, p999) 값이 높음
- 컴팩션 속도가 쓰기 속도를 따라가지 못한다면 병합되지 않은 세그먼트가 디스크 공간이 부족할때까지 계속 증가함
	- 컴팩션이 잘 되고 있는지 명시적인 모니터링 필요
- B 트리의 경우 각 키가 색인의 한 곳에만 정확하게 존재하지만, 로그 구조화 저장소엔진은 다른 세그먼트에 같은 키의 다중 복사본이 존재할 수 있음 (별도 처리가 필요)


### 3.1.5. 기타 색인 구조

- 키-값 색인의 대표적인 예는 기본 키(Primary Key) 인덱스
- 기본 키로 테이블에서 하나의 Row, 문서 데이터베이스에서 Document 그래프 데이터베이스에서 Vertex를 참조
- 보조 색인(Secondary Index): PK와 달리 보조 색인을 중복된 값을 가질 수 있음

기본 키와 보조색인 모두 LSM, B Tree 데이터 구조에 사용할 수 있음


#### 3.1.5.1. 색인 안에 값 저장하기

- 커버링 인덱스, 클러스터링 인덱스
- 색인안에 Row의 모든 값을 저장해서 바로바로 사용한다.
- 읽기 성능을 높일 수 있지만 추가적인 저장소와 인덱스의 업데이트가 필요하므로 쓰기 속도에 영향을 줄 수있음

#### 3.1.5.2. 다중 컬럼 색인
- Key: (성, 이름)
- Value: 전화번호

위 색인으로 특정 성을 가진 모든 사람이나, 특정 성 + 이름을 가진 모든 사람을 찾을 수 있지만 특정 이름을 가진 모든 사람을 찾기는 힘듦 (스킵 스캔을 지원하기도 함)


#### 3.1.5.3. 전문 검색과 퍼지 색인
- 전문 검색 시  철자가 틀린 단어와 유사한 키에 대해서도 검색할 수 있도록 동의어를 자동으로 검색하거나 특정 편집 거리 내(edit distance) 단어 검색을 지원
#### 3.1.5.4. 모든 것을 메모리에 보관
- 데이터를 디스크에 저장하는 것의 장점
	- GB 당 비용이 저렴함
	- 디스크는 지속성이 있음
- 메모리에 저장하는 것의 장점
	- 모든 것을 메모리에 저장해 빠르게 읽어올 수 있음
	- 디스크에 데이터를 저장하기 위해 데이터를 부호화할 필요가 없어 오버헤드 감소
	- 디스크에 저장하는 것보다 구현이 간단함


### 용어
- Log: 시스템의 운영 현황 기록, 추가 전용 저장소
- WAL: Write Ahead Log, 로깅하기 전에 먼저 디스크에 데이터를 저장하고 장애 발생 시 복구에 활용
- LSM(Log-Structured Merge-Tree)
- SS Table: Sorted String Table


## 3.2. 트랜잭션 처리나 분석?

- 트랜잭션 처리: **주기적으로 수행되는 일괄 처리 작업과 달리 지연 시간이 낮은(low-latency) 읽기**, 쓰기 처리
	- 인덱스를 이용해 **적은 수의 레코드를 읽고, 쓰는 패턴**
- 분석: 트랜잭션 처리 처럼 데이터 저장소의 일부데이터를 가져오는게 아니라 **많은 수의 레코드를 스캔해 레코드의 일부 컬럼만 읽어 Count, Sum, Avg 값을 계산해 반환하는 패턴**
	- 예시: 2023년 1월 각 지역별 고객수와 매출은 얼마인가?

```sql
select * from orders where id = 10000;
```


| 특성 | 트랜잭션 처리 시스템 (OLTP) | 분석 시스템 (OLAP) |
| ----- | ----- | ----- |
| 주요 읽기 패턴 | 질의당 적은 수의 레코드, 키 기준으로 가져옴 | 많은 레코드에 대한 집계 |
| 주요 쓰기 패턴  | 임의 접근, 사용자 입력을 낮은 지연시간으로 기록 | 대규모 불러오기(bulk import, ETL) 또는 이벤트 스트림 |
| 주요 사용처 | 웹 애플리케이션을 통한 최종 사용자/소비자 | 의사결정 지원을 위한 내부 분석가 |
| 데이터 표현 | 데이터의 최신 상태(현재 시점) | 시간이 지나며 일어난 이벤트 이력 |
| 데이터셋 크기 | 기가 바이트에서 테라바이트 | 테라바이트에서 페타바이트 |

### 3.2.1. 데이터 웨어하우징

- 여러 도메인, 서비스의 데이터를 변환 후 **한 곳에 모아 데이터 분석**을 진행
- 한 곳에 데이터를 웨어하우징 하는 목적
	1. 높은 가용성과 낮은 지연시간이 요구되는 OLTP 환경과 쿼리 요청시 연산이 많은 OLAP 환경을 분리하여 **서비스의 안정성 보장**
	2. **데이터 분석에 편리한 스키마로 데이터를 변환 및 적재**하여 활용 (정규화 되어 쪼개져있는 테이블을 역 정규화, 스타스키마 구조로 데이터를 정리)
	3. **다양한 데이터 소스의 데이터들을 통합해서 분석**, ex. 구글 애널리틱스, AWS RDS 데이터를 조인해 데이터 분석 진행

ETL 예시 (Extract, Tranform, Load)
![[그림 3-8. ETL 예시.png]]

#### 3.2.1.1. OLTP 데이터베이스와 데이터 웨어하우스의 차이점

- 표면적으로는 OLTP, OLAP 데이터베이스 모두 SQL로 데이터를 조회할 수 있기에 비슷해 보임
- 하지만 **각 각 다른 데이터 조회 패턴에 맞게 최적화 됐기**에 시스템의 내부는 완전히 다름
	- 질의당 적은 수의 레코드, 키 기준으로 가져옴 (인덱스로 소량의 데이터를 조회, 갱신, 추가)
	- 많은 레코드에 대한 집계
- 요즘 대부분의 데이터베이스는 **트랜잭션 처리, 분석 작업부하  양쪽 모두를 지원하기 보다는 하나를 지원하는데 중점**을 두고 있음

#### 3.2.2. 분석용 스키마: 별 모양 스키마와 눈꽃송이 모양 스키마

- 2장에서 살펴본 것처럼 데이터 모델은 트랜잭션 처리 영역에서 애플리케이션의 필요에 따라 광범위하고 다양함
	- 문서형, 관계형, 그래프형 데이터 모델
- 반면 **분석에서는 데이터 모델의 다양성이 훨씩 적고 대부분의 데이터 웨어하우스는 별 모양 스키마로 상당히 정형화된 방식**을 사용함
	- Fact Table: 보통 특정 시간에 일어난 개별 이벤트와 수치들을 담고 있어 **많은 수의 Rows가 저장**됨
	- Dimension Table: Fact Table이 참조하는 테이블로 이벤트의 속성인 누가, 언제, 어디서, 무엇을, 어떻게, 왜를 나타내기에 사실 테이블보다 적은 수의 Rows가 저장됨
		- ex. 날짜(공휴일 정보등 저장), 브랜드 이름, 범주, 설명, 지역명 등

![[그림 3-9. 스타스키마 예시.png]]

- 눈꽃송이 모양 스키마: 차원 테이블을 더 세분화 함 (정규화)
- 별모양 스키마로 저장된 데이터를 분석하기 더 쉽기때문에 `보통 분석가들은 별모양 스키마를 선호함`

## 3.3. 컬럼 지향 저장소

- Fact Table 은 많은 Rows가 존재함
- 하지만 **Fact Table 의 모든 Column을 데이터 분석 시 사용하지 않음**
- 일반적인 OLTP 데이터베이스는 Row 단위로 데이터를 저장하고 불러옴
	- Row 단위로 데이터가 저장되어 있을 때 예제 3-1과 같은 쿼리를 처리하려한다면 각 Row의 100개 이상의 속성 값을 모두 디스크에서 읽어온 후  그 중에서 2~3개의 컬럼만 필터링해서 사용해야함
	- 조회 예시: 주, 카테고리별 상품 판매량 조회 (예제 3-1)
		- Row가 많은 fact_sales 테이블에서 quantity 컬럼만 사용
```sql
select
	dim_date.weekday
	, dim_product.category
	, sum(fact_sales.quantity) as quantity_sold
from fact_sales
left join dim_date on fact_sales.date_key = dim_date_date_key
left join dim_products on fact_sales.product_key = dim_products.product_key
...
group by
	dim_date.weekday, dim_product.category
```

- 컬럼 지향 저장소: 데이터를 Row 단위로 저장하는 것이 아닌 컬럼 단위로 값을 저장함
	- 데이터를 컬럼 단위로 저장하면 **분석 질의에 사용된 컬럼만 읽어 분석할 수 있고 결과적으로 디스크에서 읽어오는 데이터와 작업량이 줄어들 수** 있음
![[그림 3-10. 컬럼 단위 데이터 저장.png]]


### 3.3.1. 컬럼 압축


- 컬럼 단위로는 비슷한 값들이 많기에 효율적으로 압축할 수 있음

비트맵 부호화 압축 예시
![[그림 3-11. 압축된 단일 컬럼의 비트맵 색인 저장소.png]]
- **데이터를 압축해서 저장하고 압축한 파일을 읽어와 분석하기에 디스크 I/O 감소**
- AND, OR 연산으로 효율적인 처리 가능
```sql
where product_sk in (30, 68, 69)
-- 3개의 비트맵을 적재하고 세 비트맵의 비트 OR을 계산해서 데이터를 가져온다.

where product_sk = 3 and store_sk = 3
-- 2개의 비트맵을 각각 저장하고 비트 AND를 계산해서 데이터를 가져온다.
-- 각 컬럼에 동일한 순서로 데이터가 저장되기에 위처럼 계산할 수 있다.

```

#### 3.3.1.1.  메모리 대역폭과 벡터화 처리

- 수백만 로우를 스캔해야하는 데**이터 웨어하우스 질의의 가장큰 병목은 디스크로부터 메모리로 데이터**를 가져오는 대역폭
- 하지만 이외에 **메모리 -> CPU 캐시로 가는 대역폭**도 중요
- 컬럼 저장소 배치는 디스크로부터 적재할 데이터 양 줄이기 외에도 **CPU 주기를 효율적으로 사용하기에 적합**
	- 압축된 컬럼 데이터를 CPU의 L1 캐시에 딱 맞게 덩어리로 나눠 가져오고 함수 호출이 없는 타이트 루프 (Tight Loop)에서 반복
	- **컬럼 압축을 사용하면 L1 캐시에 더 많은 로우를 저장**할 수 있음
- 벡터화 처리: And, OR 연산으로 빠른 데이터 처리

### 3.3.2. 컬럼 저장소의 순서 정렬

- **각 컬럼을 개별로 정렬할 수 없음** (컬럼을 개별로 정렬하면 컬럼들의 조합으로 Row를 재구성할 수 없음)
	- 따라서 데이터 정렬 시 모든 컬럼을 한번에 정렬해야함
- **Sort Key가 존재해 정렬 할 수 있고 이를 이용해 효율적으로 쿼리**할 수 있음
	- ex. date_key가 1차 정렬 키 라면 특정 날짜 범위로 쿼리 시 효율적
- 정렬된 순서의 또 다른 장점: 컬럼 압축에 도움이 됨 (정렬 키를 Run-length 부호화 했을 때 매우 효율적)
	- **수십억 개의 로우를 가진 테이블이라도 수 킬로바이트로 컬럼을 압축**할 수 있음

[레드 시프트 Sort key Document]

![[레드시프트 sort key.png]]

#### 3.3.2.1. 다양한 순서 정렬
- 복제 데이터가 저장된 노**드 마다 서로 다른 방식으로 데이터를 정렬해서 저장하고 질의를 처리할 때 적절한 노드로 분기**함
- 궁금한점: 하지만 로우 지향 저장은 한곳(힙 파일)이나 클러스터드 색인에 모든 로우를 유지하고.. (103page)
	- Heap 파일의 CS적 의미

### 3.3.3. 컬럼 지향 저장소에 쓰기

- 컬럼 지향 저장소, 압축, 정렬은 모두 읽기 질의를 더 빠르게 하지만 **쓰기를 어렵게하는 단점**이 있음
- B-Tree 처럼 제자리 갱신(update-in-place, 레코드가 저장된 페이지를 찾아 페이지를 업데이트) 접근 방식은 불가능함
- **정렬된 테이블의 중간에 Row 삽입을 원할 경우 모든 컬럼 파일을 재작성**해야함
- LSM 트리가 정렬된 구조에 쓰기 데이터를 모았다가 충분한 데이터가 모이면 백그라운드에서 데이터를 쓰는 작업으로 극복

### 3.3.4. 집계: 데이터 큐브와 구체화 뷰

- 동일한 데이터를 집계 후 자주 사용한다면 캐싱해두자는 접근
- 가상 뷰: 질의의 단축키
- 구체화 뷰: 원본 데이터 변경 시에 갱신되는 뷰 **(실제 저장)**
- 데이터 큐브: 구체화 뷰의 특별 사례, **많은 케이스의 데이터를 미리 집계 해두고 사용**함
	- Raw 데이터에 질의하는 것과 동일한 유연성이 없음
	- 집계된 데이터 이기 때문에 원하는 데이터를 모두 찾을 수없음 

## 3.4. 정리

- 데이터베이스가 어떻게 저장과 검색을 다루는지 살펴봤음

고수준에서 데이터 저장소 엔진은  **트랜잭션 처리 최적화와 분석 최적화라는 2가지 범주**로 나눠짐
- 트랜잭션 처리 최적화 (OLTP)
	- OLTP 시스템은 보통 사용자 대면이기 때문에 대량의 요청을 받을 수 있음 (높은 TPS)
	- **작업 부하 유형은 보통 적은 수의 레코드를 조회, 삽입, 갱신하는 작업**
	- 데이터를 찾기 위해 저장소 엔진은 인덱스를 사용하고 `디스크 탐색이 병목`
- 분석 최적화 (OLAP)
	- 회사의 분석, ML 직군등이 사용함
	- 질의 수는 적지만 **각 질의는 매우 복잡하고 많은양의 데이터를 조회**해야함
	- 일반적으로는 디스크 탐색이 아닌 `디스크 대역폭이 병목`
	- 컬럼 지향 저장소는 디스크 대역폭 병목을 개선하기 위한 적절한 방법
		- 일부만 읽어올 수 있고 압축할 수 있음


OLTP 측면에서 두가지 주요한 관점
- 로그 구조화 관점
	- **데이터 추가와 오래된 파일의 삭제만 허용**하고 한 번 쓰여진 파일은 절대 갱신하지 않음
	- 비트캐스트, SS테이블, LSM, 레벨DB, 카산드라, Hbase, 루씬 등이 이 그룹에 속함
		- 쓰기가 빠르겠구나, 데이터를 로그로 저장하는 구나..
- 제자리 갱신 관점
	- 덮어쓰기 할 수 있는 고정 크기 페이지의 셋으로 디스크를 다룸 (대표적인 예: B 트리)

로그 구조화 저장소 엔진은 비교적 최근에 개발되었고 **핵심 아이디어는 임의 접근 쓰기를 순차 쓰기**로 바꾼 것
- 이를 통해 쓰기 처리량을 높이는 것이 가능