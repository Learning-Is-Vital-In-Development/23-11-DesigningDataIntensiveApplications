# **03장. 저장소와 검색**DB란

---

# 들어가기에 앞서

- 관계형 DB와 NoSQL DB에 사용되는 저장소 엔진에 대해 공부한다.
- 로그 구조(log-structured) 계열 저장소 엔진과 (B-tree 같은) 페이지 지향(page-oriented) 계열 저장소 엔진을 검토한다.

# DB란

### DB작업

- data 저장 ,data 요청 시 제공

### 개발자가 DB 내 저장 및 검색 처리 방법을 주의해야하는 이유

- 처음부터 저장소 엔진을 구현하는 것이 아닌, 사용 가능한 여러 저장소 엔진 중 가장 적합한 엔진을 선택해야 하기 때문 ( **작업 부하**에 맞춰 최적화 된 저장소 엔진/ **분석** 위해 최적화된 엔진 차이)

### DB를 강력하게 만드는 데이터 구조

DB는 대부분 내부적으로 append-only 데이터 파일인 로그(`연속된 추가 전용 레코드`)를 사용한다. 

DB에서는 일반적으로 특정 키의 값을 효율적으로 찾기 위해 Index를 사용한다. 

- Index(색인)
    - 저장소 시스템에서 중요한 `trade off 관계`
    - 인덱스가 많이 있다면 여러 **WHERE 절 조건에 대응**할 수 있는 또는 **조회**에서 조금 더 효과 적인 인덱스를 사용할 수는 있겠지만, trade-off 관계로 Index 가 많아질수록 데이터의 입력이나 갱신에서는 적은 인덱스를 사용하는 것에 비해 상대적으로 성능이 불리해 질 수 있다.
    - 인덱스를 잘 선택하면 **읽기 속도가 향상** 되지만 모든 인덱스는 **쓰기(write) 속도를 떨어뜨린다**. (데이터를 쓸 때마다 인덱스도 갱신해야 하기 때문.)
    - 따라서!  DB는 일반적으로 모든 것을 인덱싱하지는 않고, 개발자가 수동으로 인덱스 설정을 하도록 해서 적은 오버헤드로 고효율을 주도록 한다.

### 

# 서론

이전에 스터디에서 바로 3장에 들어갔을 때는 정말 데이터 모델? 질의 언어? 무슨 소리하는지 하나도 몰랐는데 

1장에서는 책에서 사용하는 용어들을 배우고, 2장에서는 데이터 모델과 질의 언어에 대해 비교해보았다. 
이렇게 1,2장부터 찬찬히 해보니 흐름이 이해가 돼서 재밌는거 같다 

**2장**에서는 애플리케이션 개발자의 관점에서 DB에 데이터를 제공하는 형식을 설명했다면, 
**3장**에서는 DB관점에서 데이터를 저장하는 방법과 요청했을 때 다시 찾을 수 있는 방법에 대해 알아본다.
→ 개발자가 내부 구현을 알아야지 적합한 DB 선택이 가능해지기 때문.

엔진은 크게 `트렌젝션 처리`/`분석`에 따라 크게 나눌 수 있다.

> `트렌젝션 처리 최적화 엔진`  → 이번 차시에서 확인할 저장소
> 
- 트랜잭션 작업부하에 맞춰 최적화 됨.
- **저장소**
- 관계형 데이터 베이스(RDBMS) / NoSQL

> `분석 최적화 엔진`
> 
- 칼럼 지향 저장소
- **분석**

## DB 를 강력하게 만드는 데이터 구조

### 로그

> 일반적으로 많은 DB는 내부적으로 **추가 전용(append-only)** 데이터 파일인 **로그(log)를 사용**
** 로그 - 일반적인 의미 : 연속된 추가 전용 레코드 (binary 파일인 경우 많음)*
> 
- 일반적으로 파일 추가 작업은 매우 효율적이기 때문에 , 매우 간단한 작업의 경우에 db_set 같은 함수가 꽤 좋은 성능을 보인다. 
→ 추가적으로 고려할 사항은 많지만 로그는 유용함
    - DB에서 다뤄야할 문제들
        - 동시성 제어
        - 로그 compaction을 통한 디스크 공간 회수
        - 오류 처리 (오류로 인한 부분적 기록 레코드 ... )
        - ...
- append only 예시 (db_set)
    
    ```bash
    #!/bin/bash
    
    #매우 간단한 형태의 DB를 bash 함수로 구현
    db_set() {
    	echo "$1, $2" >> database
    }
    
    db_get() {
    	echo "^$1, " database | sed -e "s/^$1,//" | tail -n 1
    }
    ```
    
    ![dp_set 호출 시 파일의 끝에 추가를 하므로 키를 여러번 갱신해도 값의 예전 버전을 덮어쓰지 않음. 따라서 파일의 최신 값을 찾기 위해 파일에서 키의 마지막 항목을 살펴보면 됨 → tail -n 1](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/4ea00fc7-e561-4891-9f3d-4c922508ada9/Untitled.png)
    
    dp_set 호출 시 파일의 끝에 추가를 하므로 키를 여러번 갱신해도 값의 예전 버전을 덮어쓰지 않음. 따라서 파일의 최신 값을 찾기 위해 파일에서 키의 마지막 항목을 살펴보면 됨 → tail -n 1
    
- 하지만! db_set은 DB에 많은 레코드가 있으면 성능이 좋지 않다. 레코드 수가 2배로 늘면 검색도 2배
→ 매번 키를 찾을 때 마다 전체 db파일을 처음부터 끝까지 스캔해야하므로 (검색 비용 O(n))
**레코드란? SQL에서 행(row) 또는 튜플(tuple)이라고 불린다.*
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/b46486df-4e14-40e1-bcba-48fc25db804c/Untitled.png)
    

### 색인

> 특정 키의 값을 효율적으로 찾기 위해 다른 데이터 구조가 필요한데 이게 바로 **`색인(index)`**이다!
**색인이란? 
- 일반적인 개념 : 부가적인 메타데이터(이정표 역할) 유지하는 것.
- 정의 : 특정 키의 값을 효율적으로 찾기 위해 필요한 것 (*기본 데이터에서 파생된 추가적인 구조)
- *특징:
    - DB의 내용에 영향을 미치지는 않으나. 추가적인 구조(인덱스)의 유지보수는 특히 쓰기 과정에서 **오버헤드**를 동반한다.
    - 어떤 종류의 색인이라도 속도를 느리게 만든다 → 색인도 갱신해야되기 때문 (단순 append구조보다 당연히 느리다.)
    -  `trade off : (색인 선택) 읽기 속도 ▲ 쓰기 속도 ▼` 
     → 따라서 모든 DB는 자동으로 모든 것을 색인하지 않는다. (애플리케이션 개발자나, db관리자가 전형적인 질의 패턴에 대한 지식을 활용해 수동으로 색인을 선택해야 **오버헤드를 지양**할 수 있음)*
> 

- 색인 종류
    - ****해시 색인 (Hash index)****
    - ****SS 테이블 & LSM 트리****
    - ****B 트리****

## 해시 색인 ****(Hash index)****

- Key - Value 색인 구조 (a.k.a dictionary Type)
- **가장 간단한 색인 전략 - key 값 데이터 파일의 byte offset에 매핑해 Inmemory HashMap 유지**
    - **byte-offset을 통해 값을 바로 찾을 수 있음**
    - **but 파일에 k-v를 추가할 때마다 직전 data offset을 반영하기 위해서는 메모리의 HashMap도 갱신해야함**
- 해당 방식 : Bitcask(비트캐스크) - 리악(Riak)의 기본 저장소 엔진에서 근본적으로 사용하는 방식
    - 비트캐스크 : HashMap을 전부 메모리 유지 -> 고성능의 읽기 쓰기 보장
- 해당 방식은 key 별 value가 자주 갱신되는 상황에 매우 적합하다
- 즉 쓰기가 많지만, 고유 key 값이 많지 않은 상황(key 당 쓰기 수가 많지만 메모리에 모든 키 보관이 가능할 때)

### 1) **Log-structured 형식 (가장 간단한 색인 전략, 비트캐스크)**

Bitcask(비트캐스크) - 리악(Riak)의 기본 저장소 엔진에서 근본적으로 사용하는 방식 : Key - Value 색인 구조 (가장 간단한 색인 전략) 

- 비트캐스크 : HashMap을 전부 메모리 유지 -> 고성능의 읽기 쓰기 보장
- 메모리 해시맵은 모든 데이터를 메모리에 저장하므로 읽기, 쓰기 속도 모두 성능이 높다.
    - 값이 자주 갱신되는 쓰기 작업에 유리하다.→ 예) url 조회 수 증가 작업 , url 데이터는 작으나 조회수는 갱신

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/a87ab334-f47e-4002-b542-219877387673/Untitled.png)

- 단점 : 항상 파일에 추가만 하기 때문에 결국 디스크 공간이 부족

### 2) Compaction (지속적 write 디스크 공간부족 문제 해결)

컴팩션이란 중복된 키를 버리고 각 키의 최신 값만 유지하는 것을 말한다.

→ 데이터를 특정 크기의 세그먼트(segment)로 나누고 주기적으로 컴팩션(compaction)을 수행하여 l**og structured 형식의 디스크 공간 부족 문제**를 해결한다. 
이렇게 하면 해시 맵은 각 데이터의 오프셋과 키를 매핑하고 각 오프셋이 가리키는 값은 최신 값임을 보장할 수 있다.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/0e0a7a38-b35b-4b62-bede-e5bfc4a7020a/Untitled.png)

**과정 정리**

- 세그먼트가 특정 크기 도달 시, 병합을 위한 새 세그먼트 파일 생성
- 세그먼트 병합은 백그라운드 스레드에서 수행, 이를 통해 이전 세그먼트에 읽기/쓰기 처리 정상 수행 가능
- 병합이 끝난 후, 새 세그먼트로 전환 → 기존 세그먼트 파일 삭제 (log에서 중복된 키를 버리고 키별 최신 value만 유지)
- 병합 과정을 통해 세그먼트 수를 더 적게 유지하기 때문에 조회할 때 많은 해시 맵을 확인할 필요 X

### 해시 테이블 색인의 한계

해시 색인은 간단한 만큼 단점이 확실하다.

- 해시 맵을 메모리에 저장해야 하므로 키가 너무 많으면 문제가 된다.  (모든 데이터에 대한 키를 저장하므로)
디스크에 해시 맵을 유지할 수는 있지만 무작위 접근 I/O가 많이 필요하기 때문에 디스크 상의 해시 맵에 좋은 성능을 기대하기는 어렵다.
- **해시 맵은 범위 질의(range query)에 굉장히 비효율적이다.** 해시 맵에서 모든 키를 개별적으로 조회해야 한다.

## ****SS 테이블 & LSM 트리 (제한 없는 색인 구조)****

두 테이블과 해시 색인과의 차이는 세그먼트 병합 시 `key-value 쌍으로 **키를 정렬**`한다는 것이다. 

<aside>
💡 **정렬이 메모리 용량과 검색 속도에 어떤 영향을 미칠까?**

- 특정 키를 찾기 위해 메모리에 모든 키의 색인을 유지할 필요가 없기 때문에, 검색 속도가 빨라진다!
</aside>

### SS테이블 (**Sorted String Table)**

Log-structured 데이터 형식을 **Sorted String Table** 혹은 **`SS 테이블`**이라 칭한다.

- 세그먼트가 정렬되어 있어 merge sort 및 특정 키를 찾기 위해 메모리에 모든 키의 색인을 유지할 필요가 없다.

**데이터를 키로 정렬하는 방법 (쓰기와 읽기 과정)**

디스크 보다 메모리에서 정렬하고 디스크로 내려다 보는 편이 쉽다!

1. 쓰기가 들어오면 인메모리 `균형 트리(balanced tree)` `데이터 구조(e.g. red-black tree`)에 추가한다. 
이 `인메모리 트리`를 `멤테이블(memtable)`이라고 부른다.
2. 멤테이블의 크기가 `임계값(보통 수 MB)`보다 커지면 `SS테이블 파일`로 디스크에 기록 (트리가 이미 정렬되어 있기 때문에 효율적)
3. 읽기 요청을 처리하려면 먼저 멤테이블에서 키를 찾는다. 그 다음 디스크상의 최신 세그먼트부터 찾는다. (인메모리 해시맵이나 bloom filter 를 사용하여 탐색 시간을 줄일 수 있다.)
4. 백그라운드에서 지속적으로 컴팩션 과정을 수행한다.

### LSM트리 **(Log-Structured Merge-Tree)**

SS 테이블의 형식으로 디스크에 key-value 데이터를 **저장**하는 색인 방식 
→ append-only 로그 형식으로 저장하고 지속적으로 merge sort를 수행한다.

- 블룸 필터 (Bloom Filter)

블룸 필터는 **원소가 특정 집합에 속하는지 여부를 확률적으로 알아낼 수 있는 자료구조**로, 이를 활용하면 키가 데이터베이스가 존재하는지 유무를 알 수 있다. 블룸 필터를 통해 데이터가 없다고 판단되었을 경우, 실제로도 찾으려는 데이터가 디스크에 존재하지 않음이 보장되기 때문에 추가적인 디스크 읽기를 아낄 수 있다. 다만, 블룸 필터는 데이터가 있다고 판단했지만 실제 디스크에는 데이터가 없는 **False Positive 가 발생할 수 있다.**

- 레벨 컴팩션 (Leveled Compaction)

SS 테이블을 여러 단계(level)로 구분한다. 단계가 높아질수록 테이블의 크기가 커진다. 상대적으로 좀 더 새롭고 작은 SS 테이블을 상대적으로 오래됐고 큰 SS 테이블에 연이어 합치는 방식이다. 한 레벨의 SS 테이블 파일들끼리는 키가 겹치지 않는 특징 때문에 데이터를 찾기 위해서 level 수만큼만 쿼리하면 된다.

- Skip List

멤테이블에 데이터를 효율적으로 쓰고 읽기위해 멤테이블을 skip list 로 구현하는 경우도 있다. (Rocks DB, Level DB)

## B트리 (가장 널리 사용되는 색인 구조)

LSM 트리 색인이 보편화되고 있지만 아직까지 가장 널리 사용되는 색인 구조는 B트리이다.
정렬된 키-값 쌍을 유지하기 때문에 범위 질의에 효율적이라는 점 빼고는 사실상 두 구조는 아예 다르다.

*`LSM` : 수 메가바이트 이상의 가변 크기를 가진 **세그먼트 단위**로 데이터를 기록하고 이는 항상 순차적이다.
* `B트리` : 보통 4KB 고정 크기의 **페이지 단위**로 읽기 또는 쓰기를 수행한다. 이는 근복적으로 하드웨어와 조금 더 밀접한 관련이 있다.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/4844e4f8-8064-4df0-bb27-ac7073d3072e/Untitled.png)

**B트리의 페이지** 

한 페이지가 가지고 있는 **참조 수**를 `분기 계수(branching factor)`라고 부른다. → 위 그림에서 분기 계수는 6 이다. 
*대부분의 데이터베이스는 수백 개 정도로 지정한다고 한다.

- 색인에서 키를 찾으려면 `루트(root) 페이지`(B트리의 루프페이지로 지정된)에서 시작해야한다.
- 최종적으로는 `리프(leaf) 페이지`에 도달, 리프페이지는 **각 키의 값이나 값을 찾을 수 있는 페이지의 참조**를 갖고있다.

**B 트리에 존재하는 키의 값을 갱신하는 과정**

- 해당 키를 포함하고 있는 리프 페이지를 검색 → 페이지의 해당 키 값을 수정 → 페이지를 디스크에 기록 
*페이지에 대한 모든 참조는 유지된다. (유효)
- 이 알고리즘은 Tree 가 계속 **균형**을 유지하는 것을 보장한다. n개의 키를 가진 B-tree는 깊이가 항상 O(logn)이다.
- 대부분 DB에서 깊이는 3~4 단계면 충분하다.
분기 계수 500의 4KB페이지의 4단계 트리는 256TB 까지 저장할 수 있다

## 색인 전략
	해시 색인	SS 테이블 & LSM 트리	B 트리
설명	- 가장 간단한 색인 전략
- 색인으로 key-value 저장소를 쓴다. 
- 키를 데이터 파일의 바이트 오프셋에 매핑해 인메모리 해시맵에 저장하는 것 (값을 조회하려면 해시 맵을 사용 해 데이터 파일에서 오프셋을 찾아 위치를 구하고 값을 얻어야한다.)
- 시간복잡도 O(n)	- 해시 색인과 다르게 제한이 없는 색인 방식
- 해시 색인에서 모든 key-value 쌍을 키를 기준으로 정렬한 Log-structured 데이터 형식 : Sorted String Table, SS 테이블 칭함.
-LSM 트리: SS 테이블의 형식으로 디스크에 key-value 데이터를 저장하는 색인 방식
(수 메가바이트 이상의 가변 크기를 가진 세그먼트 단위로 데이터를 기록하고 이는 항상 순차적)	- 가장 널리 사용되는 색인 구조
- 정련된 키-값 쌍이라 범위 질의에 효율적이라는 점 빼고는, LSM트리와 다 다르다.
- B 트리는 보통 4KB 고정 크기의 페이지 단위(page-oriented)로 읽기 또는 쓰기를 수행한다. 이는 근복적으로 하드웨어와 조금 더 밀접한 관련이 있다.
분기 계수 500, 페이지 크기 4KB인 4단계 B 트리는 256TB 까지 저장할 수 있다.
장단점 	(단점)
- 해시 맵을 전부 메모리에 유지하는 것을 조건으로 사용하기 때문에, 키가 너무 많으면 성능이 떨어진다. 
- 디스크에 해시맵 유지는 가능하나, 무작위 접근 I/O가 많이 필요해 디스크 상의 해시 맵에 좋은 성능을 기대하기는 어렵다. 
- 해시 맵은 범위 질의(range query)에 굉장히 비효율적→모든 키를 개별적으로 조회해야하기 때문
- 로그 구조(log-structured) 형식으로 데이터를 저장하면 파일에 항상 추가만 하기 때문에 디스크 공간이 부족해진다. 	(장점)
- 세그먼트 병합이 보다 효율적이다. 세그먼트가 정렬되어 있기 때문에 merge sort 가 가능하다.
-파일에서 특정 키를 찾기 위해 더는 메모리에 모든 키의 색인을 유지할 필요가 없다. 아래 그럼처럼 일부 키 색인만 있으면 충분하다. (대략 수 킬로바이트당 키 하나)	
적합한 작업	- 키 자체가 많지는 않지만 키당 write 수가 많은 작업 부하에 적합하다. 
-로그 구조(log-structured) 형식에서 특정 크기의 세그먼트로 나누고 주기적으로 컴팩션(compaction:중복된 키 버리고 각 키의 최신값만 유지)을 수행해서 디스크 공간 문제를 해결한다.
 → 해시 맵은 각 데이터의 오프셋과 키를 매핑하고 각 오프셋이 가리키는 값은 최신 값임을 보장한다.	LSM 트리가 성능을 최적화한 방법
- 블룸 필터 (Bloom Filter)
    - 특정집합에 속하는지 여부 확률적으로 알아낼 수 있는 자료구조
    - 추가적인 디스크 읽기 안할 수 있지만,블룸필터는 데이터가 있다고 판단했으나 실제로 없는 경우 false positive 발생
- 레벨 컴팩션 (Leveled Compaction)
    - SS테이블을 여러 단계로 구분, 단계가 높아질 수록 테이블이 커짐. 한 레벨의 SS 파일끼리는 키가 겹치지 않아 데이터 찾기 위해 level수만큼만 쿼리하면 됨
- Skip List
    - 멤테이블을 skip list로 구현하기 (Rocks DB, level DB)	-
