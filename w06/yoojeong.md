## 부호화와 발전

### 데이터 부호화 형식

데이터는 보통 두 가지 형태로 표현된다.

- **메모리에서** - Object, Struct, List, Array, Tree, Hash Table 등 (CPU에서 효율적으로 접근, 조작 가능)
- **파일 혹은 네트워크 전송에서** - 스스로를 포함한 일련의 바이트열 (JSON 등)의 형태로 부호화


이처럼 두 가지 표현 사이에 데이터 전환이 필요하고, 이 때 사용되는 방식이 부호화이다.

> **부호화란?**
<br>인메모리 표현에서 바이트열로의 전환. 다른 말로는 직렬화, 마샬링이라고도 한다.


### 언어별 형식

자바, 루비, 파이썬 같은 언어들은 인메모리 객체를 바이트열로 부호화하는 기능을 내장한다.<br>
이는 최소한의 추가 코드로 인메모리 객체를 저장하고 복원할 수 있어 편리하지만 다음과 같은 문제점들이 있다.

1. 특정 프로그래밍 언어와 묶여 있어 다른 언어에서 데이터를 읽기가 어렵다. 이는 다른 언어를 사용하는 다른 시스템과의 통합을 어렵게 만든다.

2. 동일한 객체 유형의 데이터를 복원하려면 복호화 과정에서 임의의 클래스를 인스턴스화할 수 있어야 하고, 이는 보안 문제의 원인이 된다. 공격자가 임의의 바이트열을 복호화할 수 있는 어플리케이션을 얻어 임의의 클래스를 인스턴스화할 수 있고 공격자가 원격으로 임의 코드를 실행할 수도 있다.

3. 데이터 버전 관리는 부호화 라이브러리에서는 우선순위가 떨어져 상위, 하위 호환성의 문제가 등한시되곤 한다.

4. 복/부호화에 소요되는 CPU, 부호화된 구조체 크기 등 효율성이 고려되지 않을 수 있다.

<details>
<summary>직렬화 후 바이트 크기 비교</summary>
  
![image](https://github.com/rachel5004/23-11-DesigningDataIntensiveApplications/assets/75432228/2be4dc22-25e1-44af-86da-45c6ac3ad617)

</details>

<details>
<summary>직렬화 소요 시간 비교</summary>
  
![image](https://github.com/rachel5004/23-11-DesigningDataIntensiveApplications/assets/75432228/671eff79-cc59-485a-a2d5-f66b7d1fabc1)


</details>

### JSON과 XML, 이진 변형

JSON, XML, CSV는 텍스트 형식이므로 어느정도 사람이 읽을 수 있다.<br>
그러나 이들의 문법적 문제 외에도 일부 미묘한 문제가 있다.

**1. Number 부호화의 애매함**

XML과 CSV에서는 number와 digit으로 구성된 문자열을 구분할 수 없다.<br>
JSON은 string과 number를 구분하지만 정수와 부동소수점은 구별하지 않고 정밀도가 떨어진다.<br>
특히 이 문제는 큰 수를 다룰 때 문제가 되는데, 2^53과 같은 큰 정수는 부동소수점 수에서는 정확하게 표현할 수 없기 때문에 JS같은 언어에서는 파싱할 때 부정확해질 수 있다.

**2. 이진 문자열 미지원**

JSON과 XML은 유니코드 문자열(사람이 읽을 수 있는 텍스트)을 잘 지원하지만 이진 문자열(문자 부호화가 없는 바이트열)은 지원하지 않는다.<br>
이런 제한을 피하는 방법으로 Base64 인코딩 형식을 사용해 텍스트로 부호화한 다음 Base64로 부호화되었다는 사실을 스키마를 통해 명시하고 있으나, 이 방법은 정공법과는 거리가 있으며 데이터 크기가 33% 증가한다는 단점이 있다.

**3. 스키마 지원이 취약함**

XML, JSON 은 스키마를 지원하지만 구현하기가 상당히 난해하다.<br>
또한 데이터의 올바른 해석은 스키마의 정보에 따라 달라지므로 XML/JSON 스키마를 사용하지 않는 어플리케이션은 별도의 부호화/복호화 로직을 작성해야 한다.

**4. CSV의 스키마 미지원**

CSV는 스키마를 미지원하기 때문에 각 row, column의 의미 정의는 어플리케이션에서 작업해야 한다.<br>
따라서 변경에 유연하지 못하고 CSV 자체가 매우 모호한 형식이기 때문에 모든 Parser가 규칙을 정확하게 구현하지는 않는다.


이러한 결점들에도 불구하고 JSON, XML, CSV는 앞으로도 인기를 유지할 것이다.<br>
특히 데이터 교환 형식으로 사용하기에 매우 좋다.

**무엇이든 다른 조직의 동의를 얻는 것**이 대부분의 다른 문제들(가독성,효율성 등)보다 더 크다.

### 이진 부호화

작은 데이터 셋의 경우에는 부호화 형식 선택으로 얻는 이득이 매우 작지만 테라바이트 정도가 되면 데이터 타입의 선택이 큰 영향을 미친다.

데이터타입 셋을 확장하지만 JSON/XML 모델은 유지하는 형식의 다양한 이진 부호화의 개발로 이어졋다.

```java
{
  userName: 'Martin',
  favoriteNumber: 1339,
  interests: ['daydreaming', 'hacking']
}
```

to MessagePack

![image](https://github.com/rachel5004/23-11-DesigningDataIntensiveApplications/assets/75432228/67f0ec6f-7704-4723-952f-265a237780f7)

- 첫 번째 byte(0x83)는 이어지는 내용이 세 개의 필드(하위 4bit = 0x03)을 가진 객체(상위 4bit = 0x80)라는 뜻

만약 객체가 15개가 넘는 필드를 가지고 있어 4bit에 맞지 않다면 필드 수를 2 혹은 4바이트로 부호화한다.

- 두 번째 byte(0xa8)은 이어지는 내용이 8byte 길이(하위 4bit = 0x08)의 문자열(상위 4bit = 0xa0)이라는 뜻
- 다음 8byte는 필드 이름인 `userName`의 아스키 코드, 길이는 이전에 8byte로 표시됐기 때문에 EOF 표기할 필요 없음
- 다음 7byte는 앞에 0xa6(하위 4bit = 0x06 = 6byte길이, 상위 4bit = 0xa0 = 문자열)이므로 `Martin`이라는 6글자 문자열 값을 부호화함


메시지팩으로 이진 부호화한 이후의 크기는 66byte로 JSON(81byte)보다 작다.

이진부호화를 통해 JSON의 용량문제를 어느정도 해소 할 수 있지만 이 작은 공간의 절약(어쩌면 파싱속도의 향상)이 가독성을 해칠 만큼 가치가 있는지는 확실하지 않다.

### Thrift와 프로토콜 버퍼(propuf)

Apache Thrift와 Protocol Buffer(protobuf)는 같은 원리를 기반으로 한 이진 부호화 라이브러리이며, 둘 다 모두 부호화할 데이터를 위한 스키마가 필요하다.

```c
# Thrift
struct Person {
	1: required string userName,
	2: optional i64 favoriteNumber,
	3: optional list<string> interests
}
```

```c
# protobuf 
message Person {
	required string user_name = 1;
	optional int64 favorite_number = 2;
	repeated string interests = 3;
}
```

Thrift와 protobuf 둘다 스키마 정의를 사용해 코드를 생성하는 도구가 있다.<br>
이 도구는 다양한 언어로 스키마를 구현한 클래스를 생성하고 어플리케이션은 생성된 코드를 호출하면 스키마의 레코드를 부호화하고 복호화한다.


이 스키마로 부호화된 데이터는 그럼 어떤 모습일까?

Thrift는 두 가지 프로토콜이 존재한다.

1. 바이너리 프로토콜

각 필드에는 메시지팩처럼 타입 주석(annotation)이 있고 필요한 경우 길이 표시가 있다.<br>
데이터에 나타난 문자열도 유사하게 Ascii로 부호화한다.<br>
메시지팩과 다른 점은 필드이름(usernme, favoriteNumber, interests)이 없고 ”필드태그” 로 이를 대체한다. 

![image](https://github.com/rachel5004/23-11-DesigningDataIntensiveApplications/assets/75432228/b7ee3de1-da65-4cb5-b1bc-fa0db9d7359d)

2. 컴팩트 프로토콜

의미상으로는 바이너리 프로토콜과 유사하지만 동일한 정보를 단지 34byte로 줄여 부호화한다.<br>
필드 타입과 태그 숫자를 1byte로 줄이고 가변 길이 정수를 사용하여 부호화한다.<br>

ex) 숫자 1337같은 경우 8byte가 아닌 2byte만을 사용하여 부호화한다.<br>
각 byte의 상위 bit는 앞으로 더 많은 byte가 있는지 나타내는데 이것은 `-64~63` (`-2^6 ~ 2^6-1`)은 1byte로 부호화하고 `-8192~8191`(`-2^13 ~ 2^13-1`) 사이의 숫자는 2byte로 부호화한다. 숫자가 클수록 더 많은 byte를 사용한다.

![image](https://github.com/rachel5004/23-11-DesigningDataIntensiveApplications/assets/75432228/8a439db5-a310-4967-81b4-b8cc4f21144c)


 프로토콜 버퍼는 이진 부호화 형식이 하나뿐이고, 비트를 줄여 저장하는 처리 방식이 약간 다르지만 스리프트의 컴팩트프로토콜과 매우 비슷하다. <br>
스키마에서 각 필드에는 required나 optional 를 통해 필드가 설정되지 않은 경우를 실행 시에 확인할 수 있고, 이는 버그를 잡을 때 유용하다.

 ![image](https://github.com/rachel5004/23-11-DesigningDataIntensiveApplications/assets/75432228/1d908cf3-f2d4-474f-a5db-655ef1d3b92e)



### 필드 태그와 스키마의 발전

스키마는 필연적으로 시간이 지나면서 변한다. 이를 **스키마 발전**이라고 한다.<br>
그렇다면 Thrift와 프로토콜 버퍼는 어떻게 하위 호환성과 상위 호환성을 유지하면서 스키마를 변경할까?

부호화된 레코드는 부호화된 필드의 연결일 뿐이다. 각 필드는 **태그로 식별**하고 데이터 타입을 주석으로 단다.<br>
필드 값을 설정하지 않은 경우엔 단순히 부호화 레코드에서 생략한다.

부호화된 데이터를 해석하기 위해 중요한 것은 필드 태그이기 때문에 필드 태그는 변경할 수 없고, 필드 이름은 참조하지 않기 때문에 쉽게 변경할 수 있다.


필드 추가는 필드에 새로운 태그 번호를 부여하여 스키마에 새 필드를 추가할 수 있다.<br>
따라서 상위 호환성을 지킬 때 예전 코드에서 새로운 코드로 기록한 데이터를 읽을 때 해당 필드를 간단히 무시할 수 있다.<br>
또한 데이터타입 주석은 Parser가 몇 byte를 건너뛸 수 있는지 알려주어 상위 호환성을 유지한다.

하위 호환성은 각 필드에 고유 태그 번호가 있는 동안에는 태그 번호가 계속 같은 의미를 갖고 있으므로 새로운 코드가 예전 데이터를 항상 읽을 수 있다.<br>
그러므로 하위 호환성을 유지하려면 필드를 추가할 경우에는 optional로 추가하거나 기본값을 가져야한다.<br>
새 필드를 required로 추가하게 되면 새로운 코드가 예전 코드로 기록된 데이터를 읽는 작업이 실패한다.


필드를 삭제하는 방법은 필드를 추가할 때 하위 호환성과 상위 호환성 문제를 해결하는 방식과는 반대로 하면 된다.<br>
즉, optional 필드만 삭제할 수 있고 같은 태그 번호는 절대 다시 사용할 수 없다.


### 데이터타입과 스키마 발전

필드의 데이터타입을 변경는 것은 가능하긴 하지만 값이 부정확해지거나 잘릴 위험이 있다.

예를 들어 32비트 정수를 64비트 정수로 변경할 때, 파서가 누락된 비트를 0으로 채울 수 있기 때문에 새로운 코드는 예전 코드가 기록한 데이터를 쉽게 읽을 수 있다.<br>
하지만, 새로운 코드가 기록한 데이터를 예전 코드가 읽는 경우 예전 코드는 값을 유지하기 위해 32비트 변수를 계속 사용하여, 복호화된 64비트 값은 32비트에 맞지 않기 때문에 잘리는 현상이 발생할 수 있다.


- 프로토콜 버퍼에는 목록이나 배열 데이터타입이 없지만 대신 필드에 repeated 표시자가 있다
  
 repeated 필드의 부호화는 레코드에 단순히 동일한 필드 태그가 여러 번 나타난다.<br>
 이것을 활용하면 단일 값인 optional 필드를 다중 값인 repeated 필드로 변경해도 문제가 없다.

 이전 데이터를 읽는 새로운 코드는 0이나 1개의 엘리먼트가 있는 목록으로 보게 되고, 새로운 데이터를 읽는 예전 코드는 목록의 마지막 엘리먼트만 보게 된다.


- Thrift의 목록 데이터타입

스리프트의 전용 목록 데이터타입은 목록 엘리먼트의 데이터타입을 매개변수로 받는다.<br>
프로토콜 버퍼와는 다르게 단일 값 → 다중 값으로의 변경을 허용하지 않지만 중첩된 목록을 지원한다. (장점??)

### 아브로

Apache 아브로는 Thrift가 하둡에 적합하지 않아 하둡의 하위 프로젝트로 시작한 이진 부호화 형식이다.


아브로도 부호화할 데이터 구조를 지정하기 위해, 사람이 편집할 수 있는 **아브로 IDL**과 기계가 더 쉽게 읽을 수 있는 **JSON 기반 언어** 두 개의 스키마 언어를 사용한다.


```C
record Person {
  string userName;
	union {null, long} favoriteNumber = null;
	array<string> interests;
}
```

```JSON
{
	"type": "record",
	"name": "Person",
	"fields": [
		{"name":"userName", "type":"string"},
		{"name":"favoriteNumber", "type":["null", "long"], "default": null},
		{"name":"userName", "type":{"type": "array", "items": "string"}}
	]
}
```

아브로는 Thrift와 프로토콜 버퍼와는 다르게 태그 번호가 없다. 따라서 이 스키마를 이용하면 32byte로 이진 부호화 형식들 중에서 길이가 가장 짧다.<br>
필드나 데이터타입을 식별하기 위한 정보가 없고, 부호화는 단순히 연결된 값으로 구성된다.

![image](https://github.com/rachel5004/23-11-DesigningDataIntensiveApplications/assets/75432228/60a67cf0-e6d3-47f7-9e68-8219ebe38e48)

아브로로 이진 데이터를 파싱하려면 스키마에 나타난 순서대로 필드를 살펴보고 스키마를 이용해 각 필드의 데이터타입을 미리 파악해야 한다.<br>
즉, 데이터를 읽는 코드가 데이터를 기록한 코드와 정확히 같은 스키마를 사용하는 경우에만 이진 데이터를 올바르게 복호화할 수 있다.


### 쓰기 스키마와 읽기 스키마

- 쓰기 스키마
  - 어플리케이션이 파일이나 데이터베이스에 쓰기 위해 또는 네트워크를 통해 전송하기 위해 어떤 데이터를 아브로로 부호화하려면 알고 있는 스키마 버전을 사용하여 데이터를 부호화한다.
 - 이떄 사용되는 스키마는 애플리케이션에 포함 할 수 있는데 이 스키마를 “쓰기 스키마”라고 한다.
- 읽기 스키마
  - 어플리케이션이 파일이나 데이터베이스에서 또는 네트워크로부터 수신 등으로 읽은 데이터를 복호화할 때 데이터가 특정 스키마로 복호화하길 기대하는데 이 스키마를 읽기 스키마라고 한다.
  - 어플리케이션 코드는 읽기 스키마에 의존하여 복호화 코드는 빌드시간에 스키마로부터 생성된다.
 

아브로의 핵심 아이디어는 바로 쓰기 스키마와 읽기 스키마가 동일하지 않아도 되며, 단지 호환 가능하면 된다는 것이다.<br>
데이터를 복호화(읽기)할 때 쓰기 스키마와 읽기 스키마를 함께 본 다음 쓰기 스키마에서 읽기 스키마로 데이터를 변환하여 그 차이를 해소한다.

![image](https://github.com/rachel5004/23-11-DesigningDataIntensiveApplications/assets/75432228/18737a84-7524-48aa-9b30-8f6c3be3960f)

- 쓰기 스키마와 읽기 스키마는 필드 순서가 달라도 문제없다. 왜냐하면 스키마 해석에서는 이름으로 필드를 일치시키기 때문이다.
- 데이터를 읽는 코드가 읽기 스키마에는 없고 쓰기 스키마에 존재하는 필드를 만나면 이 필드는 무시한다.
- 데이터를 읽는 코드가 기대하는 어떤 필드가 쓰기 스키마에는 포함돼 있지 않은 경우에는 읽기 스키마에 선언된 기본값으로 채운다.


### 스키마 발전 규칙

아브로에서 상위 호환성은 새로운 버전의 쓰기 스키마와 예전 버전의 읽기 스키마를 가질 수 있음을 의미한다.<br>
반대로 하위 호환성은 새로운 버전의 읽기 스키마와 예전 버전의 쓰기 스키마를 가질 수 있음을 의미한다.

호환성을 유지하기 위해서는 기본값이 있는 필드만 추가하거나 삭제할 수 있다.<br>
예를 들어 기본값이 있는 필드를 추가해 새로운 스키마에는 추가된 필드가 있고 예전 스키마에는 없다고 가정해보자.<br>
새로운 스키마를 사용하는 읽기가 예전 스키마로 기록된 레코드를 읽으면 누락된 필드는 기본값으로 채워진다.

기본값이 없는 필드를 추가하면 새로운 읽기는 예전 쓰기가 기록된 데이터를 읽을 수 없기 때문에 하위 호환성이 깨진다.<br>
기본값이 없는 필드를 삭제하면 예전 읽기는 새로운 쓰기가 기록된 데이터를 읽을 수 없기 때문에 상위 호환성이 깨진다.

**일부 프로그래밍 언어에서 널은 임의 변수의 기본값으로 허용하지만 아브로는 그렇지 않다.** <br>
필드에 널을 허용하려면 ***유니온 타입***을 사용해야 한다. 예를 들어 union { null, long, string } field;는 field가 수나 문자열 또는 널일 수 있다는 의미다.

필드가 유니온 엘리먼트 중 하나인 경우에만 기본값으로 널을 사용할 수 있다. 이것은 기본으로 모든 널 가능 값을 갖기보다 장황하지만 널일 수 있는 것과 널일 수 없는 것이 명확하기에 안정성이 더 높다.


### 쓰기 스키마는 무엇인가?

읽기는 특정 데이터를 부호화한 쓰기 스키마를 어떻게 알 수 있을까?<br>
모든 레코드에 전체 스키마를 포함시킬 수는 없다. 왜냐하면 스키마는 부호화된 데이터보다 훨씬 클 가능성이 있고, 그러면 이진 부호화로 절약한 공간이 소용없다.

답은 아브로를 사용하는 상황에 따라 다르다. 몇 가지 예를 보면 다음과 같다.

- 많은 레코드가 있는 대용량 파일
  - 아브로의 일반적인 용도(특히 하둡을 사용한다는 맥락에서는)는 모두 동일한 스키마로 부호화된 수백만 개 레코드를 포함한 큰 파일을 저장하는 용도다.
  - 이 경우 파일의 쓰기는 파일의 시작 부분에서 한 번만 쓰기 스키마를 포함하면 된다. 이를 위해 파일 형식(객체 컨테이너 파일)을 명시한다.
- 개별적으로 기록된 레코드를 가진 데이터베이스
  - 데이터베이스의 다양한 레코드들은 다양한 쓰기 스키마를 사용해 서로 다른 시점에 쓰여질 수 있다. 즉 모든 레코드가 동일한 스키마를 가진다고 가정할 수 없다.
  - 가장 간단한 해결책으로 모든 부호화된 레코드의 시작 부분에 버전 번호를 포함하고 데이터베이스에는 스키마 버전 목록을 유지한다.
  - 읽기는 레코드를 가져와 버전 번호를 추출한 다음 데이터베이스에서 버전 번호에 해당하는 쓰기 스키마를 가져온다.
- 네트워크 연결을 통해 레코드 보내기
  - 두 프로세스가 양방향 네트워크 연결을 통신할 때 연결 설정에서 스키마 버전 합의를 할 수 있다.
  - 이후 연결을 유지하는 동안 합의된 스키마를 사용한다.


스키마 버전을 사용하는 데이터베이스는 어떤 경우라도 유용하다. 스키마 버전들이 설명서처럼 동작해 스키마 호환성 체크를 직접할 수 있기 때문이다.

버전 번호는 단조 증가 정수나 스키마의 해시를 사용해서 할 수 있다.


### 동적 생성 스키마

프로토콜 버퍼와 스리프트에 비해 아브로는 스키마에 태그번호가 포함되어 있지 않다.

이 차이는 아브로가 동적 생성 스키마에 더 유용하다는 점이다.

예를 들어 파일로 덤프할 내용을 가진 관계형 데이터베이스가 있고 앞서 언급한 텍스트(JSON, CSV, XML)의 문제점을 피하기 위해 이진 형식을 사용한다고 가정해 보자.

아브로를 사용한다면 관계형 스키마로부터 아브로 스키마를 상당히 쉽게 생성할 수 있다. 그리고 이 스키마를 이용해 데이터베이스 내용을 부호화하고 아브로 객체 컨테이너 파일로 모두 덤프할 수 있다.<br>
각 데이터베이스 테이블에 맞게 레코드 스키마를 생성하고 각 칼럼은 해당 레코드의 필드가 된다. 데이터베이스의 칼럼 이름은 아브로의 필드 이름에 매핑된다.

이제 데이터베이스 스키마가 변경되면 갱신된 데이터베이스 스키마로부터 새로운 아브로 스키마를 생성하고 새로운 아브로 스키마로 데이터를 내보낸다.<br>
**데이터를 내보내는 과정은 스키마 변경에 신경 쓸 필요가 없다.** <br>
**새로운 데이터 파일을 읽는 사람은 레코드 필드가 변경된 사실을 알게 되지만 필드는 이름으로 식별되기 때문에 갱신된 쓰기 스키마는 여전히 이전 읽기 스키마와 매치가 가능하다.**

**이에 반해 스리프트나 프로토콜 버퍼를 이런 용도로 사용한다면 필드 태그를 수동으로 할당해야만 한다.** <br>
즉 데이터베이스 스키마가 변경될 때마다 관리자는 데이터베이스 칼럼 이름과 필드 태그의 매핑을 수동으로 갱신해야 한다.


### 코드 생성과 동적 타입 언어

스리프트와 프로토콜 버퍼는 코드 생성에 의존한다. 스키마를 정의한 후 선택한 프로그래밍 언어로 스키마를 구현한 코드를 생성할 수 있다.

이 방식은 자바, C++, C# 같은 정적 타입 언어에서 유용하다.<br>
왜냐하면 복호화된 데이터를 위해 효율적인 인메모리 구조를 사용하고 데이터 구조에 접근하는 프로그램을 작성할 때 자동 완성과 타입 확인이 가능하기 때문이다.

자바스크립트, 루비, 파이썬 같은 동적 타입 프로그래밍 언어에서는 만족시킬 컴파일 시점의 타입 검사기가 없기 때문에 코드를 생성하는 것이 중요하지 않다.

따라서 Avro는 별도의 컴파일 과정이 필요 없는 동적 타입 언어에 더 적합하다.

단, Avro는 정적 타입 프로그래밍 언어를 위해 코드 생성을 선택적으로 제공한다.<br>
이 경우 객체 컨테이너 파일이 있다면 Avro 라이브러리를 사용해 열어 JSON 파일을 보는 것처럼 데이터를 볼 수 있다.<br>
이 파일은 필요한 메타데이터를 모두 포함하기 때문에 ***자기 기술***적이다.


### 스키마의 장점

JSON, XML, CSV 같은 텍스트 데이터 타입이 널리 사용되지만 스키마를 기반으로 한 이진부호화도 충분히 선택할 만한 방법이다.

- 필드 이름을 생략 가능해서 크기가 작을 수 있다.
- 스키마 자체가 유용한 문서화 형식이다.
- 스키마 DB를 유지하면 스키마 변경을 적용하기 전에 상/하위 호환성을 확인할 수 있다
- 정적 타입 프로그래밍 언어에서 스키마로부터 코드를 생성하는건 유용하다. (컴파일시점에 타입체크 가능)
